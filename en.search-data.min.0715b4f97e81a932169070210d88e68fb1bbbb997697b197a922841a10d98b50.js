'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href','section']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/docs/golang/',title:"Golang 基础",section:"Docs",content:"Golang 基础知识大纲\n"}),a.add({id:1,href:'/docs/pxc/',title:"Pxc",section:"Docs",content:"目录\r#\r\r"}),a.add({id:2,href:'/docs/linux/',title:"Linux",section:"Docs",content:"Linux 相关\r#\r\r"}),a.add({id:3,href:'/posts/%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC%E6%9D%A5%E5%8E%BB%E6%9B%B4%E6%96%B0%E5%8D%9A%E5%AE%A2/',title:"Linux定时任务",section:"Blog",content:"定时脚本来去更新博客\r#\r\r每次写静态博客会存在github上面，虽然写完会进行手动推送到github，但是每次在服务器来去就觉得麻烦，所以就写个定时任务来帮我执行拉取更新命令\n先来介绍下cron\r#\r\rubuntu下的定时任务，能定期执行命令\n开始使用\r#\r\r查看cron是否运行\r#\r\rps -ef|grep cron\nubuntu@VM-0-10-ubuntu:~$ ps -ef |grep cron\rroot 970 1 0 Feb28 ? 00:00:21 /usr/sbin/cron -f\rubuntu 23388 8185 0 22:51 pts/0 00:00:00 grep --color=auto cron\r# 如果没有运行可以运行\r# sudo service cron start\r编写脚本命令\r#\r\rvim pull.sh\n#!/bin/bash\rcd /home/ubuntu/blogs/root/ # /home/ubuntu/blogs/root/ 本地仓库\rgit pull\rchmod +x ./pull.sh 添加执行权限\n编写定时任务\r#\r\rsudo crontab -e\n# 一般开始会选择编辑器，一般选择vim就好，对应数字编号\rubuntu@VM-0-10-ubuntu:~$ sudo crontab -e\rSelect an editor. To change later, run 'select-editor'.\r1. /bin/nano \u0026lt;---- easiest\r2. /usr/bin/vim.basic\r3. /usr/bin/vim.tiny\r4. /bin/ed\r*/1 * * * * /usr/local/qcloud/stargate/admin/start.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\r0 0 * * * /usr/local/qcloud/YunJing/YDCrontab.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\r# 每一行表示一个任务，语法如下\rcrontab 编写语法\n   * * * * * command     分（0~59） 时（0~23） 天（1~31） 月（1~12） 周（0~6） 命令    符号：\n “*” 表示任意值 “，”逗号表示可以填写多哥值，如2，4表示2或者4 “/”斜线一般配置“*”号使用，代表每隔多长时间  示例：\n（1）30 20 * * * commad 表示每天的20:30执行命令 （2）5 20 13,14 * * commad	表示每月的13日，14日20:5分执行命令 （3）0,10 10,12 * * * commad	表示每天10点至12点之间，隔10分钟执行命令 （4）/5 * * * commad	表示每5分钟执行命令\ncrontab定期的执行上述编辑的任务\n把上述编写的pull.sh加入文件\n# 在每天凌晨6：00进行执行任务 pull.sh\r* 6 * * * /home/ubuntu/blogs/pull.sh\r生效\r#\r\rsudo service cron restart 重启\n"}),a.add({id:4,href:'/docs/pxc/load-data-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE/',title:"Load Data 数据导入",section:"Pxc",content:"LOAD DATA批量导入数据\r#\r\r导入环境\r#\r\rmycat + pxc\nmycat：数据切分\npxc：两个分片，每个分片只开启一个节点。（对于其他节点的数据同步，采用直接拷贝方式）\n数据源\r#\r\r采用golang编写，生成1000万行的简单数据，数据采用文本方式存储；\n1,测试数据\r2,测试数据\r3,测试数据\r...\r10000000,测试数据\r数据库表\nCREATE TABLE t_test ( id int NOT NULL, name varchar(200) NOT NULL, PRIMARY KEY (\u0026#39;id\u0026#39;) ) code\n/* 生成导入到数据库的数据； 对应数据库表字段 id name */ package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) const num = 10000000 func generate() { file, err := os.Create(\u0026#34;./data.txt\u0026#34;) if err != nil { fmt.Printf(\u0026#34;create file failed:[%v]\\n\u0026#34;, err) return } defer file.Close() buf := bufio.NewWriter(file) // 建立缓冲，减少IO次数，提高效率 	for i:=1; i\u0026lt;=num; i++ { _, err := buf.WriteString(fmt.Sprintf(\u0026#34;%d,测试数据\\n\u0026#34;, i)) //_, err := file.WriteString(fmt.Sprintf(\u0026#34;%d, 测试数据\\n\u0026#34;, i)) // 这种无缓冲方式较慢 	if err != nil { fmt.Printf(\u0026#34;WriteString failed:[%v]\\n\u0026#34;, err) return } } buf.Flush() // 注意，由于文件长度刚好不是默认缓冲的整数倍，所以n次写入后，需要主动写入不足缓冲大小的字节数； } func main() { startTime := time.Now() generate() fmt.Println(time.Since(startTime)) // 打印一下耗时，一般大概2s样子 } 切分数据，准备多个数据（批量导入）\nsplit -l 1000000 -d data.txt # 1000万数据按每100万来划分 # x00 x01 x02 x03 x04 x05 x06 x07 x08 x09 共10个文件 导入程序\r#\r\r导入数据使用命令\nLOAD DATA LOCAL INFILE \u0026#34;data.txt\u0026#34; INTO TABLE table_name FIELDS TERMINATED BY \u0026#39;,\u0026#39; OPTIONALLY ENCLOSED BY \u0026#39;\\\u0026#34;\u0026#39; LINES TERMINATED BY \u0026#39;\\\\n\u0026#39; -- data.txt 数据文件 -- table_name 表名 -- \u0026#39;,\u0026#39; 分隔符 -- \u0026#39;\\\u0026#34;\u0026#39; 忽略 双引号 -- \u0026#39;\\\\n\u0026#39; 换行 采用golang编写导入数据的程序\n/* 导入数据到 mysql 使用多个goroutine同时导入 */ package main import ( \u0026#34;database/sql\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var dir string var db *sql.DB var wg sync.WaitGroup func init() { // 通过参数获取文件夹路径 	flag.StringVar(\u0026amp;dir, \u0026#34;path\u0026#34;, \u0026#34;.\\\\\u0026#34;, \u0026#34;指定目录路径\u0026#34;) flag.Usage = func() { _, _ = fmt.Fprint(os.Stderr, `load: 这是使用多线程通过MySQL的LOAD DATA命令导入数据 数据源通过指定目录或者把该程序移植到数据源当前目录 Usage: `) flag.PrintDefaults() } } // initDB: 初始化数据连接 func initDB() (err error) { // dsn (database source name) 数据源 	//dsn := \u0026#34;admin:Mysql123456.@tcp(192.168.145.134:8066)/test\u0026#34; 	dsn := \u0026#34;admin:Mysql123456.@tcp(192.168.145.139:3306)/test\u0026#34; // open 验证参数是否正确，并不会建立实际的连接，db是一个连接对象，存储连接过程需要的相关信息 	db, err = sql.Open(\u0026#34;mysql\u0026#34;, dsn) if err != nil { return err } // 检测连接源dsn是否真实有效 	err = db.Ping() if err != nil { fmt.Printf(\u0026#34;[%s] dsn not aviliable: [%v]\\n\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;), err) return err } db.SetMaxOpenConns(3) // 设置连接池最大打开连接数 	db.SetMaxIdleConns(0) // 设置连接池中最大空闲连接 	db.SetConnMaxLifetime(5*time.Minute) // 设置连接的最大生成时间，超过该时间不可重用 	return nil } func loading(filePath string) { defer wg.Done() fmt.Println(filePath) mysql.RegisterLocalFile(filePath) sql_ := \u0026#34;LOAD DATA LOCAL INFILE \u0026#39;\u0026#34;+filePath+\u0026#34;\u0026#39; INTO TABLE t_test(id, name) FIELDS TERMINATED BY \u0026#39;,\u0026#39; OPTIONALLY ENCLOSED BY \u0026#39;\\\u0026#34;\u0026#39; LINES TERMINATED BY \u0026#39;\\\\n\u0026#39;\u0026#34; _, err := db.Exec(sql_) if err != nil { // 如果导入失败，如连接意外断开怎么重新恢复，再次导入 	fmt.Printf(\u0026#34;load file[%s] failed:[%v]\\n\u0026#34;, filepath.Base(filePath), err) return } log.Printf(\u0026#34;file[%s] 数据导入完成....\\n\u0026#34;, filepath.Base(filePath)) } func main() { startTime := time.Now() flag.Parse() // 初始化 db 	err := initDB() if err != nil{ fmt.Printf(\u0026#34;init db failed:[%v]\\n\u0026#34;, err) return } // 获取到导入文件的路径 	files, err := ioutil.ReadDir(dir) if err != nil { fmt.Printf(\u0026#34;read file list failed:[%v]\\n\u0026#34;, err) return } // 遍历所有的文件，开启goroutine来执行导入数据 	for i, v := range files { path := dir + \u0026#34;\\\\\\\\\u0026#34; + v.Name() // 这里注意再windows下的路径 \\ \\\\ 	// 如果文件夹目录下存在其他的文件时？ 如：load.exe 	if strings.Contains(path, \u0026#34;.exe\u0026#34;) { continue } // 开启一个goroutine执行导入 	wg.Add(1) go loading(path) } wg.Wait() // 等待所有goroutine结束  fmt.Println(\u0026#34;总耗时:\u0026#34;, time.Since(startTime)) } 导入测试\r#\r\rsql.DB采用默认设置\r#\r\r对sql.DB对象不进行任何的设置，即采用默认设置来导入。\nload file[x03] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[430]} was closed ,reason is [err:java.io.IOException: Broken pipe]]\rload file[x02] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[432]} was closed ,reason is [err:java.io.IOException: Broken pipe]]\r[mysql] 2020/12/21 17:26:28 packets.go:427: busy buffer\rload file[x00] failed:[commands out of sync. You can't run this command now]\rload file[x08] failed:[Error 1152: Connection {DataHost[192.168.145.131:3306],Schema[test],threadID[418]} was closed ,reason is [err:java.io.IOException: Broken pipe]]\rload file[x06] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[428]} was closed ,reason is [err:java.io.IOException: Broken pipe]]\rload file[x01] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[433]} was closed ,reason is [err:java.io.IOException: Broken pipe]]\rload file[x07] failed:[Error 1152: Connection {DataHost[192.168.145.131:3306],Schema[test],threadID[409]} was closed ,reason is [err:java.io.IOException: Broken pipe]]\rload file[x04] failed:[Error 1152: Backend connect Error, Connection{DataHost[192.168.145.135:3306],Schema[test]} refused]\r2020/12/21 17:30:10 file[x09] 数据导入完成....\rload file[x05] failed:[Error 1105: Backend connect Error, Connection{DataHost[192.168.145.135:3306],Schema[test]} refused]\r总耗时： 11m9.7511593s\r1000万 条数据 导入成功 200万 条；\n上述日志：连接被关闭，造成MyCat中报IO异常；可能由于虚拟机的配置太低不能应对大批量数据的导入；限制同时进行导入连接数量；\n对sql.DB进行配置\r#\r\r1\n// 设置 sql.DB db.SetMaxOpenConns(5) // 设置连接池最大打开连接数 db.SetMaxIdleConns(2) // 设置连接池中最大空闲连接 出现超时以及管道断开等现象\nload file[x00] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[446]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x02] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[447]} was closed ,reason is [sql timeout]] load file[x06] failed:[Error 1152: Connection {DataHost[192.168.145.131:3306],Schema[test],threadID[427]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x03] failed:[Error 1152: Connection {DataHost[192.168.145.131:3306],Schema[test],threadID[426]} was closed ,reason is [err:java.io.IOException: Broken pipe]] 2\n// 设置 sql.DB db.SetMaxOpenConns(3) // 设置连接池最大打开连接数 db.SetMaxIdleConns(1) // 设置连接池中最大空闲连接 [mysql] 2020/12/22 10:14:33 packets.go:36: unexpected EOF load file[x09] failed:[invalid connection] [mysql] 2020/12/22 10:14:33 packets.go:36: unexpected EOF load file[x01] failed:[invalid connection] [mysql] 2020/12/22 10:14:33 packets.go:36: unexpected EOF load file[x04] failed:[invalid connection] load file[x03] failed:[dial tcp 192.168.145.134:8066: connectex: No connection could be made because the target machine actively refused it.] load file[x07] failed:[dial tcp 192.168.145.134:8066: connectex: No connection could be made because the target machine actively refused it.] load file[x06] failed:[dial tcp 192.168.145.134:8066: connectex: No connection could be made because the target machine actively refused it.] load file[x00] failed:[dial tcp 192.168.145.134:8066: connectex: No connection could be made because the target machine actively refused it.] 3\ndb.SetMaxOpenConns(3) // 设置连接池最大打开连接数 db.SetMaxIdleConns(0) // 设置连接池中最大空闲连接 只有一个X09 文件的导入出现如下问题：\n2020/12/22 10:49:24 sql res: \u0026lt;nil\u0026gt; load file[x09] failed:[commands out of sync. You can\u0026#39;t run this command now] 到这里 1000万数据全部导入成功。\n使用3个连接去导入数据，并且这三个连接每导入完成即进行关闭（不保留空闲连接）\n"}),a.add({id:5,href:'/docs/pxc/percona-percona-xtradb-cluster/',title:"Percona 集群相关",section:"Pxc",content:"Percona 集群相关\r#\r\rPercona 数据库\r#\r\r准备工作\r#\r\rjemalloc-3.6.0-1. centos7 el7.x86_64.rpm\nPercona-Server-5.7.32-35-r5688520-el7-x86_64-bundle centos7.tar\n安装\r#\r\r解压.tar\r#\r\r# 拷贝至目录 scp jemalloc-3.6.0-1. centos7 el7.x86_64.rpm Percona-Server-5.7.32-35-r5688520-el7-x86_64-bundle centos7.tar centos7.tar root@192.168.31.129:/home cd /home tar -xf Percona-Server-5.7.32-35-r5688520-el7-x86_64-bundle centos7.tar yum localinstall *.rpm 启动\r#\r\rsystemctl start mysqld\n防火墙开放 3306\r#\r\rfirewall-cmd --zone=public --add-port=3306/tcp --permanent 开放3306\n\u0026ndash;permanent： 永久生效，重启系统后依然生效\nfirewall-cmd --reload 重新导入配置\n修改数据库配置文件\r#\r\rvi /etc/my.cnf character_set_server = utf8 bind-address = 0.0.0.0 skip-name-resolve # 跳过dns解析，可解决在云上安装后运行慢的情况 重启mysql systemctl restart mysqld\n禁用开机mysql自动启动\r#\r\rchkconfig mysqld off\nNote: Forwarding request to \u0026#39;systemctl disable mysqld.service\u0026#39;. Removed symlink /etc/systemd/system/multi-user.target.wants/mysqld.service. Removed symlink /etc/systemd/system/mysql.service. 原因： 当某个节点宕机时间过长时，如果随系统自动启动后，会同步宕机时间内更新的数据，如果时间过长，pxc集群会限制其它的写入操作，直到所有的数据全部同步完成，所以禁用开机自启是必要的。\n**正确做法：**从其它节点拷贝数据文件到当前节点里面，然后再去启动数据库。\n修改数据库root密码\r#\r\rcat /var/log/mysqld.log | grep \u0026quot;A temporary password\u0026quot; 查看root默认密码\nmysql_secure_installation\npassword: Mysql123456.\n[root@mysql-first ~]# mysql_secure_installation Securing the MySQL server deployment. Enter password for user root: The existing password for the user account root has expired. Please set a new password. New password: Re-enter new password: The \u0026#39;validate_password\u0026#39; plugin is installed on the server. The subsequent steps will run with the existing configuration of the plugin. Using existing password for root. Estimated strength of the password: 100 Change the password for root ? ((Press y|Y for Yes, any other key for No) : y New password: Re-enter new password: Sorry, passwords do not match. New password: Re-enter new password: Estimated strength of the password: 100 Do you wish to continue with the password provided?(Press y|Y for Yes, any other key for No) : y By default, a MySQL installation has an anonymous user, allowing anyone to log into MySQL without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? (Press y|Y for Yes, any other key for No) : y Success. Normally, root should only be allowed to connect from \u0026#39;localhost\u0026#39;. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? (Press y|Y for Yes, any other key for No) : y Success. By default, MySQL comes with a database named \u0026#39;test\u0026#39; that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? (Press y|Y for Yes, any other key for No) : y - Dropping test database... Success. - Removing privileges on test database... Success. Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? (Press y|Y for Yes, any other key for No) : y Success. All done! 创建远程连接账户\r#\r\rmysql -uroot -pMysql123456. mysql\u0026gt; create user \u0026#39;admin\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;Mysql123456.\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; grant all privileges on *.* to \u0026#39;admin\u0026#39;@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) 忘记root密码\r#\r\r 编辑数据库配置文件  vi /etc/my.cnf\n# 添加一行 skip-grant-tables 重启数据库  systemctl restart mysqld\nmysql命令直接进入数据库，并修改root密码为：Mysql12345.  mysql mysql\u0026gt; use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql\u0026gt; UPDATE user SET authentication_string = password(\u0026#39;Mysql12345.\u0026#39;) where User=\u0026#39;root\u0026#39;; Query OK, 1 row affected, 1 warning (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 1 mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) Percona XtraDB Cluster 集群\r#\r\r准备工作\r#\r\r删除 mariadb-libs\r#\r\ryum -y remove mari* 卸载 mari 开头的全部程序包，避免影响PXC集群的安装\n开放PXC 依赖的端口\r#\r\r   端口 描述     3306 MySQL服务端口   4444 请求全量同步（SST）端口，会引发集群限速，尽量避免   4567 数据库节点之间通信端口   4568 请求增量同步（IST）端口，平时节点同步采用方式    firewall-cmd --zone=public --add-port=3306/tcp --add-port=4444/tcp --add-port=4567/tcp --add-port=4568/tcp --permanent firewall-cmd --reload 关闭SELINUX\r#\r\rLinux安全程序会影响PXC的运行，配置 SELINUX=disabled\nvi /etc/selinux/config\n# This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. # SELINUX=enforcing  SELINUX = disabled # 更改行 # SELINUXTYPE= can take one of three values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted reboot 重启生效\npkg包\r#\r\rPercona-XtraDB-Cluster-5.7.31-31.45-r10-el7-x86_64-bundle.tar 包含了percona数据库\nqpress-11-1.el7.x86_64.rpm\nPercona-XtraBackup-2.4.21-r5988af5-el7-x86_64-bundle.tar\n安装\r#\r\r拷贝至 /home 目录\r#\r\rscp qpress-11-1.el7.x86_64.rpm Percona-XtraDB-Cluster-5.7.31-31.45-r10-el7-x86_64-bundle.tar centos7.tar Percona-XtraBackup-2.4.21-r5988af5-el7-x86_64-bundle.tar root@192.168.31.129:/home\ncd /home [root@localhost home]# tar -xf Percona-XtraBackup-2.4.21-r5988af5-el7-x86_64-bundle.tar [root@localhost home]# tar -xf Percona-XtraDB-Cluster-5.7.31-31.45-r10-el7-x86_64-bundle.tar yum localinstall *.rpm 初始化工作\r#\r\r修改/etc/my.cnf\r#\r\rvi /etc/my.cnf\n# # The Percona XtraDB Cluster 5.7 configuration file. # # # * IMPORTANT: Additional settings that can override those from this file! # The files must end with \u0026#39;.cnf\u0026#39;, otherwise they\u0026#39;ll be ignored. # Please make any edits and changes to the appropriate sectional files # included below. # !includedir /etc/my.cnf.d/ !includedir /etc/percona-xtradb-cluster.conf.d/ # 去目录下查看  cd /etc/percona-xtradb-cluster.conf.d/\n-rw-r--r--. 1 root root 381 Oct 20 15:57 mysqld.cnf # mysql配置文件 -rw-r--r--. 1 root root 440 Oct 20 15:57 mysqld_safe.cnf -rw-r--r--. 1 root root 1.1K Oct 20 15:57 wsrep.cnf # 集群配置文件 把该目录下的mysql配置文件更新到 /etc/my.cnf\n# Template my.cnf for PXC # Edit to your requirements. [client] socket=/var/lib/mysql/mysql.sock [mysqld] server-id=1 datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid log-bin log_slave_updates expire_logs_days=7 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 修改root用户密码\r#\r\r参考Percona数据库安装中方式\n创建远程连接账户\r#\r\r参考Percona数据库安装中方式\n禁用开机自启动\r#\r\r参考Percona数据库安装中方式\n配置集群相关配置\r#\r\rpcx01 节点配置\nserver-id=1 #PXC集群中MySQL实例的唯一ID，不能重复，必须是数字 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so wsrep_cluster_name=pxc-cluster #PXC集群的名称 PXC集群节点的IP wsrep_cluster_address=gcomm://192.168.145.131,192.168.145.132,192.168.145.133 # pxc集群节点ip wsrep_node_name=pxc01 #当前节点的名称 wsrep_node_address=192.168.145.131 #当前节点的IP wsrep_sst_method=xtrabackup-v2 #同步方法(mysqldump、rsync、xtrabackup) wsrep_sst_auth= admin:Mysql123456. #同步使用的帐户 pxc_strict_mode=ENFORCING #同步严厉模式 binlog_format=ROW #基于ROW复制(安全可靠) default_storage_engine=InnoDB #默认引擎 innodb_autoinc_lock_mode=2 #主键自增长不锁表 pcx02 节点配置\nserver-id=2 #PXC集群中MySQL实例的唯一ID，不能重复，必须是数字 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so wsrep_cluster_name=pxc-cluster #PXC集群的名称 PXC集群节点的IP wsrep_cluster_address=gcomm://192.168.145.131,192.168.145.132,192.168.145.133 # pxc集群节点ip wsrep_node_name=pxc02 #当前节点的名称 wsrep_node_address=192.168.145.132 #当前节点的IP wsrep_sst_method=xtrabackup-v2 #同步方法(mysqldump、rsync、xtrabackup) wsrep_sst_auth= admin:Mysql123456. #同步使用的帐户 pxc_strict_mode=ENFORCING #同步严厉模式 binlog_format=ROW #基于ROW复制(安全可靠) default_storage_engine=InnoDB #默认引擎 innodb_autoinc_lock_mode=2 #主键自增长不锁表 pcx03 节点配置\nserver-id=3 #PXC集群中MySQL实例的唯一ID，不能重复，必须是数字 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so wsrep_cluster_name=pxc-cluster #PXC集群的名称 PXC集群节点的IP wsrep_cluster_address=gcomm://192.168.145.131,192.168.145.132,192.168.145.133 # pxc集群节点ip wsrep_node_name=pxc03 #当前节点的名称 wsrep_node_address=192.168.145.133 #当前节点的IP wsrep_sst_method=xtrabackup-v2 #同步方法(mysqldump、rsync、xtrabackup) wsrep_sst_auth= admin:Mysql123456. #同步使用的帐户 pxc_strict_mode=ENFORCING #同步严厉模式 binlog_format=ROW #基于ROW复制(安全可靠) default_storage_engine=InnoDB #默认引擎, 只支持InnoDB innodb_autoinc_lock_mode=2 #主键自增长不锁表 分别在各个节点上，向/etc/my.cnf 中添加如上配置\npxc01\n[client] socket=/var/lib/mysql/mysql.sock [mysqld] character_set_server = utf8 bind-address = 0.0.0.0 skip-name-resolve # 跳过dns解析，可解决在云上安装后运行慢的情况 server-id=1 datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid log-bin log_slave_updates expire_logs_days=7 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so wsrep_cluster_name=pxc-cluster #PXC集群的名称 PXC集群节点的IP wsrep_cluster_address=gcomm://192.168.145.131,192.168.145.132,192.168.145.133 # pxc集群节点ip wsrep_node_name=pxc01 #当前节点的名称 wsrep_node_address=192.168.145.131 #当前节点的IP wsrep_sst_method=xtrabackup-v2 #同步方法(mysqldump、rsync、xtrabackup) wsrep_sst_auth= admin:Abc_123456 #同步使用的帐户 pxc_strict_mode=ENFORCING #同步严厉模式 binlog_format=ROW #基于ROW复制(安全可靠) default_storage_engine=InnoDB #默认引擎 innodb_autoinc_lock_mode=2 #主键自增长不锁表 pxc02 pxc03 类似。\n集群初次启动\r#\r\r关闭各节点的msyql服务\r#\r\rsystemctl stop mysql\n构建集群\r#\r\r从所有节点中选择一个节点，这里选择pxc01(192.168.145.131)\nsystemctl start mysql@bootstrap.service\n启动其他节点\r#\r\rservice mysql start\n[root@pxc02 home]# systemctl status mysql.service ● mysql.service - Percona XtraDB Cluster Loaded: loaded (/usr/lib/systemd/system/mysql.service; disabled; vendor preset: disabled) Active: failed (Result: exit-code) since Thu 2020-11-26 16:18:08 CST; 3min 12s ago Process: 7624 ExecStopPost=/usr/bin/mysql-systemd stop-post (code=exited, status=0/SUCCESS) Process: 7595 ExecStop=/usr/bin/mysql-systemd stop (code=exited, status=2) Process: 6608 ExecStartPost=/usr/bin/mysql-systemd start-post $MAINPID (code=exited, status=1/FAILURE) Process: 6607 ExecStart=/usr/bin/mysqld_safe --basedir=/usr (code=exited, status=1/FAILURE) Process: 6538 ExecStartPre=/usr/bin/mysql-systemd start-pre (code=exited, status=0/SUCCESS) Main PID: 6607 (code=exited, status=1/FAILURE) Nov 26 16:18:08 pxc02 mysql-systemd[6608]: ERROR! mysqld_safe with PID 6607 has already exited: FAILURE Nov 26 16:18:08 pxc02 systemd[1]: mysql.service: control process exited, code=exited status=1 Nov 26 16:18:08 pxc02 mysql-systemd[7595]: WARNING: mysql pid file /var/run/mysqld/mysqld.pid empty or not readable Nov 26 16:18:08 pxc02 mysql-systemd[7595]: ERROR! mysql already dead Nov 26 16:18:08 pxc02 systemd[1]: mysql.service: control process exited, code=exited status=2 Nov 26 16:18:08 pxc02 mysql-systemd[7624]: WARNING: mysql pid file /var/run/mysqld/mysqld.pid empty or not readable Nov 26 16:18:08 pxc02 mysql-systemd[7624]: WARNING: mysql may be already dead Nov 26 16:18:08 pxc02 systemd[1]: Failed to start Percona XtraDB Cluster. Nov 26 16:18:08 pxc02 systemd[1]: Unit mysql.service entered failed state. Nov 26 16:18:08 pxc02 systemd[1]: mysql.service failed. 启动失败；经查找原因是 构建节点的配置文件中\nwsrep_sst_auth= admin:Mysql123456.  是密码配置不对\n测试集群是否搭建成功\r#\r\r连接任意集群节点，执行下面SQL\nshow status like 'wsrep_cluster%'\n输出如下：\n   Variable_name Value Comment     wsrep_cluster_weight 3 节点权重   wsrep_cluster_conf_id 3 集群成员更改总数   wsrep_cluster_size 3 集群大小   wsrep_cluster_state_uuid 85ab08a0-2fbc-11eb-b645-67acc08322c2    wsrep_cluster_status Primary     集群状态参数\r#\r\r节点同步相关\r#\r\r   Variable_name Comment     wsrep_last_applied 最后一次应用的事务的序列号   wsrep_last_committed 最后提交的事务的序列号   wsrep_replicated 复制的写集总数（发送到其他节点）   wsrep_replicated_bytes 复制的写集的总大小   wsrep_received 从其他节点接收的写集总数（当前节点接收的同步次数）   wsrep_received_bytes 从其他节点收到的写集的总大小（以字节为单位）    队列相关\r#\r\r   Variable_name Comment     wsrep_local_send_queue 发送队列的当前长度（即，等待发送的写集的数量）   wsrep_local_send_queue_avg 自上次状态查询以来发送队列的平均长度。当群集遇到网络吞吐量问题或复制限制时，该值将大大大于0。   wsrep_local_send_queue_max 发送队列的最大长度   wsrep_local_send_queue_min 发送队列的最小长度   wsrep_local_recv_queue 接收队列的当前长度（即，等待应用的写集的数量）   wsrep_local_recv_queue_avg 自上次状态查询以来接收队列的平均长度，当大于0表示队列过载，会造成复制限制   wsrep_local_recv_queue_max 接收队列的最大长度   wsrep_local_recv_queue_min,0 接收队列的最小长度    流量控制相关\r#\r\r   Variable_name Comment     wsrep_flow_control_paused_ns 在暂停状态下花费的总时间（以纳秒为单位），流控时间   wsrep_flow_control_paused 自上次状态查询以来，由于流控制而暂停的时间。（占比0-1），流控的时间占比   wsrep_flow_control_sent 发送的流控暂停的事件数量，指节点发出流控命令   wsrep_flow_control_recv 收到的流控暂停的事件数量，指节点收到流控命令   wsrep_flow_control_interval 此变量显示Galera流量控制的下限和上限。上限是队列中允许的最大请求数。如果队列达到上限则拒绝新请求引发流控。随着现有请求的处理队列减少，并且一旦达到下限，将再次允许新请求   wsrep_flow_control_status 流量控制状态（off 表示流控关闭，on表示流控开启）    怎样避免流量控制：\n1.改善网速，提高带宽；升级网卡带宽\n2.增加线程数，提高同步效率\n​	在配置文件中增加，线程数一般是CPU线程数的1-1.5倍；\n​ wsrep_slave_threads=16\n3.升级计算机性能，如CPU 内存 硬盘\n节点与集群的相关\r#\r\r   Variable_name Comment     wsrep_local_state_comment 节点状态   wsrep_cluster_status 集群状态   wsrep_connected 节点与集群连接状态   wsrep_ready 此变量显示节点是否准备好接受查询   wsrep_cluster_size 节点数量   wsrep_desync_count 延时节点数量   wsrep_incoming_addresses 集群节点的ip    事物相关\r#\r\r   Variable_name Comment     wsrep_cert_deps_distance 最高和最低序号之间的平均距离，可以并行应用。事物执行并发数   wsrep_apply_oooe 此变量显示并行化效率，无序应用写入集的频率；接收队列中事物的占比   wsrep_apply_oool 变量显示具有较高序列号的写集在具有较低序列号的写集之前应用的频率。接收队列中事物乱序执行的频率   wsrep_apply_window 最高和最低同时应用序列号之间的平均距离；接收队列中事物的平均数量   wsrep_commit_oooe 此变量显示事务无序提交的频率。发送队列中事物的占比   wsrep_commit_oool 当前无意义   wsrep_commit_window 最高和最低同时提交序列号之间的平均距离。发送队列中事物的平均数量    具体示例\r#\r\rwsrep_apply_oooe,0.000000 wsrep_apply_oool,0.000000 wsrep_apply_window,1.000000 wsrep_causal_reads,0 wsrep_cert_bucket_count,22 wsrep_cert_deps_distance,1.000000 wsrep_cert_index_size,3 wsrep_cert_interval,0.000000 wsrep_cluster_conf_id,9 wsrep_cluster_size,3 wsrep_cluster_state_uuid,85ab08a0-2fbc-11eb-b645-67acc08322c2 wsrep_cluster_status,Primary wsrep_cluster_weight,3 wsrep_commit_oooe,0.000000 wsrep_commit_oool,0.000000 wsrep_commit_window,1.000000 wsrep_connected,ON wsrep_desync_count,0 wsrep_evs_delayed,\u0026#34;\u0026#34; wsrep_evs_evict_list,\u0026#34;\u0026#34; wsrep_evs_repl_latency,0/0/0/0/0 wsrep_evs_state,OPERATIONAL wsrep_flow_control_interval,\u0026#34;[ 173, 173 ]\u0026#34; wsrep_flow_control_interval_high,173 wsrep_flow_control_interval_low,173 wsrep_flow_control_paused,0.000000 wsrep_flow_control_paused_ns,0 wsrep_flow_control_recv,0 wsrep_flow_control_sent,0 wsrep_flow_control_status,OFF wsrep_gcache_pool_size,3704 wsrep_gcomm_uuid,118e17ce-2fc1-11eb-9f3f-cfb115f418ee wsrep_incoming_addresses,\u0026#34;192.168.145.131:3306,192.168.145.132:3306,192.168.145.133:3306\u0026#34; wsrep_ist_receive_seqno_current,0 wsrep_ist_receive_seqno_end,0 wsrep_ist_receive_seqno_start,0 wsrep_ist_receive_status,\u0026#34;\u0026#34; wsrep_last_applied,6 wsrep_last_committed,6 wsrep_local_bf_aborts,0 wsrep_local_cached_downto,1 wsrep_local_cert_failures,0 wsrep_local_commits,0 wsrep_local_index,0 wsrep_local_recv_queue,0 wsrep_local_recv_queue_avg,0.176471 wsrep_local_recv_queue_max,2 wsrep_local_recv_queue_min,0 wsrep_local_replays,0 wsrep_local_send_queue,0 wsrep_local_send_queue_avg,0.000000 wsrep_local_send_queue_max,1 wsrep_local_send_queue_min,0 wsrep_local_state,4 wsrep_local_state_comment,Synced wsrep_local_state_uuid,85ab08a0-2fbc-11eb-b645-67acc08322c2 wsrep_open_connections,0 wsrep_open_transactions,0 wsrep_protocol_version,9 wsrep_provider_name,Galera wsrep_provider_vendor,Codership Oy \u0026lt;info@codership.com\u0026gt; wsrep_provider_version,3.45(ra60e019) wsrep_ready,ON wsrep_received,34 wsrep_received_bytes,5976 wsrep_repl_data_bytes,0 wsrep_repl_keys,0 wsrep_repl_keys_bytes,0 wsrep_repl_other_bytes,0 wsrep_replicated,0 wsrep_replicated_bytes,0 集群的关闭与启动\r#\r\r安全关闭\r#\r\r启动\r#\r\r集群构建节点：systemctl start mysql@bootstrap.service\n普通节点启动：service mysql start  or systemctl start mysql\n关闭\r#\r\r节点怎么启动，就使用对应命令关闭\n集群构建节点的关闭：systemctl stop mysql@bootstrap.service\n普通节点的关闭：service mysql stop\n启动与关闭相关参数\r#\r\r/var/lib/mysql/grastate.dat\n# GALERA saved state version: 2.1 uuid: 85ab08a0-2fbc-11eb-b645-67acc08322c2 seqno: -1 safe_to_bootstrap: 0 # 如果为 1 当前节点需要作为集群构建节点启动 启动顺序：\n 当集群中所有节点均正常关闭时，集群会把最后正常关闭的节点的参数进行设置 safe_to_boostrap:1，因为该节点的数据是最新的，再次启动集群时，需要通过集群的构建节点方式优先启动该节点。 当整个集群均同时非正常关闭，造成集群不能设置某个节点作为集群构建节点启动时，需要手动设置某个节点的参数safe_to_boostrap:1，然后通 过构建节点启动方式启动。其他节点按普通方式启动加入集群。举个例子：当通过vmware同时进行关机时，虚拟机构建的节点会同时关闭，没有足够的时间进行safe_to_boostrap:1 设置。  节点关闭对集群的影响\r#\r\r 当集群中超过半数的节点非正常关闭时，会造成集群所有的节点都停止服务；如果是属于正常关闭，则不会。 非正常关闭节点时，集群参数 wsrep_cluster_size 不会随节点的减少而改变  MySQL集群中间件\r#\r\r为什么还需要集群中间件？\r#\r\r中间件的作用主要是用于负载均衡，读写分离，数据切分(mysql数据库单表超2000万记录，读写性能会变差)等。\n负载均衡：Haproxy，MySQL-Proxy\n数据切分：MyCat ，Atlas，OneProxy，ProxySQL\n中间件对比\r#\r\r    MyCat Atlas One_Proxy Proxy SQL     是否开源 开源（基于阿里巴巴的Corba中间件）部署在3000台服务器上，每天执行50亿次请求 基于My\u0026rsquo;SQL Proxy，主要用于360产品，每天承载几十亿次请求  开源免费   基于环境 JAVA      跨平台 是      功能 分片算法丰富，读写分离，全局主键，分布式事务 读写分析，少量的数据切分算法，不支持全局主键，分布式事务  性能出众，Perconna推荐，支持读写分离和数据切分，功能较基础   社区 活跃 无社区，无出版物，资料少  资料较多    MyCat\r#\r\r准备工作\r#\r\rJDK：java-1.8.0-openjdk-devel.x86_64  (MyCat基于java开发)\nMyCat: Mycat-server-1.6.5-release-20180122220033-linux.tar.gz\n开放端口：8066（mycat数据服务） 和 9066（mycat管理端口）\nfirewall-cmd --zone=public --add-port=8066/tcp --add-port=9066/tcp --permanent firewall-cmd --reload 关闭SELINUX：关闭SELINUX请参考其他安装\n安装jdk\r#\r\ryum install java-1.8.0-openjdk-devel.x86_64 \n环境配置\npath环境自动配置完成；\nJAVA_HOME配置：\nls -lrt /etc/alternatives/java ··· 输出 lrwxrwxrwx. 1 root root 73 Nov 30 15:28 /etc/alternatives/java -\u0026gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el7_9.x86_64/jre/bin/java ··· vi /etc/profile	··· 添加如下内容 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el7_9.x86_64/ ··· source /etc/profile 安装mycat\r#\r\rtar -xf Mycat-server-1.6.5-release-20180122220033-linux.tar.gz\ndrwxr-xr-x. 2 root root 190 Dec 1 11:30 bin drwxrwxrwx. 2 root root 6 Mar 1 2016 catlet drwxrwxrwx. 4 root root 4096 Dec 1 11:47 conf drwxr-xr-x. 2 root root 4096 Dec 1 11:30 lib drwxrwxrwx. 2 root root 6 Jan 22 2018 logs -rwxrwxrwx. 1 root root 219 Jan 22 2018 version.txt MyCat配置文件\r#\r\rserver.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- - - Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); - you may not use this file except in compliance with the License. - You may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 - - Unless required by applicable law or agreed to in writing, software - distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the License for the specific language governing permissions and - limitations under the License. --\u0026gt; \u0026lt;!DOCTYPE mycat:server SYSTEM \u0026#34;server.dtd\u0026#34;\u0026gt; \u0026lt;mycat:server xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;system\u0026gt; \u0026lt;property name=\u0026#34;nonePasswordLogin\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户--\u0026gt; \u0026lt;property name=\u0026#34;useHandshakeV10\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;useSqlStat\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启实时统计、0为关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useGlobleTableCheck\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启全加班一致性检测、0为关闭 --\u0026gt; \u0026lt;property name=\u0026#34;sequnceHandlerType\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;subqueryRelationshipCheck\u0026#34;\u0026gt;false\u0026lt;/property\u0026gt; \u0026lt;!-- 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false --\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;useCompression\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--1为开启mysql压缩协议--\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;fakeMySQLVersion\u0026#34;\u0026gt;5.6.20\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--设置模拟的MySQL版本号--\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;processorBufferChunk\u0026#34;\u0026gt;40960\u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;processors\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;processorExecutor\u0026#34;\u0026gt;32\u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena | type 2 NettyBufferPool --\u0026gt; \u0026lt;property name=\u0026#34;processorBufferPoolType\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!--默认是65535 64K 用于sql解析时最大文本长度 --\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;maxStringLiteralLength\u0026#34;\u0026gt;65535\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;sequnceHandlerType\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;backSocketNoDelay\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;frontSocketNoDelay\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;processorExecutor\u0026#34;\u0026gt;16\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;serverPort\u0026#34;\u0026gt;8066\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;managerPort\u0026#34;\u0026gt;9066\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;idleTimeout\u0026#34;\u0026gt;300000\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;bindIp\u0026#34;\u0026gt;0.0.0.0\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;frontWriteQueueSize\u0026#34;\u0026gt;4096\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;processors\u0026#34;\u0026gt;32\u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--\u0026gt; \u0026lt;property name=\u0026#34;handleDistributedTransactions\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- off heap for merge/order/group/limit 1开启 0关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useOffHeapForMerge\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;!-- 单位为m --\u0026gt; \u0026lt;property name=\u0026#34;memoryPageSize\u0026#34;\u0026gt;64k\u0026lt;/property\u0026gt; \u0026lt;!-- 单位为k --\u0026gt; \u0026lt;property name=\u0026#34;spillsFileBufferSize\u0026#34;\u0026gt;1k\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;useStreamOutput\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 单位为m --\u0026gt; \u0026lt;property name=\u0026#34;systemReserveMemorySize\u0026#34;\u0026gt;384m\u0026lt;/property\u0026gt; \u0026lt;!--是否采用zookeeper协调切换 --\u0026gt; \u0026lt;property name=\u0026#34;useZKSwitch\u0026#34;\u0026gt;false\u0026lt;/property\u0026gt; \u0026lt;!-- XA Recovery Log日志路径 --\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;XARecoveryLogBaseDir\u0026#34;\u0026gt;./\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!-- XA Recovery Log日志名称 --\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;XARecoveryLogBaseName\u0026#34;\u0026gt;tmlog\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;/system\u0026gt; \u0026lt;!-- 全局SQL防火墙设置 --\u0026gt; \u0026lt;!--白名单可以使用通配符%或着*--\u0026gt; \u0026lt;!--例如\u0026lt;host host=\u0026#34;127.0.0.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--例如\u0026lt;host host=\u0026#34;127.0.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--例如\u0026lt;host host=\u0026#34;127.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--例如\u0026lt;host host=\u0026#34;1*7.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--这些配置情况下对于127.0.0.1都能以root账户登录--\u0026gt; \u0026lt;!-- \u0026lt;firewall\u0026gt; \u0026lt;whitehost\u0026gt; \u0026lt;host host=\u0026#34;1*7.0.0.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;/whitehost\u0026gt; \u0026lt;blacklist check=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;/blacklist\u0026gt; \u0026lt;/firewall\u0026gt; --\u0026gt; \u0026lt;!-- mysql 账户配置 --\u0026gt; \u0026lt;user name=\u0026#34;admin\u0026#34; defaultAccount=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;Mysql123456.\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;test\u0026lt;/property\u0026gt; \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;!-- \u0026lt;privileges check=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;TESTDB\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;table name=\u0026#34;tb01\u0026#34; dml=\u0026#34;0000\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table name=\u0026#34;tb02\u0026#34; dml=\u0026#34;1111\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt;	--\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;!-- \u0026lt;user name=\u0026#34;user\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;user\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;TESTDB\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;readOnly\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; --\u0026gt; \u0026lt;/mycat:server\u0026gt; schema.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- 虚拟逻辑库和表 --\u0026gt; \u0026lt;schema name=\u0026#34;test\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!-- auto sharding by id (long) 切分算法 mod-long --\u0026gt; \u0026lt;table name=\u0026#34;t_user\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;!-- 分片关系配置 --\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;cluster1\u0026#34; database=\u0026#34;test\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;cluster2\u0026#34; database=\u0026#34;test\u0026#34; /\u0026gt; \u0026lt;!-- 连接信息配置 1--\u0026gt; \u0026lt;!-- balance: 代表负载均衡类型； 0 表示不开启读写分离； 1 表示保留一个写节点负责写入，其他节点处理读请求； 2 表示所有写节点都要额外承担读请求； 3 表示读节点只处理读请求，写节点只处理写请求； writeType: 分发请求到写节点的模式 0 表示分发所有的请求到第一个写节点，只有第一个写节点宕机才会启用第二个写节点； 1 表示分发所有的请求到所有写节点一起处理； switchType: 依据什么来判断切换节点； 1 依据mycat自己的心跳检测来识别是否切换； 2 依据数据库集群的信息来判断节点是否切换； --\u0026gt; \u0026lt;dataHost name=\u0026#34;cluster1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;2\u0026#34; writeType=\u0026#34;1\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;W1\u0026#34; url=\u0026#34;192.168.145.131:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt; \u0026lt;!-- can have multi read hosts --\u0026gt; \u0026lt;readHost host=\u0026#34;W1R1\u0026#34; url=\u0026#34;192.168.145.132:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;readHost host=\u0026#34;W1R2\u0026#34; url=\u0026#34;192.168.145.133:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;writeHost host=\u0026#34;W2\u0026#34; url=\u0026#34;192.168.145.132:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt; \u0026lt;!-- can have multi read hosts --\u0026gt; \u0026lt;readHost host=\u0026#34;W2R1\u0026#34; url=\u0026#34;192.168.145.131:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;readHost host=\u0026#34;W2R2\u0026#34; url=\u0026#34;192.168.145.133:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt;	\u0026lt;!-- 连接信息配置 2 --\u0026gt; \u0026lt;dataHost name=\u0026#34;cluster2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;2\u0026#34; writeType=\u0026#34;1\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- can have multi write hosts --\u0026gt; \u0026lt;writeHost host=\u0026#34;W1\u0026#34; url=\u0026#34;192.168.145.135:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt; \u0026lt;!-- can have multi read hosts --\u0026gt; \u0026lt;readHost host=\u0026#34;W1R1\u0026#34; url=\u0026#34;192.168.145.136:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;readHost host=\u0026#34;W1R2\u0026#34; url=\u0026#34;192.168.145.137:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;writeHost host=\u0026#34;W2\u0026#34; url=\u0026#34;192.168.145.136:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; \u0026gt; \u0026lt;!-- can have multi read hosts --\u0026gt; \u0026lt;readHost host=\u0026#34;W2R1\u0026#34; url=\u0026#34;192.168.145.135:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;readHost host=\u0026#34;W2R2\u0026#34; url=\u0026#34;192.168.145.137:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; rule.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- - - Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); - you may not use this file except in compliance with the License. - You may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 - - Unless required by applicable law or agreed to in writing, software - distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the License for the specific language governing permissions and - limitations under the License. --\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;tableRule name=\u0026#34;rule1\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;func1\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;rule2\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;user_id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;func1\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-intfile\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;auto-sharding-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;rang-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;mod-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;mod-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-murmur\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;murmur\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;crc32slot\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;crc32slot\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-month\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;create_time\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;partbymonth\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;latest-month-calldate\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;calldate\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;latestMonth\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;auto-sharding-rang-mod\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;rang-mod\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;jch\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;jump-consistent-hash\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;murmur\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMurmurHash\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;seed\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt;\u0026lt;!-- 默认是0 --\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt;\u0026lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片 --\u0026gt; \u0026lt;property name=\u0026#34;virtualBucketTimes\u0026#34;\u0026gt;160\u0026lt;/property\u0026gt;\u0026lt;!-- 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍 --\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;weightMapFile\u0026#34;\u0026gt;weightMapFile\u0026lt;/property\u0026gt; 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 --\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;bucketMapPath\u0026#34;\u0026gt;/etc/mycat/bucketMapPath\u0026lt;/property\u0026gt; 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 --\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;crc32slot\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByCRC32PreSlot\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt;\u0026lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片 --\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;hash-int\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;rang-long\u0026#34; class=\u0026#34;io.mycat.route.function.AutoPartitionByLong\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;autopartition-long.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;mod-long\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMod\u0026#34;\u0026gt; \u0026lt;!-- how many data nodes --\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;func1\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByLong\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;partitionCount\u0026#34;\u0026gt;8\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;partitionLength\u0026#34;\u0026gt;128\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;latestMonth\u0026#34; class=\u0026#34;io.mycat.route.function.LatestMonthPartion\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;splitOneDay\u0026#34;\u0026gt;24\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;partbymonth\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMonth\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dateFormat\u0026#34;\u0026gt;yyyy-MM-dd\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;sBeginDate\u0026#34;\u0026gt;2015-01-01\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;rang-mod\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByRangeMod\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-range-mod.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;jump-consistent-hash\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByJumpConsistentHash\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;totalBuckets\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 启动与关闭\r#\r\r分配启动权限\r#\r\rcd mycat/bin chmod -R 777 *.sh # 添加权限 启动\r#\r\r./startup_nowrap.sh # 启动mycat ./mycat start # 启动mycat 关闭\r#\r\rps -aux | grep mycat kill -9 pid 测试\r#\r\r这里测试需要安装 mysql-client客户端（初学时，发现没有mysql客户端，没有mysql的命令）；\nmysql -uadmin -pMysql123456. -P 8066 -h 127.0.0.1 # 注意这里host：127.0.0.1 MyCat 切分\r#\r\r   七分算法 适合场合 备注     主键求模切分 数据增长速度慢，难于增加分片 有明确主键值   枚举值切分 归类存储数据，适合大多数业务    主键范围切分 数据快速增长，容易增加分片，不利于归档，腾出空间不会再次使用 有明确主键值   日期切分 数据快速增长，容易增加分片，不利于归档，腾出空间不会再次使用     主键求模切分\r#\r\r对主键求模来切分，一般选择对分片数求模\n  适合初始数据量很大，但是数据增长不快的场景\n地图产品 行政数据 企业数据\n怎么去理解增速很快？\n因为如果数据库增速很快，导致集群需要增加分片，由于求模算法，回导致数据的迁移，占用很大的IO资源；\n  求模切分的弊端在于扩展新分片难度大，迁移的数据太多；\n举个例子：由原来的2分片，扩展到4分片，迁移前2分片的数据到新增的2分片中，数据迁移困难；\n  如果非增加分片不可的情况，建议成倍增加为原有分片的2n倍，这样可以预测数据迁移规则；\n举个例子：原始分片2个，扩展到4个；\n原始分片中求模余0或1还再原来的分片，余2的则迁移至第3个分片，余3则迁移至第4个分片；\n  什么时候该添加分片？\n现有分片不足以保存热数据才添加分片；\n  枚举值切分\r#\r\r按照某个sh字段的值（数字）来切分\n\u0026lt;tableRule name=\u0026#34;sharding-by-intfile\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;!-- sharding_id: 数据库中字段名 --\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;!-- 算法名，这是使用java实现的类 --\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; ... \u0026lt;function name=\u0026#34;hash-int\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;!-- 切分算法使用java实现 --\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;!-- partition-hash-int.txt：配置枚举规则：如 001 是分片1， 201 是分片2 --\u0026gt; \u0026lt;!-- 010=0 024=0 0411=1 --\u0026gt; \u0026lt;/function\u0026gt; 例子：\ncustomer-hash-int.txt\n101=0 102=0 103=0 104=1 105=1 106=1 rule.xml\n\u0026lt;!-- 定义切分规则，指定数据列，及其切分算法 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-customer\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;customer-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; ... \u0026lt;!-- 配置切分算法实现类和切分枚举规则 --\u0026gt; \u0026lt;function name=\u0026#34;customer-hash-int\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;customer-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; schema.xml\n\u0026lt;!-- 虚拟逻辑库和表 --\u0026gt; \u0026lt;schema name=\u0026#34;test\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; ... \u0026lt;!-- 添加枚举切分t_customer --\u0026gt; \u0026lt;table name=\u0026#34;t_customer\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;sharding-customer\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; 热重载mycat配置文件\n[root@mycat conf]# mysql -uadmin -pMysql123456. -P 9066 -h 127.0.0.1 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 23 Server version: 5.6.29-mycat-1.6.7.6-release-20201126013625 MyCat Server (monitor) Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; reload @@config_all; Query OK, 1 row affected (0.53 sec) Reload config success 创建t_customer 表进行测试切分\n-- DataGrip 通过mycat 来创建表，会出现创建的表名和字段名都为大写 -- 可以再分片中分别创建即可 CREATE TABLE t_customer ( id INT PRIMARY KEY, username VARCHAR(200) NOT NULL, sharding_id INT NOT NULL ); -- 插入数据 insert into t_customer (id, username, sharding_id) values (1, \u0026#34;xiaoming\u0026#34;, 101); 应用场景\n 淘宝网：数据分片按商品分类来枚举值切分，当某个商品类的数据库出现故障，并不会影响其他商品类别的正常工作； 美团或饿了么：按地区类别来进行数据切分，这样某个地区数据分片宕机并不会影响其他地区的业务进行；  MyCat 父子表\r#\r\r父子表要解决的问题是？\r#\r\rMyCat不支持跨分片连接查询；\n现有2分片，分片1记录了A用户的信息，但是A用户的购物记录被切分到了分片2，这样的话在做连接查询时就会遇到问题，而父子表就是为了解决这种问题而出现的，使得分片记录如下，A用户的信息和A用户购物记录均会保存到统一分片，这样就可以随意做连接查询了。\n配置父子表\r#\r\rschema.xml\n\u0026lt;!-- 添加枚举切分t_customer --\u0026gt; \u0026lt;table name=\u0026#34;t_customer\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;sharding-customer\u0026#34; \u0026gt; \u0026lt;childTable name=\u0026#34;t_orders\u0026#34; primaryKey=\u0026#34;ID\u0026#34; joinKey=\u0026#34;customer_id\u0026#34; parentKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;/table\u0026gt; -- mycat 热重载所有配置文件 mysql\u0026gt; reload @@config_all; Query OK, 1 row affected (0.52 sec) Reload config success MyCat集群\r#\r\r方案\r#\r\r图中Haproxy两个节点实现了高可用，当一个Haproxy节点宕机， 另外一个节点通过争抢ip来进行服务\n只有一个Haproxy节点 能应对高一个负载吗？\r#\r\r能应对；一个Haproxy节点能应对 80000 次/s 请求。\n一个日访问量5000000，平均每秒请求 5000000 / 24 / 3600 = 58 次；\nMySQL 要大量集群， MyCat 要少量集群，Haproxy 不需要集群。\n增加Mycat节点\r#\r\r请参考之前方式，或者直接vmware克隆\n部署Haproxy\r#\r\r准备工作\r#\r\r开放端口：3306 TCP/IP转发端口；4001 监控界面端口；\nfirewall-cmd --zone=public --add-port=3306/tcp --add-port=4001/tcp --permanent firewall-cmd --reload 关闭SELINUX\nvi /etc/selinux/config\nSELINUX=disabled reboot 生效\n安装haproxy\r#\r\ryum -y install haproxy\n启动与停止与重启：\nservice haproxy start\nservice haproxy stop\nservice haproxy restart\n配置文件\r#\r\rvi /etc/haproxy/haproxy.cfg\nglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 # 后台监控的配置 listen admin_stats # 名称 bind 0.0.0.0:4001 # 监控界面的访问的ip和端口 mode http # 访问协议 stats uri /dbs # URI相对地址 stats realm Global\\ statistics # 统计报告格式 stats auth admin:admin # 登录密码 # 负载均衡的配置 listen proxy-mysql # 名称 bind 0.0.0.0:3306 mode tcp balance roundrobin # 请求转发算法，这里时轮询 option tcplog # 日志格式 server mycat01 192.168.145.134:8066 check port 8066 weight 1 maxconn 2000 # 负载均衡  server mycat02 192.168.145.138:8066 check port 8066 weight 1 maxconn 2000 # 负载均衡 # 由于上面再用的转发算法为 “轮询”，这里的weight无效； # 当balance 采用权重算法来转发时，weight才会起到作用；那么什么情况下会使用权重算法转发呢？ # 在需要负载均衡的多个节点存在差异化时，如ab两节点，a主机性能更好，处理效率更高，那么会给他更多权重，处理更多的请求。 option tcpka # 使用keeplive 检测死链 启动错误，无提示\r#\r\rsystemctl status haproxy  查看状态发现配置文件错误；\n部署keepalived\r#\r\r准备工作\r#\r\r开启防火墙的VRRP协议\nfirewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --protocol vrrp -j ACCEPT firewall-cmd --reload 安装\r#\r\ryum -y install keepalived 配置文件\r#\r\rvi /etc/keepalived/keepalived.conf\nvrrp_instance VI_1 {\rstate MASTER ! 如果2个节点都设置为MASTER，则当节点启动时会争抢虚拟IP，未抢到的接待你会编程SLAVE\rinterface ens33 ! 网卡名称\rvirtual_router_id 51 ! 虚拟路由标识，代表 节点ID \u0026lt;255\rpriority 100 ! 定义优先级\radvert_int 1 ! 秒\r! 认证，只有通过认证的才会心跳检测\rauthentication { auth_type PASS\rauth_pass 123456\r}\rvirtual_ipaddress { 192.168.145.139 ! 虚拟IP地址\r}\r}\r启动与关闭\r#\r\rsystemctl start keepalived systemctl stop keepalived 测试\r#\r\r使用DataGrip 通过keepalived的虚拟IP来连接mycat\n或者可以通过虚拟IP登录到linux来测试\nSysbench 基准测试\r#\r\r安装\r#\r\r在线安装\r#\r\rcurl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash yum -y install sysbench 本地安装\nsysbench 命令\r#\r\r语法：sysbench script [option] [command]\nOPTION\r#\r\r连接参数\n--mysql-host: 数据库IP地址\n--mysql-port: 端口号\n–-mysql-user: 用户名\n--mysql-password: 密码\n数据库测试\n--oltp-test-mode: 执行模式（simple只测试查询不测试写入 、nontrx测试无事务的增删改查、complex 带事务的增删改查）\n--oltp-tables-count: 测试表数量\n--oltp-table-size: 测试表的记录数\n--threads: 并发连接数\n--time: 测试执行时间（秒）\n--report-interval: 生成报告单的间隔时间（秒）\ncommand\r#\r\rprepare: 准备测试数据\nrun : 执行测试\ncleanup: 清楚测试数据\n测试示例\r#\r\r通过prepare命令生成测试数据\n# 注意这里的script脚本的路径，下面为在线安装的脚本路径，编译安装版本需要注意放置位置 sysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua \\ --mysql-host=192.168.145.138 \\  --mysql-port=3306 \\  --mysql-user=admin \\  --mysql-password=Mysql123456. \\ --oltp-tables-count=10 \\ --oltp-table-size=100000 \\ prepare 配置Haproxy(192.168.145.138) 负载均衡拥有3个节点的分片\n/etc/haproxy/haproxy.cfg\n# 这三个为同一个分片 server mysql01 192.168.145.131:3306 check port 3306 weight 1 maxconn 2000 server mysql02 192.168.145.132:3306 check port 3306 weight 1 maxconn 2000 server mysql03 192.168.145.133:3306 check port 3306 weight 1 maxconn 2000 生成测试数据\nsysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua --mysql-host=192.168.145.138 --mysql-port=3306 --mysql-user=admin --mysql-password=Mysql123456. --oltp-test-mode=complex --threads=10 --time=300 --report-interval=10 run \u0026gt;\u0026gt; /home/mysql_sysbench.log 查看测试结果：\n小结\r#\r\r数据表建议不低于10个，单表数据量不低于500万行。\n如果配备了SSD或者PCIE SSD，则建议单表数据量最少不低于1亿行。\n真实物理主机上的基准测试，建议24小时以上。\nTPCC-MYSQL压力测试\r#\r\r测试方案\r#\r\r安装tpcc-mysql\r#\r\r准备工作\r#\r\rvi /etc/my.cnf 编辑pxc集群配置文件\npxc_strict_mode=ENFORCING # 这个是默认，不允许不规范的操作\r# 修改为下面配置\rpxc_strict_mode=DISABLED # 这个是为了能运行tpcc测试模型（模型种存在无主键的数据 表）\r使用haproxy做负载均衡\n# 负载均衡\rserver mysql01 192.168.145.131:3306 check port 3306 weight 1 maxconn 2000\rserver mysql02 192.168.145.132:3306 check port 3306 weight 1 maxconn 2000\rserver mysql03 192.168.145.133:3306 check port 3306 weight 1 maxconn 2000\rtpcc 只有源代码，所以只能通过源代码编译执行\n安装编译所需的包\nyum -y install gcc yum install -y mysql-devel 下载tpcc-mysql源代码\ntpcc-mysql\n解压编译安装\nunzip tpcc-mysql-master.zip cd tpcc-mysql-master/src make 连接mysql 集群，创建tpcc测试的逻辑库\ntpcc\n导入tpcc 测试数据\n/tpcc_mysql_master/\ncd /home/tpcc_msyql_master ls *.sql add_fkey_idx.sql count.sql create_table.sql drop_cons.sql # create_table.sql: 创建数据表 add_fkey_idx.sql: 增加外键约束和索引 # 上面两个需要导入 mysql -uadmin -pMysql123456. -h 192.168.145.138 -P3306 use tpcc source create_table.sql source add_fkey_idx.sql 生成测试数据\ncd /home/tpcc_msyql_master ./tpcc_load -h 192.168.145.138 -P 3306 -d tpcc -uadmin -pMysql123456. -w 1 # w 代表tpcc测试模型种数据库种的仓库数，实际测试建议仓库数弄上千个，但这比较耗时 # vmware 虚拟机，生成w=1的测试数据大概耗时30分钟 执行测试\ncd /home/tpcc_msyql_master ./tpcc_start -h 192.168.145.138 -P 3306 -d tpcc -uadmin -pMysql123456. -w 1 -c 5 -r 300 -l 600 -\u0026gt; tpcc-output-log # -c 并发线程数 -r 数据库预热时间，单位秒 -l 测试时间s # tpcc-output-log 输出到文件 # 真实环境中，-r -l的时间都要长一些；如 -r 3600 -l 3600*24 PXC 原理\r#\r\r了解binlog 日志\r#\r\rbinlog 日志文件种类\r#\r\rmy.ini mysql配置文件\nbinlog-format=row # binlog模式 log-bin=mysql_bin # 日志文件名定义 日志文件\r#\r\r根据上面my.ini配置输出日志文件名称：\nmysql_bin.000001 mysql_bin.000002 这种文件名的文件，二进制方式存储，需要特定程序才能打开；\n打开日志文件方式：\n使用SQL语句\n-- 查看索引文件，显示有多少条binlog日志文件 show master logs; -- 查看具体的binlog日志文件 show binlogs events in \u0026#39;localhost:-bin.000009\u0026#39;; 索引文件\r#\r\rmysql_bin.index 以index结尾的文件，文本文件；\nbinlog 日志格式\r#\r\rRow\r#\r\r每条记录的变化都会写入日志中，记录的是实实在在的数据变化；\nSTATEMENT 模式\r#\r\r每一条会修改数据的sql语句会记录到binlog中\nMixed\r#\r\r普通操作使用STATEMENT格式，同步可能出现问题（例如，插入数据sql语句中包含某些函数UUID函数时）的操作选择ROW模式；\n集合了上述两种模式的优点\nPXC 同步原理\r#\r\rGTID (全局事务GIT, Global Transaction ID)\r#\r\r组成：server uuid + transaction_id\nserver uuid\r#\r\rshow status like '%uuid%' 查看uuid\n   Variable_name Value      wsrep_local_state_uuid 85ab08a0-2fbc-11eb-b645-67acc08322c2 集群uuid   wsrep_gcomm_uuid 533dbf66-35ca-11eb-89ce-02d6a075f25a 节点uuid   wsrep_cluster_state_uuid 85ab08a0-2fbc-11eb-b645-67acc08322c2 集群uuid    transaction_id\r#\r\rshow binlog event in 'localhost-binlog.000001' 通过查看binlog日志文件，图中红色框内的就是transaction_id, 指的是pxc集群的transaction_id\n节点的事务id\nshow status like 'wsrep_last_committed%' 查看节点的transaction_id\n通过这个ID可以推断节点同步情况；如有一个节点在wsrep_last_committed = 100的时候宕机。当他启动一段时间后，wsrep_last_committed = 150 ，那么100~150 就是该节点上线来同步的事务id\npxc 同步流程图\r#\r\r问题：\n  当其他节点接收到GTID之后宕机，那么其他节点Galera返回成功的响应，本地节点Galera正常提交，记录日志数据写入成功，而其他节点由于宕机并没真正写入数据，这是不是说“pxc集群并不是强一致性”。\npxc在这里还是强一致性的，因为宕机的节点已经不在集群中存活了，重启启动之前不会提供服务，所以并没有什么关系；当宕机节点再次启动后，还是会与集群中的节点进行同步，达到数据的一致性；\n  pxc集群由于网络原因会不会出现读写不一致的问题\n不会，pxc集群是同步发送writeSet和GTID的，如果网络故障Master收不到发送成功的响应是不会进行提交的。\n  pxc 中锁冲突流程图\r#\r\r有AB两个节点，这两个节点同时操作同一数据时可能引发锁冲突。\n举个例子：\n有AB两节点同时向数据库中的同一张表插入数据，且该表的主键是“自增长”的。且这两个节点同时争抢到主键ID为1的，并向对方发送writeSet，当A还没收到锁冲突的验证结果时，而先收到了B发给他的writeSet，A节点发现主键1自己正在使用，所以A节点会发送锁冲突的响应；同理B节点也可能会发送锁冲突的响应，这样对于主键1，AB两节点均收到锁冲突，而放弃使用；\n这样会造成什么影响呢？\n如在自增长主键的表中，可能会出现主键不连续的情况。这是因为在争抢的过程中，出现上述情况，就会重新争抢新的主键，而放弃了存在冲突的主键值。\n怎么避免这种问题呢？\n 不使用自增长主键 采用MyCat的全局主键  Replication集群\r#\r\r同步数据过程图：\n采用的是 异步机制，Master节点只管自身的数据的插入，并不主动发送数据到其他节点。其他slave节点会开启专用的线程来读取Master节点的binlog日志来进行同步；这样的集群适合读多写少的数据库。\nMySQL 5种架构设计\r#\r\rMySQL + 分布式Proxy扩展\r#\r\rPXC 集群\n适用于需要强一致性的系统，如与钱相关的。一般是PXC 集群+ MyCat（中间件） + Haproxy（负载均衡） + keepalived（双机热备）\nReplication集群\nPXC + Replication 集群\n集群表连接查询：\n  采用同步中间件，把pxc集群的数据同步到replication集群种，再做表连接查询\n  使用类似于kettle先分别从PXC集群和Replication集群获取数据，然后通过kettle来进行连接查询\n  数据归档，冷热数据分离\r#\r\rMongoDB 和 TokuDB\nMongoDB：兼顾读写性能，对于归档数据需要进行查询的场景，推荐使用MongoDB。4.0已支持事务\nTokuDB: MySQL一种存储引擎，性能比MongoDB 快且是带事务的写入\nMySQL + 缓存（redis）高并发架构\r#\r\rredis 或memcached\nMySQL + 小文件系统\r#\r\r文件体积大： Hadoop 的 HDFS 文件系统\n文件体积小： MongoDB的GridFS(可以存储图片、语音、短视频灯)，如果文件数据较小如 16m以下，可以使用默认的Binary BSON\nMySQL + Inforbright统计分析架构\r#\r\r对数据有统计分析的需求时采用\nMySQL 的设计原则\r#\r\rMySQL 架构的演化\r#\r\r单体单节点阶段\nPXC 集群的使用\r#\r\r导入数据\r#\r\rsql文件\r#\r\rsource 命令： source test.sql\n批量导入sql文件：source all.sql (先把所有的sql文件的路径，写入到all.sql 中，然后再导入)\n适用数据不多的情况；\n导入慢的原因：由于MySQL导入sql文件时，需要先对sql语句进行词法分析和分析，然后在继续数据的写入。当数据量过大，也就是sql语句过多，自然就会慢起来。\n文本文件\r#\r\rLOAD DATA  纯数据导入，速度快\nLOAD DATA LOCAL INFILE 'data.txt' INTO TABLE orders FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\u0026quot;' LINES TERMINATED BY '\\n'\n解释：从本地文件data.txt 导入表 orders 中，字段按 “,” 分隔；无视双引号，每行以换行符结束（不同操作系统不同“\\n” “\\r\\n”）。\nLOAD DATA 为单线程，可以先对data.txt来进行切分，然后采用多个线程来导入（30G 文件 6000万多条数据，大概50分钟即可导入完成）；\n注意 ： 在向MyCat 中间件使用上述命令时，需要在表名后面加上对应的字段\nLOAD DATA LOCAL INFILE 'data.txt' INTO TABLE orders(字段1，字段2) FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\u0026quot;' LINES TERMINATED BY '\\n'\n准备导入数据\r#\r\r使用熟悉的语言生成1000万条数据\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) var num = 10000000 func generate() { file, err := os.Create(\u0026#34;./data.txt\u0026#34;) if err != nil { fmt.Printf(\u0026#34;create file failed:[%v]\\n\u0026#34;, err) return } defer file.Close() buf := bufio.NewWriter(file) for i:=1; i\u0026lt;=num; i++ { _, err := buf.WriteString(fmt.Sprintf(\u0026#34;%d, 测试数据\\n\u0026#34;, i)) // id, name 	//_, err := file.WriteString(fmt.Sprintf(\u0026#34;%d, 测试数据\\n\u0026#34;, i)) 	if err != nil { fmt.Printf(\u0026#34;WriteString failed:[%v]\\n\u0026#34;, err) continue } } } func main() { startTime := time.Now() generate() time := time.Since(startTime) fmt.Println(time) // 耗时 2s } 切分文件为多份\nsplit -l 1000000 -d data.txt\n导入大量数据时MySQL配置\r#\r\r 当导入大量数据时，以下配置可以提高导入速度  [mysqld] ...... # 正常情况下为事务提交后，日志才写入硬盘，当设置为0后，日志每秒都写入磁盘，与事务是否提交没关系，代表数据库在事务# # 提交之前把日志写入磁盘，免去事务提交后才写入磁盘，提高事务效率。 innodb_flush_log_at_trx_commit = 0 # 不等待提交，直接写入磁盘； # 日志数据直接写入磁盘，而不会写到系统缓冲区。跳过缓冲区，减少CPU和内存的占用 innodb_flush_method = O_DIRECT # 设置引擎缓冲区的大小，减少写入次数，提高io效率 innodb_buffer_pool_size = 200M # 导入安全设置 =null表示禁用， /home表示仅限于该目录， 空为不做限制  secure_file_priv = 授予账户导入权限  grant file on *.* to admin@\u0026#39;%\u0026#39;  关闭集群分片节点（保留一个节点）  PXC集群在导入大量数据时，会导致限流，为了快速导入数据，就不能有限流；所以在导入时，一个pxc集群只开启一个节点，其他节点通过拷贝数据库文件来实现同步；\n我这里保留的节点为： 192.168.145.131（分片1） 和 192.168.145.135（分片2）\n在两个节点上分别创建t_test表；  CREATE TABLE t_test ( id int primary key, name varchar(200) not null )  修改MyCat配置文件\n修改之前记得保存之前的schme.xml文件\ncp schema.xml schema.xml_pxc\nschema.xml [192.168.145.131（分片1） 和 192.168.145.135（分片2）]\n  ... \u0026lt;!-- 添加需要进行七分的表，按mod-long切分 --\u0026gt; \u0026lt;table name=\u0026#34;t_test\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt;	\u0026lt;!-- 连接信息配置 1--\u0026gt; \u0026lt;dataHost name=\u0026#34;cluster1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;1\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- can have multi write hosts --\u0026gt; \u0026lt;writeHost host=\u0026#34;W1\u0026#34; url=\u0026#34;192.168.145.131:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt;\u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;!-- 连接信息配置 2 --\u0026gt; \u0026lt;dataHost name=\u0026#34;cluster2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;1\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- can have multi write hosts --\u0026gt; \u0026lt;writeHost host=\u0026#34;W1\u0026#34; url=\u0026#34;192.168.145.135:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt;\u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; ... 重新启动pxc 和 mycat\nsystemctl restart mysql@bootstrap.service cd /mycat/bin/ ./mycat restart 查看集群的情况\n开始数据导入\r#\r\r具体导入请查看 数据批量导入\n同步其他节点数据\r#\r\r对数据文件进行拷贝来同步其他节点的数据，这样会提高同步的效率，但需要使用 percona 专业的数据打包工具来进行，这边之后再进行研究；\n由于当前数据较少，直接采用pxc集群的全量同步进行。即把之前改动的MyCat记忆Mysql配置部分文件进行还原即可。\nPXC节点(/etc/my.cnf)\nvi /etc/my.cnf systemctl restart mysql@bootstrap.service my.cnf\r下面三项：使用load data命令导入数据时的配置文件；开启集群后需要删除；\rinnodb_flush_log_at_trx_commit = 0\rinnodb_flush_method = O_DIRECT\rinnodb_buffer_pool_size = 200M\r \r\rMyCat配置文件(/home/mycat/conf/)\nmv schema.xml schema.xml_load_data mv schema.xml_pxc schema.xml vi schema.xml ../bin/mycat restart schema.xml\r\u0026lt;schema name=\u0026quot;test\u0026quot; checkSQLschema=\u0026quot;false\u0026quot; sqlMaxLimit=\u0026quot;100\u0026quot;\u0026gt;\r\u0026lt;!-- 增加下方t_test的虚拟表及其分片算法 --\u0026gt;\r\u0026lt;table name=\u0026quot;t_test\u0026quot; dataNode=\u0026quot;dn1,dn2\u0026quot; primaryKey=\u0026quot;id\u0026quot; rule=\u0026quot;mod-long\u0026quot; /\u0026gt;\r...\r\u0026lt;/schema\u0026gt;\r\r\r\r集群同步完成。\n"}),a.add({id:6,href:'/docs/linux/ubuntu-%E4%B8%AD%E8%AE%BE%E7%BD%AE%E5%9B%BD%E5%86%85%E8%BD%AF%E4%BB%B6%E6%BA%90/',title:"Ubuntu 软件源",section:"Linux",content:"ubuntu 把软件源修改为国内源和更新\r#\r\r  备份原始文件\nsudo cp /etc/apt/sources.list /etc/apt/sources.list.backup\r  修改文件并添加国内源\nvi /etc/apt/sources.list	  注释原文件内的源 并添加如下地址 复制代码\n# Ubuntu 官方源\rdeb http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiverse\rdeb http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiverse\rdeb http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiverse\rdeb http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiverse\rdeb http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse\rdeb-src http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiverse\rdeb-src http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiverse\rdeb-src http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiverse\rdeb-src http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiverse\rdeb-src http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse\r# 阿里云\rdeb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\rdeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse\rdeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse\r# 网易163\rdeb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse\rdeb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse\rdeb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse\rdeb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse\rdeb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse\rdeb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse\r# 非官方包可能存在不完整情况，可在尾部添加官方源\rdeb http://archive.ubuntu.org.cn/ubuntu-cn/ feisty main restricted universe multiverse\r  更新源\nsudo apt-get update\r  更新软件\n注意：\n由于包与包之间存在各种依赖关系。upgrade只是简单的更新包，不管这些依赖，它不和添加包，或是删除包。而dist-upgrade可以根据依赖关系的变化，添加包，删除包。upgrade:系统将现有的Package升级,如果有相依性的问题,而此相依性需要安装其它新的Package或影响到其它Package的相依性时,此Package就不会被升级,会保留下来. dist-upgrade:可以聪明的解决相依性的问题,如果有相依性问题,需要安装/移除新的Package,就会试着去安装/移除它. (所以通常这个会被认为是有点风险的升级)\n# 谨慎操作\rsudo apt-get dist-upgrade sudo apt-get upgrade\r  常见的修复安装命令\nsudo apt-get -f install\r   国内主要软件源\r#\r\r企业站\r#\r\r1.搜狐：http://mirrors.sohu.com/\r2.网易：http://mirrors.163.com/\r3.阿里云：http://mirrors.aliyun.com/\r4.腾讯：http://Android-mirror.bugly.qq.com:8080/（仅针对APP开发的软件，限流，不推荐）\r5.淘宝：http://npm.taobao.org/\r教育站\r#\r\r1.上海交通大学：http://ftp.sjtu.edu.cn/html/resources.xml（部分移动运营商出口状况不佳，无法访问）\r2.华中科技大学：http://mirror.hust.edu.cn/（当前已用容量估计：4.83T）\r3.清华大学：http://mirrors.tuna.tsinghua.edu.cn/（当前已用容量估计：9.8T）\r4.北京理工大学：http://mirror.bit.edu.cn/web/\r5.兰州大学：http://mirror.lzu.edu.cn/\r6.中国科技大学：http://mirrors.ustc.edu.cn/（当前已用容量估计：21.32T）\r7.大连东软信息学院：http://mirrors.neusoft.edu.cn/（当前已用容量估计：2.5T）\r8.东北大学：http://mirror.neu.edu.cn/\r9.大连理工大学：http://mirror.dlut.edu.cn/\r10.哈尔滨工业大学：http://run.hit.edu.cn/html/（部分联通运营商出口状况不佳，无法访问）\r11.北京交通大学：http://mirror.bjtu.edu.cn/cn/\r12.天津大学：http://mirror.tju.edu.cn（无法访问，ping超时）\r13.中国地质大学：http://mirrors.cug.edu.cn/（当前已用容量估计：2.3T）\r14.浙江大学：http://mirrors.zju.edu.cn/\r15.厦门大学：http://mirrors.xmu.edu.cn/\r16.中山大学：http://mirror.sysu.edu.cn/\r17.重庆大学：http://mirrors.cqu.edu.cn/（当前已用容量估计：3.93T）\r18.北京化工大学：http://Ubuntu.buct.edu.cn/（Android SDK镜像仅供校内使用，当前已用容量估计：1.72T）\r19.南阳理工学院：http://mirror.nyist.edu.cn/\r20.中国科学院：http://www.opencas.org/mirrors/\r21.电子科技大学：http://ubuntu.uestc.edu.cn/（无法访问，ping超时）\r22.电子科技大学星辰工作室：http://mirrors.stuhome.net/（当前已用容量估计：1.08T）\r23.西北农林科技大学：http://mirrors.nwsuaf.edu.cn/（只做CentOS镜像，当前已用容量估计：140GB） 24.浙江大学：http://mirrors.zju.edu.cn/\r25.台湾淡江大学: http://ftp.tku.edu.tw/Linux/\r其他\r#\r\r1.首都在线科技股份有限公司（英文名Capital Online Data Service）：http://mirrors.yun-idc.com/\r2.中国电信天翼云：http://mirrors.ctyun.cn/\r3.noc.im：http://mirrors.noc.im/（当前已用容量估计：3.74T）\r4.常州贝特康姆软件技术有限公司：http://centos.bitcomm.cn/（只做CentOS镜像，当前已用容量估计：140GB）\r5.公云PubYun（母公司为贝特康姆）：http://mirrors.pubyun.com/\r6.Linux运维派：http://mirrors.skyshe.cn/（使用阿里云服务器，界面使用浙江大学的模板，首页维护，内容可访问）\r7.中国互联网络信息中心：http://mirrors.cnnic.cn/（只做Apache镜像，当前已用容量估计：120GB）\r8.Fayea工作室：http://apache.fayea.com/（只做Apache镜像，当前已用容量估计：120GB）\r9.开源中国社区 http://mirrors.oss.org.cn/\r软件版\r#\r\r操作系统类\r#\r\r# Ubuntu\r阿里云：http://mirrors.aliyun.com/ubuntu-releases/\r网易：http://mirrors.163.com/ubuntu-releases/\r搜狐：http://mirrors.sohu.com/ubuntu-releases/（搜狐在12年之后似乎不同步了）\r首都在线科技股份有限公司：http://mirrors.yun-idc.com/ubuntu-releases/\r# CentOS\r网易：http://mirrors.163.com/centos/\r搜狐：http://mirrors.sohu.com/centos/\r阿里云：http://mirrors.aliyun.com/centos/\r服务器类\r#\r\r# Apache\r中国互联网络信息中心：http://mirrors.cnnic.cn/apache/\r华中科技大学：http://mirrors.hust.edu.cn/apache/\r北京理工大学：http://mirror.bit.edu.cn/apache/\r# MySQL\r北京理工大学：http://mirror.bit.edu.cn/mysql/Downloads/\r中国电信天翼云：http://mirrors.ctyun.cn/Mysql/\r# PostgreSQL\r浙江大学：http://mirrors.zju.edu.cn/postgresql/\r# MariaDB\r中国电信天翼云：http://mirrors.ctyun.cn/MariaDB/\r# VideoLAN\r大连东软信息学院：http://mirrors.neusoft.edu.cn/videolan/\r中国科技大学：http://mirrors.ustc.edu.cn/videolan-ftp/\r开发工具类\r#\r\r# Eclipse\r中国科技大学：http://mirrors.ustc.edu.cn/eclipse/\r中国科学院：http://mirrors.opencas.cn/eclipse/\r东北大学：http://ftp.neu.edu.cn/mirrors/eclipse/，http://mirror.neu.edu.cn/eclipse/\r# 安卓SDK\r中国科学院：http://mirrors.opencas.ac.cn/android/repository/\r南洋理工学院：http://mirror.nyist.edu.cn/android/repository/\r中国科学院：http://mirrors.opencas.cn/android/repository/\r腾讯：http://android-mirror.bugly.qq.com:8080/android/repository/（限流，不推荐）\r大连东软信息学院：http://mirrors.neusoft.edu.cn/android/repository/（同步效果不如中科院的镜像，不推荐）\r# Xcode\r腾讯：http://android-mirror.bugly.qq.com:8080/Xcode/（从7.2之后不再更新，建议直接从官网下载）\r官方镜像列表状态地址\r#\r\rCentOS：http://mirror-status.centos.org/#cn Archlinux：https://www.archlinux.org/mirrors/status/ Ubuntu：https://launchpad.net/ubuntu/+cdmirrors Debian：http://mirror.debian.org/status.html Fedora Linux/Fedora EPEL：https://admin.fedoraproject.org/mirrormanager/mirrors Apache：http://www.apache.org/mirrors/#cn Cygwin：https://www.cygwin.com/mirrors.html "}),a.add({id:7,href:'/docs/golang/go-%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/',title:"多平台交叉编译",section:"Golang 基础",content:"多平台交叉编译\r#\r\rwindows\r#\r\rwindow平台下编译其他平台的程序文件，修改 go env 配置\nMac\r# go env SET CGO_ENABLED=0 SET GOOS=darwin SET GOARCH=amd64 Linux\r# go env SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 \r示例：go env -w CGO_ENABLED=0 GOOS=linux GOARCH=amd64\nLinux\r#\r\rLinux平台下编译其他平台的程序文件，修改 go env 配置\nMac\r# go env SET CGO_ENABLED=0 SET GOOS=darwin SET GOARCH=amd64 Windows\r# go env SET CGO_ENABLED=0 SET GOOS=windows SET GOARCH=amd64 \r示例：go env -w CGO_ENABLED=0 GOOS=windows GOARCH=amd64\nMac\r#\r\rMac平台下编译其他平台的程序文件，修改 go env 配置\nLinux\r# go env SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 Windows\r# go env SET CGO_ENABLED=0 SET GOOS=windows SET GOARCH=amd64 \r示例：go env -w CGO_ENABLED=0 GOOS=windows GOARCH=amd64\n"}),a.add({id:8,href:'/docs/golang/go-%E4%B8%AD%E7%9A%84%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E7%AD%96%E7%95%A5/',title:"错误处理策略",section:"Golang 基础",content:"Go 中的错误处理策略\r#\r\r一、传递错误\r#\r\r传递错误就是向函数的调用者传递错误。\n当函数返回错误时，调用者应该负责检查错误并采取合适的方式进行处理。\n 1.直接返回错误，不做任何的修改与包装\nreturn nil, err   2.对错误进行包装再返回\nif err != nil { return nil, fmt.Errorf(\u0026#34;parsing %s as HTML: %V\u0026#34;, url, err) }  包装error宗旨：错误信息能够提供一个从最根本问题到总体问题故障的清晰因果链\n1.包含充足的相关信息，并保持一致性\n2.传递过程中不断补充在处理错误可能需要的信息\n二、多次重试后，再传递错误\r#\r\r对于不固定和不可预测的错误，在短暂的间隔后再进行重试，超出重试次数和限定时间后再报错退出。\ngop1.io/ch5/wait\n// WaitForServer 尝试连接URL对应的服务器 // 在一分钟内使用指数退避策略进行重试 // 所有尝试失败后退出 func WaitForServer(url string) error { const timeout = 1 * time.Minute deadline := time.Now().Add(timeout) for tries := 0; time.Now().Before(deadline); tries ++ { _, err := http.Head(url) if err == nil { return nil // 成功  } log.Printf(\u0026#34;server not responding (%s); retrying...\u0026#34;, err) time.sleep(time.Second \u0026lt;\u0026lt; unit(tries)) // 指数退避策略 休眠2的n次方时间  } return fmt.Errorf(\u0026#34;server %s failed to respond after %s\u0026#34;, url, timeout) } 三、输出错误，并优雅的停止程序\r#\r\r如果对于多次重试后，仍然不能顺利进行下去，调用者能够输出错误然后优雅的停止程序。\n 这里的停止程序，应该要留给主程序部分来停止\n 举例：\n通常库函数应当传递错误给调用者，除非这个错误表示一个内部一致性的错误\nif err := WaitForServer(url); err != nil { fmt.FPrintf(os.Stderr, \u0026#34;Site is down: %v\\n\u0026#34;, err) os.Exit(1) } // 上述打印输出以及退出程序可以有代替方法 if err := WaitForServer(url); err != nil { log.Fatalf(\u0026#34;Site is down: %v\\n\u0026#34;, err) // 直接输出并退出，输出有时间等信息，并可定制输出格式 } 四、只记录错误，程序继续运行\r#\r\r使用log包来输出日志，可定制\nif err := Ping(); err != nil { log.Printf(\u0026#34;ping failed %v; networking disabled\u0026#34;, err) // log包的相关函数会自动添加换行 } 五、少数情况下，直接忽略日志\r#\r\ros.RemoveAll(dir) // 忽略错误，但是需要注释 忽略的意图 "}),a.add({id:9,href:'/docs/pxc/%E4%BC%98%E5%8C%96%E7%9B%B8%E5%85%B3/',title:"集群优化相关",section:"Pxc",content:"分页查询优化\r#\r\r这边先看几个简单例子：\n-- 查询优化 select * from t_test limit 100,100; -- 85ms select * from t_test limit 1000,100; -- 279ms select * from t_test limit 10000,100;	-- 2s31ms select * from t_test limit 100000,100; -- 19s497ms 怎么去优化呢？\n我们可以通过 explain 命令来查看，可关注type all为全表扫描，查看rows可以知道扫描数据row数\nmysql\u0026gt; explain select * from t_test limit 1000,100; +----+-------------+--------+------------+------+---------------+------+---------+------+---------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+---------------+------+---------+------+---------+----------+-------+ | 1 | SIMPLE | t_test | NULL | ALL | NULL | NULL | NULL | NULL | 4585371 | 100.00 | NULL | +----+-------------+--------+------------+------+---------------+------+---------+------+---------+----------+-------+ 1 row in set, 1 warning (0.00 sec) 如果使用条件where， type 为range 变成范围查询，并且使用主键，扫描的row数变少很多；\nmysql\u0026gt; explain select * from t_test where id\u0026gt;1000 limit 100; +----+-------------+--------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ | 1 | SIMPLE | t_test | NULL | range | PRIMARY | PRIMARY | 4 | NULL | 2292685 | 100.00 | Using where | +----+-------------+--------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ 1 row in set, 1 warning (0.01 sec) 直接使用where 条件过滤出数据，扫描行数才仅仅50\nmysql\u0026gt; explain select * from t_test where id\u0026gt;1000 and id\u0026lt; 1100; +----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+ | 1 | SIMPLE | t_test | NULL | range | PRIMARY | PRIMARY | 4 | NULL | 50 | 100.00 | Using where | +----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) 可知第三种方式应该是最优情况；\n但是第三种方式是否存在问题呢？如果说主键不连续的情况下，过滤的数据是否一定是刚好100条呢？\n答案是否定的，如果主键不连续，那就是少于100条数据。\n解决办法：采用逻辑删除\n如果物理删除时，这里也有一个折中办法。利用主键来加速。\nselect * from t_test t join (select id from t_test where id\u0026gt;100000 limit 100) t1 on t.id=t1.id; "})})()