'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href','section']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/docs/golang/',title:"Golang",section:"Docs",content:"Golang\n"}),a.add({id:1,href:'/docs/pxc/',title:"Pxc",section:"Docs",content:"目录 #  "}),a.add({id:2,href:'/posts/git-%E4%B9%8B-ssh-%E9%85%8D%E7%BD%AE/',title:"Git 之 SSH 配置",section:"Blog",content:"Git 之 SSH 配置 #  生成 ssh 密钥 #  ssh-keygen -t rsa -C \u0026#39;youremail@qq.com\u0026#39; # 可以不断回车跳过 # 如果有需求可以一步一步查看配置的内容 # 基本是关于密钥存放文件路径,以及密钥使用的时候需要的账户密码 配置ssh 公钥 #  比如:配置一个ssh公钥到github\n如图配置即可\n添加公钥\n"}),a.add({id:3,href:'/docs/golang/go-%E5%9F%BA%E7%A1%80/',title:"Go 基础",section:"Golang",content:"关键字 #  25个关键字\n break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var 37个保留字\nConstants:	true false iota nil Types:	int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr float32 float64 complex128 complex64 bool byte rune string error Functions:	make len cap new append copy close delete complex real imag panic recover 变量 #   WARNING\n函数外的每个语句都必须以关键字开始（var 、const、func、type等）\n:= 不能使用在函数外\n_ 多用于占位，标识忽略值\n 常量 #  iota\n INFO\niota 只用于常量声明中，大多用于枚举场景\niota 可以理解为：“批量声明变量时，const 变量的索引值”\n Example：\n// 常量的批量声明 const ( n1 = 100 // 100 	n2	// 100		n3	// 100	) // 引入 iota 关键字；可理解为计数器。每次递增 +1 // 只能使用在常量声明中，也可理解为 const 中常量声明的索引 const ( a = iota + 1 // 1 	b // 2 	c // 3 	d // 4 	e // 5 ) const ( aa = iota + 1 // 1 	bb = 100 // 100 	cc = iota // 2 	dd // 3 	ee // 4 ) // 出现 _ 占位符会跳过，但是 iota 计数器还是会计数 const ( aaa = iota + 100 // 100 	_ ccc // 102 	ddd // 103 	eee // 104 ) const ( aaaa, aaaaa = iota + 1, iota + 2 // 1, 2 	bbbb, bbbbb // 2, 3 	cccc, ccccc // 3, 4 	dddd, ddddd // 4, 5 	eeee, eeeee // 5, 6 ) const ( _ = iota KB = 1 \u0026lt;\u0026lt; (10 * iota) // 1024 = 2^10 2的10次方 	MB = 1 \u0026lt;\u0026lt; (10 * iota) // 1048576 = 2^20 	GB = 1 \u0026lt;\u0026lt; (10 * iota) // 1073741824 = 2^30 	TB = 1 \u0026lt;\u0026lt; (10 * iota) // 1099511627776 = 2^40 	PB = 1 \u0026lt;\u0026lt; (10 * iota) // 1125899906842624 = 2^50 ) 基本数据类型 #  整型\n两系类型： int* 和 uint*，对应有符号和无符号\n   类型 描述     uint8 无符号 8位整型 (0 到 255)   uint16 无符号 16位整型 (0 到 65535)   uint32 无符号 32位整型 (0 到 4294967295)   uint64 无符号 64位整型 (0 到 18446744073709551615)   int8 有符号 8位整型 (-128 到 127)   int16 有符号 16位整型 (-32768 到 32767)   int32 有符号 32位整型 (-2147483648 到 2147483647)   int64 有符号 64位整型 (-9223372036854775808 到 9223372036854775807)    特殊系：\n   类型 描述     uint 32位操作系统上就是uint32，64位操作系统上就是uint64   int 32位操作系统上就是int32，64位操作系统上就是int64   uintptr 无符号整型，用于存放一个指针     WARNING\n在使用 int 和 uint 时，要注意在不同的平台（32位与64位）所表示的区别差异\n内建函数len() 会根据平台来自动进行变化\n实际场景中，切片和map的元素数量都可以使用int来表示\n涉及到二进制传输、读写文件的结构描述时，为了保持文件的结构不会受到平台字节长度的影响，不要使用int和 uint\n 浮点型\nfloat32 和 float64\nvar ( // 最大值 	float32Max float32 = math.MaxFloat32 // 3.4028235e+38 	float64Max float64 = math.MaxFloat64 // 1.7976931348623157e+308  // 最小值 近似为1.4e-45和4.9e-324 ) 复数型\n常用开发使用很少\n布尔型\nfalse 和 true 分别对应 \u0026ldquo;真\u0026rdquo; 和 \u0026ldquo;假\u0026rdquo;\n WARNING\n布尔型的初始化值为 \u0026ldquo;false\u0026rdquo;（假）\nGo 语言中不允许 \u0026ldquo;布尔型\u0026rdquo; 与 \u0026ldquo;整型\u0026rdquo; 之间进行强制转换\n\u0026ldquo;布尔型\u0026rdquo; 与 \u0026ldquo;其他基础类型\u0026rdquo; 相互不能进行转换\n 字符串\nGo 语言中的字符串内部实现采用 UTF-8 编码（包含世界上大多数使用的文本字符）\n声明\nvar str string = \u0026#34;Hello World\u0026#34; var str1 = \u0026#34;Hello World\u0026#34; // 自动类型推导  func strDeclaration() { str2 := \u0026#34;Hello World\u0026#34; // 注意该方式声明不能用于包级域，需要用于函数内部  } 读取\nfunc strSub() { str := \u0026#34;Hello World\u0026#34; fmt.Println(len(str)) // 11 	fmt.Printf(\u0026#34;%#v\\n\u0026#34;, str[1]) // 0x65 	fmt.Printf(\u0026#34;%v\\n\u0026#34;, str[1]) // 101 	fmt.Printf(\u0026#34;%q\\n\u0026#34;, str[1]) // \u0026#39;e\u0026#39; 	fmt.Printf(\u0026#34;%c\\n\u0026#34;, str[1]) // e 	fmt.Printf(\u0026#34;%U\\n\u0026#34;, str[1]) // U+0065 }  WARNING\nlen() 返回的是字符串 字节数（并不是字符数）\n 转义字符\n   转义符 含义     \\a 响铃   \\b 退格   \\f 换页   \\r 回车符（返回行首）   \\n 换行符（直接跳到下一行的同列位置）   \\t 制表符   \\v 垂直制表符   \\' 单引号   \\\u0026quot; 双引号   \\\\ 反斜杠    Example：\n// window 下文件路径 fmt.Println(\u0026#34;file_path=\\\u0026#34;c:\\\\file\\\\x\\\\demo.go\\\u0026#34;\u0026#34;) // file_path=\u0026#34;c:\\file\\x\\name.go\u0026#34; 原生字符串面值\n字符串面值： 使用双引号\u0026quot;\u0026quot;包裹字节序列，如 \u0026quot;Hello World\u0026quot;\n原生字符串面值：使用反引号 ` 包裹字节序列，如 `Hello World`\nExample:\nconst STR = `一个原生的字符串面值形式是`...`，使用反引号代替 双引号。在原生的字符串面值中，没有转义操作；全部的内容都是字面 的意思，包含退格和换行，因此一个程序中的原生字符串面值可能跨越 多行（译注：在原生字符串面值内部是无法直接写字符的，可以用八进 制或十六进制转义或+\u0026#34;`\u0026#34;连接字符串常量完成）。唯一的特殊处理是会 删除回车以保证在所有平台上的值都是一样的，包括那些把回车也放入 文本文件的系统（译注：Windows系统会把回车和换行一起放入文本文件 中） --- Go语言程序设计 `  INFO\n用于编写 正则表达式，因为正则表达式往往会包含多个反斜杠来实现转义\n原生字符串面值同时被广泛应用于HTML模板、JSON面值、命令行提示信息以及那些需要扩展到多行的场景\n byte 与 rune\nbyte（uint8 别名类型）： 指的是 字节类型, 代表一个 ASCII 字符\nrune（int32 别名类型 ）： 指的是 字符类型, 代表 UTF-8 字符\n一个rune 字符可由一个或多个byte 字符组成\nExample:\nvar a byte = \u0026#39;a\u0026#39; fmt.Printf(\u0026#34;%T, %q\\n\u0026#34;, a, a) // uint8, \u0026#39;a\u0026#39;  var b rune = \u0026#39;你\u0026#39; fmt.Printf(\u0026#34;%T, %q\\n\u0026#34;, b, b) // int32, \u0026#39;你  c := \u0026#39;我\u0026#39; fmt.Printf(\u0026#34;%T, %q\\n\u0026#34;, c, c) // int32, \u0026#39;我\u0026#39;  字符串的遍历\nstr := \u0026#34;Hello, 中国\u0026#34; for i := 0; i \u0026lt; len(str); i++ { fmt.Printf(\u0026#34;%v[%c] \u0026#34;, str[i], str[i]) } fmt.Println() for _, v := range str { fmt.Printf(\u0026#34;%v[%c] \u0026#34;, v, v) } // output: // 72[H] 101[e] 108[l] 108[l] 111[o] 44[,] 32[ ] 228[ä] 184[¸] 173[­] 229[å] 155[ 189[½] // 72[H] 101[e] 108[l] 108[l] 111[o] 44[,] 32[ ] 20013[中] 22269[国] 从上面两种遍历字符串方式可以知道，由于 len(str) 返回的是字节长度，按字节来打印对于 \u0026ldquo;中\u0026rdquo; \u0026ldquo;国\u0026rdquo; （均为3个字节来表示）来说，等于是拆分为单个字节来打印，所以有写字节会出现乱码，而对于存在的 ASCII 码（0-255）会打印对应字符\n而 range 遍历才是遍历每一个字符\n字符串修改\n在字符串的定义中，字符串就是不能被修改的，一旦初始化，就不能更改\n这里提供一种修改方式\n可以先把字符串强制类型转换为 []rune 或 []byte，修改完成再转换为 字符串即可。但修改过后的字符串并不是原来字符串\nExample：\nstr := \u0026#34;Hello, 中国\u0026#34; midStr := []rune(str) midStr[0] = \u0026#39;你\u0026#39; midStr[1] = \u0026#39;好\u0026#39; str = string(midStr) fmt.Println(str) // \u0026#34;你好llo, 中国\u0026#34; 强制类型转换\nT(v)\nT 目标类型\nv 源值\n WARNING\nGo 语言中只有 显示 的类型转换\n 数组 #  定义\nvar 变量名 [元素数量]T\nExample:\nvar ary [5]int // [0, 0, 0, 0, 0]  WARING\n数组的类型包含： 数组长度和数组元素类型\nfmt.Printf(\u0026quot;%T\\n\u0026quot;, ary) // [5]int \n 初始化\n以默认值初始化\nvar array [5]int // [0, 0, 0, 0, 0] 初始化时使用大括号加逗号来表示数组元素\nvar array = [5]int{1,2,3,4,5} var array = [5]string{\u0026#34;H\u0026#34;,\u0026#34;e\u0026#34;,\u0026#34;l\u0026#34;,\u0026#34;l\u0026#34;,\u0026#34;o\u0026#34;} 初始化时，可以省略长度，使用 ... 来表示长度，编译器会自动推导\nvar array = [...]int{1,2,3,4,5} var array = [...]string{\u0026#34;H\u0026#34;,\u0026#34;e\u0026#34;,\u0026#34;l\u0026#34;,\u0026#34;l\u0026#34;,\u0026#34;o\u0026#34;} 使用索引值来表示元素的位置\nvar array = [...]string{1:\u0026#34;H\u0026#34;,2:\u0026#34;e\u0026#34;,3:\u0026#34;l\u0026#34;,5:\u0026#34;l\u0026#34;,7:\u0026#34;o\u0026#34;} 数组遍历\nfunc main() { var array = [5]string{\u0026#34;H\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;l\u0026#34;, \u0026#34;l\u0026#34;, \u0026#34;o\u0026#34;} // 方式一： 	for i := 0; i \u0026lt; len(array); i++ { fmt.Println(array[i]) } // 方式二： 	for i, v := range array { fmt.Println(i, v) } } 数组是值类型\n看下方示例，通过修改传入的数组的元素值，发现 arr 数组并没有发生改变；说明传入的是另外一个数组\nGo 中数组作为参数传入时，传入的是其拷贝后的副本\nfunc main() { // 数组是值类型 	arr := [...]string{\u0026#34;H\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;l\u0026#34;, \u0026#34;l\u0026#34;, \u0026#34;o\u0026#34;} modify(arr) fmt.Println(arr) // [H e l l o]  } func modify(a [5]string) { a[0] = \u0026#34;s\u0026#34; fmt.Println(a) // [s e l l o] } 切片 #  切片的扩容策略\n// 切片扩容 func growslice(et *_type, old slice, cap int) slice { newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { newcap = cap } else { if old.len \u0026lt; 1024 { newcap = doublecap } else { for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } if newcap \u0026lt;= 0 { newcap = cap } } } 上面一小段代码展示的就是扩容后容量的确定\n1.当期望的容量 cap 大于两倍的原始切片容量的大小时，新的容量就是cap\n2.当cap 不大于两个倍的原始容量时，且原始切片的长度小于 1024时，新容量则为 两倍原始切片容量\n3.当cap 不大于两个倍的原始容量时，且原始切片的长度大于等于1024时，新容量为在原始容量上再增加25%\n拷贝切片\ncopy(目标切片, 原始切片)\nfunc main() { a := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} c := make([]string, 5, 5) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, c) // []string{\u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;} 	copy(c, a) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, a) // []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} 	fmt.Printf(\u0026#34;%#v\\n\u0026#34;, c) // []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;} }  Warning\n切片的拷贝操作采用的是整体的内存拷贝，相比于逐一对元素的拷贝，性能要好\n但是对于很大的切片来说，拷贝性能也是需要关注的\n Example:\n给数组进行排序：var a = [\u0026hellip;]int{3, 7, 8, 9, 1}\nfunc main() { var b = [...]int{3, 7, 8, 9, 1} c := b[:] sort.Ints(c) for i, _ := range c { b[i] = c[i] } fmt.Printf(\u0026#34;%#v\\n\u0026#34;, b) } Map #  map 是 key-value 一种数据结构。\n定义\nmap[keyType]valueType\n// map类型声明 	var mapDemo map[string]string fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, mapDemo, mapDemo) // map[string]string(nil)  mapDemo1 := map[string]string{\u0026#34;Name\u0026#34;: \u0026#34;小明\u0026#34;, \u0026#34;Desc\u0026#34;: \u0026#34;这是一个map的Demo\u0026#34;} fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, mapDemo1, mapDemo1) // map[string]string{\u0026#34;Desc\u0026#34;:\u0026#34;这是一个map的Demo\u0026#34;, \u0026#34;Name\u0026#34;:\u0026#34;小明\u0026#34;}  var mapDemo2 = make(map[string]int, 5) fmt.Printf(\u0026#34;%T, %#v\\n\u0026#34;, mapDemo2, mapDemo2) // map[string]int, map[string]int{}  查看某个 key 是否存在\n// 查询某个key是否存在 	mapDemo3 := map[string]string{ \u0026#34;username\u0026#34;: \u0026#34;小王子\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123456\u0026#34;, } //v, ok := mapDemo3[\u0026#34;username\u0026#34;] 	v, ok := mapDemo3[\u0026#34;test\u0026#34;] if ok { fmt.Println(v) } else { fmt.Println(\u0026#34;没有这个key存在\u0026#34;) } map 遍历\n// 遍历map k-v 	mapDemo4 := make(map[string]int, 4) // 这里的 cap = 4 可以省略 	mapDemo4[\u0026#34;小明\u0026#34;] = 100 mapDemo4[\u0026#34;小红\u0026#34;] = 98 mapDemo4[\u0026#34;小王\u0026#34;] = 95 mapDemo4[\u0026#34;小张\u0026#34;] = 90 for k, v := range mapDemo4 { fmt.Println(k, v) } // 如果只遍历 map 的 k 	for k := range mapDemo4 { fmt.Println(k) } 删除某个key-value值\n// map 删除某个 key 	delete(mapDemo4, \u0026#34;小明\u0026#34;) fmt.Println(mapDemo4) 统计单词出现次数\n// \u0026#34;aa bb aa bb cc dd cc bb\u0026#34;  func count(s string) { if len(s) \u0026lt;= 0 { fmt.Println(\u0026#34;字符串为空……\u0026#34;) return } sSlice := strings.Split(s, \u0026#34; \u0026#34;) if len(sSlice) \u0026lt;= 1 { fmt.Printf(\u0026#34;%s=%d\\n\u0026#34;, sSlice[0], len(sSlice)) return } smap := make(map[string]int, len(sSlice)) fmt.Printf(\u0026#34;%#v\\n\u0026#34;, smap) for _, v := range sSlice { //_, ok := smap[v] 	//if ok { 	//	smap[v] += 1 	//} else { 	//	smap[v] = 1 	//} 	smap[v]++ } for k, v := range smap { fmt.Printf(\u0026#34;%s=%d\\n\u0026#34;, k, v) } } 考察切片扩容和append()\nfunc test() { type Map map[string][]int m := make(Map) s := []int{1, 2} s = append(s, 3) fmt.Printf(\u0026#34;%+v, %d, %d, %p\\n\u0026#34;, s, len(s), cap(s), s) // [1 2 3], 3, 4, 0xc0000101c0 	m[\u0026#34;demo\u0026#34;] = s s = append(s[:1], s[2:]...) fmt.Printf(\u0026#34;%+v, %d, %d, %p\\n\u0026#34;, s, len(s), cap(s), s) // [1 3], 2, 4, 0xc0000101c0 	fmt.Printf(\u0026#34;%+v\\n\u0026#34;, s) // []int{1,3} 	fmt.Printf(\u0026#34;%+v\\n\u0026#34;, m[\u0026#34;demo\u0026#34;]) // []int{1,3,3}  // 这里主要考察了 append() 函数，以及 切片扩容 	// 如果容量足够，则不会扩容，引用的底层数组是不会改变 	// 当容量不够时，扩容会导致生成新的数组，从而导致引用的数组为新创建的 	// 上述代码中，由于map key=demo 的值为 切片 s, 	// 虽然对s进行了一系列操作，但是并没有涉及扩容，所以对s进行操作同样适用于map的 	// 因为底层数组是同一个 } 函数 #  函数的类型\nimport \u0026#34;fmt\u0026#34; type calculat func(int, int) int // 定义的一个函数类型  func main() { var a calculat a = add // add 与 sub 满足 calculat 函数类型情况，所以可以赋值  fmt.Printf(\u0026#34;%T\\n\u0026#34;, a) fmt.Printf(\u0026#34;%T\\n\u0026#34;, add) // 通过a来调用函数add 	fmt.Println(a(1, 1)) // 2  } func add(x, y int) (s int) { s = x + y return } func sub(x, y int) (s int) { s = x - y return } 函数作为参数\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(mathClaculat(2, 2, sub)) } func add(x, y int) (s int) { s = x + y return } // 函数作为参数 func mathClaculat(x, y int, fn func(int, int) int) int { s := fn(x, y) return s } 函数作为返回值\nfunc returnFunc() func() { return func() { fmt.Println(\u0026#34;日志：我是作为返回值的函数\u0026#34;) } } 闭包\nfunc main() { // 闭包： 一个函数内部嵌入其他一个函数，内部的函数共享引用外部函数的变量，外部函数返回内部函数引用。 	f1, f2 := cal1(10) fmt.Println(f1(1), f2(2)) // 11, 9 	fmt.Println(f1(3), f2(4)) // 12, 8 	fmt.Println(f1(5), f2(6)) // 13, 7  f3, f4 := cal2(10) fmt.Println(f3(1), f4(2)) // 11, 8  fmt.Println(f3(3), f4(4)) // 13, 6  fmt.Println(f3(5), f4(6)) // 15, 4 } // 闭包1 func cal1(base int) (func(int) int, func(int) int) { return func(i int) int { base += i return base }, func(i int) int { base -= i return base } } // 闭包2 不共享外部函数域中的变量的方法 func cal2(base int) (func(int) int, func(int) int) { return func(i int) int { base := base // base 变为匿名函数的局部变量，所以外部函数的base 不会更改 	base += i fmt.Println(\u0026#34;我是闭包函数1\u0026#34;, base) return base }, func(i int) int { base := base base -= i fmt.Println(\u0026#34;我是闭包函数2\u0026#34;, base) return base } } 函数参数传递\n传递基本类型和数组作为参数\npackage main import \u0026#34;fmt\u0026#34; // 构建函数，打印传入参数变量的地址 func printArgs(i int, a [3]int) { fmt.Printf(\u0026#34;call printArgs -- i:%d %p; a:%v %p\\n\u0026#34;, i, \u0026amp;i, a, \u0026amp;a) } // 构建函数： 修改传入的参数比变量 func printArgsAndModify(i int, a [3]int) { i = 100 a[0] = 999 fmt.Printf(\u0026#34;call printArgsAndModify -- i:%d %p; a:%v %p\\n\u0026#34;, i, \u0026amp;i, a, \u0026amp;a) } func main() { i := 5 a := [3]int{1, 2, 3} fmt.Printf(\u0026#34;before call -- i:%d %p; a:%v %p\\n\u0026#34;, i, \u0026amp;i, a, \u0026amp;a) printArgs(i, a) printArgsAndModify(i, a) fmt.Printf(\u0026#34;after call -- i:%d %p; a:%v %p\\n\u0026#34;, i, \u0026amp;i, a, \u0026amp;a) // out: 	//before call -- i:5 0xc00000a098; a:[1 2 3] 0xc000012180 	//call printArgs -- i:5 0xc00000a0d0; a:[1 2 3] 0xc0000121b0 函数内部与外部地址不一样，说明函数参数的传递属于 “值传递” 	//call printArgsAndModify -- i:100 0xc00000a0d8; a:[999 2 3] 0xc0000121e0 更改传递参数并不会改变源变量 	//after call -- i:5 0xc00000a098; a:[1 2 3] 0xc000012180  } 传递结构体和结构体指针\npackage main import \u0026#34;fmt\u0026#34; // Mystruct 构建结构体： type Mystruct struct { num int } // 构建函数: 打印结构体和指针信息 func printStructAndPoint(s Mystruct, p *Mystruct) { s.num = 111 p.num = 999 fmt.Printf(\u0026#34;call printStructAndPoint -- s:%v %p; p:%v %p\\n\u0026#34;, s, \u0026amp;s, p, \u0026amp;p) } func main() { s := Mystruct{num: 100} p := \u0026amp;Mystruct{num: 200} fmt.Printf(\u0026#34;before call -- s:%v %p; p:%v %p\\n\u0026#34;, s, \u0026amp;s, p, \u0026amp;p) printStructAndPoint(s, p) fmt.Printf(\u0026#34;after call -- s:%v %p; p:%v %p\\n\u0026#34;, s, \u0026amp;s, p, \u0026amp;p) // out: 	//before call -- s:{100} 0xc00000a098; p:\u0026amp;{200} 0xc000006028 	//call printStructAndPoint -- s:{111} 0xc00000a0d0; p:\u0026amp;{999} 0xc000006038 传结构体会拷贝结构体全部内容，传指针会拷贝结构体指针，但是指针所指向的结构体并没拷贝 	//after call -- s:{100} 0xc00000a098; p:\u0026amp;{999} 0xc000006028 } ​\n"}),a.add({id:4,href:'/posts/homebrew/',title:"Homebrew",section:"Blog",content:"Homebrew #  homebrew 是 Mac os 下的管理软件,类似于ubuntu下的apt等,不用手动去管理依赖等问题.\n安装 #  我的系统: MacOs x86_64\n这里参考了 [Homebrew / Linuxbrew 镜像使用帮助](homebrew | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror) 来进行安装\n主要分为三步 #    配置环境变量\n终端输入以下几行命令设置环境变量\nif [[ \u0026#34;$(uname -s)\u0026#34; == \u0026#34;Linux\u0026#34; ]]; then BREW_TYPE=\u0026#34;linuxbrew\u0026#34;; else BREW_TYPE=\u0026#34;homebrew\u0026#34;; fi export HOMEBREW_BREW_GIT_REMOTE=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git\u0026#34; export HOMEBREW_CORE_GIT_REMOTE=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/${BREW_TYPE}-core.git\u0026#34; export HOMEBREW_BOTTLE_DOMAIN=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/${BREW_TYPE}-bottles\u0026#34;   下载安装\n# 从本镜像下载安装脚本并安装 Homebrew / Linuxbrew # 这里的安装可能需要花一些时间,主要看访问github仓库的情况 git clone --depth=1 https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/install.git brew-install /bin/bash brew-install/install.sh # 这里可以不删除,其中存在着卸载homebrew的程序,以便后续卸载  rm -rf brew-install # 也可从 GitHub 获取官方安装脚本安装 Homebrew / Linuxbrew. 我的测试失败,连接不上所以采用上一方式 /bin/bash -c \u0026#34;$(curl -fsSL https://github.com/Homebrew/install/raw/master/install.sh)\u0026#34;   配置brew的源\n替换brew程序本身的源\ngit -C \u0026#34;$(brew --repo)\u0026#34; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git 针对MacOs系统上的Homebrew\n# 手动设置 git -C \u0026#34;$(brew --repo homebrew/core)\u0026#34; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git git -C \u0026#34;$(brew --repo homebrew/cask)\u0026#34; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git git -C \u0026#34;$(brew --repo homebrew/cask-fonts)\u0026#34; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-fonts.git git -C \u0026#34;$(brew --repo homebrew/cask-drivers)\u0026#34; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-drivers.git git -C \u0026#34;$(brew --repo homebrew/cask-versions)\u0026#34; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-versions.git # 或使用下面的几行命令自动设置 BREW_TAPS=\u0026#34;$(brew tap)\u0026#34; for tap in core cask{,-fonts,-drivers,-versions}; do if echo \u0026#34;$BREW_TAPS\u0026#34; | grep -qE \u0026#34;^homebrew/${tap}\\$\u0026#34;; then # 将已有 tap 的上游设置为本镜像并设置 auto update # 注：原 auto update 只针对托管在 GitHub 上的上游有效 git -C \u0026#34;$(brew --repo homebrew/${tap})\u0026#34; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-${tap}.git git -C \u0026#34;$(brew --repo homebrew/${tap})\u0026#34; config homebrew.forceautoupdate true else # 在 tap 缺失时自动安装（如不需要请删除此行和下面一行） brew tap --force-auto-update homebrew/${tap} https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-${tap}.git fi done   还原brew官方源\n# brew 程序本身，Homebrew / Linuxbrew 相同 git -C \u0026#34;$(brew --repo)\u0026#34; remote set-url origin https://github.com/Homebrew/brew.git # 以下针对 macOS 系统上的 Homebrew BREW_TAPS=\u0026#34;$(brew tap)\u0026#34; for tap in core cask{,-fonts,-drivers,-versions}; do if echo \u0026#34;$BREW_TAPS\u0026#34; | grep -qE \u0026#34;^homebrew/${tap}\\$\u0026#34;; then git -C \u0026#34;$(brew --repo homebrew/${tap})\u0026#34; remote set-url origin https://github.com/Homebrew/homebrew-${tap}.git fi dones # 以下针对 Linux 系统上的 Linuxbrew git -C \u0026#34;$(brew --repo homebrew/core)\u0026#34; remote set-url origin https://github.com/Homebrew/linuxbrew-core.git # 重新设置 git 仓库 HEAD brew update-reset   使用 #  搜索软件 #  # 支持正则匹配搜索 brew search wget 安装软件 #  brew install software_name # 例如: 我安装 wget brew install wget 卸载软件 #  brew uninstall wget 升级软件 #  brew upgrade wget 查看所有安装的软件 #  brew list 升级 homebrew 本身 #  brew update "}),a.add({id:5,href:'/docs/linux/',title:"Linux",section:"Docs",content:"Linux 相关 #  "}),a.add({id:6,href:'/posts/%E5%AE%9A%E6%97%B6%E8%84%9A%E6%9C%AC%E6%9D%A5%E5%8E%BB%E6%9B%B4%E6%96%B0%E5%8D%9A%E5%AE%A2/',title:"Linux定时任务",section:"Blog",content:"定时脚本来去更新博客 #  每次写静态博客会存在github上面，虽然写完会进行手动推送到github，但是每次在服务器来去就觉得麻烦，所以就写个定时任务来帮我执行拉取更新命令\n先来介绍下cron #  ubuntu下的定时任务，能定期执行命令\n开始使用 #  查看cron是否运行 #  ps -ef|grep cron\nubuntu@VM-0-10-ubuntu:~$ ps -ef |grep cron root 970 1 0 Feb28 ? 00:00:21 /usr/sbin/cron -f ubuntu 23388 8185 0 22:51 pts/0 00:00:00 grep --color=auto cron # 如果没有运行可以运行 # sudo service cron start 编写脚本命令 #  vim pull.sh\n#!/bin/bash cd /home/ubuntu/blogs/root/ # /home/ubuntu/blogs/root/ 本地仓库 git pull chmod +x ./pull.sh 添加执行权限\n编写定时任务 #  sudo crontab -e\n# 一般开始会选择编辑器，一般选择vim就好，对应数字编号 ubuntu@VM-0-10-ubuntu:~$ sudo crontab -e Select an editor. To change later, run 'select-editor'. 1. /bin/nano \u0026lt;---- easiest 2. /usr/bin/vim.basic 3. /usr/bin/vim.tiny 4. /bin/ed */1 * * * * /usr/local/qcloud/stargate/admin/start.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; 0 0 * * * /usr/local/qcloud/YunJing/YDCrontab.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; # 每一行表示一个任务，语法如下 crontab 编写语法\n   * * * * * command     分（0~59） 时（0~23） 天（1~31） 月（1~12） 周（0~6） 命令    符号：\n “*” 表示任意值 “，”逗号表示可以填写多哥值，如2，4表示2或者4 “/”斜线一般配置“*”号使用，代表每隔多长时间  示例：\n（1）30 20 * * * commad 表示每天的20:30执行命令 （2）5 20 13,14 * * commad	表示每月的13日，14日20:5分执行命令 （3）0,10 10,12 * * * commad	表示每天10点至12点之间，隔10分钟执行命令 （4）/5 * * * commad	表示每5分钟执行命令\ncrontab定期的执行上述编辑的任务\n把上述编写的pull.sh加入文件\n# 在每天凌晨6：00进行执行任务 pull.sh * 6 * * * /home/ubuntu/blogs/pull.sh 生效 #  sudo service cron restart 重启\n"}),a.add({id:7,href:'/docs/pxc/load-data-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE/',title:"Load Data 数据导入",section:"Pxc",content:"LOAD DATA批量导入数据 #  导入环境 #  mycat + pxc\nmycat：数据切分\npxc：两个分片，每个分片只开启一个节点。（对于其他节点的数据同步，采用直接拷贝方式）\n数据源 #  采用golang编写，生成1000万行的简单数据，数据采用文本方式存储；\n1,测试数据 2,测试数据 3,测试数据 ... 10000000,测试数据 数据库表\nCREATE TABLE t_test ( id int NOT NULL, name varchar(200) NOT NULL, PRIMARY KEY (\u0026#39;id\u0026#39;) ) code\n/* 生成导入到数据库的数据； 对应数据库表字段 id name */ package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) const num = 10000000 func generate() { file, err := os.Create(\u0026#34;./data.txt\u0026#34;) if err != nil { fmt.Printf(\u0026#34;create file failed:[%v]\\n\u0026#34;, err) return } defer file.Close() buf := bufio.NewWriter(file) // 建立缓冲，减少IO次数，提高效率 	for i:=1; i\u0026lt;=num; i++ { _, err := buf.WriteString(fmt.Sprintf(\u0026#34;%d,测试数据\\n\u0026#34;, i)) //_, err := file.WriteString(fmt.Sprintf(\u0026#34;%d, 测试数据\\n\u0026#34;, i)) // 这种无缓冲方式较慢 	if err != nil { fmt.Printf(\u0026#34;WriteString failed:[%v]\\n\u0026#34;, err) return } } buf.Flush() // 注意，由于文件长度刚好不是默认缓冲的整数倍，所以n次写入后，需要主动写入不足缓冲大小的字节数； } func main() { startTime := time.Now() generate() fmt.Println(time.Since(startTime)) // 打印一下耗时，一般大概2s样子 } 切分数据，准备多个数据（批量导入）\nsplit -l 1000000 -d data.txt # 1000万数据按每100万来划分 # x00 x01 x02 x03 x04 x05 x06 x07 x08 x09 共10个文件 导入程序 #  导入数据使用命令\nLOAD DATA LOCAL INFILE \u0026#34;data.txt\u0026#34; INTO TABLE table_name FIELDS TERMINATED BY \u0026#39;,\u0026#39; OPTIONALLY ENCLOSED BY \u0026#39;\\\u0026#34;\u0026#39; LINES TERMINATED BY \u0026#39;\\\\n\u0026#39; -- data.txt 数据文件 -- table_name 表名 -- \u0026#39;,\u0026#39; 分隔符 -- \u0026#39;\\\u0026#34;\u0026#39; 忽略 双引号 -- \u0026#39;\\\\n\u0026#39; 换行 采用golang编写导入数据的程序\n/* 导入数据到 mysql 使用多个goroutine同时导入 */ package main import ( \u0026#34;database/sql\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var dir string var db *sql.DB var wg sync.WaitGroup func init() { // 通过参数获取文件夹路径 	flag.StringVar(\u0026amp;dir, \u0026#34;path\u0026#34;, \u0026#34;.\\\\\u0026#34;, \u0026#34;指定目录路径\u0026#34;) flag.Usage = func() { _, _ = fmt.Fprint(os.Stderr, `load: 这是使用多线程通过MySQL的LOAD DATA命令导入数据 数据源通过指定目录或者把该程序移植到数据源当前目录 Usage: `) flag.PrintDefaults() } } // initDB: 初始化数据连接 func initDB() (err error) { // dsn (database source name) 数据源 	//dsn := \u0026#34;admin:Mysql123456.@tcp(192.168.145.134:8066)/test\u0026#34; 	dsn := \u0026#34;admin:Mysql123456.@tcp(192.168.145.139:3306)/test\u0026#34; // open 验证参数是否正确，并不会建立实际的连接，db是一个连接对象，存储连接过程需要的相关信息 	db, err = sql.Open(\u0026#34;mysql\u0026#34;, dsn) if err != nil { return err } // 检测连接源dsn是否真实有效 	err = db.Ping() if err != nil { fmt.Printf(\u0026#34;[%s] dsn not aviliable: [%v]\\n\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;), err) return err } db.SetMaxOpenConns(3) // 设置连接池最大打开连接数 	db.SetMaxIdleConns(0) // 设置连接池中最大空闲连接 	db.SetConnMaxLifetime(5*time.Minute) // 设置连接的最大生成时间，超过该时间不可重用 	return nil } func loading(filePath string) { defer wg.Done() fmt.Println(filePath) mysql.RegisterLocalFile(filePath) sql_ := \u0026#34;LOAD DATA LOCAL INFILE \u0026#39;\u0026#34;+filePath+\u0026#34;\u0026#39; INTO TABLE t_test(id, name) FIELDS TERMINATED BY \u0026#39;,\u0026#39; OPTIONALLY ENCLOSED BY \u0026#39;\\\u0026#34;\u0026#39; LINES TERMINATED BY \u0026#39;\\\\n\u0026#39;\u0026#34; _, err := db.Exec(sql_) if err != nil { // 如果导入失败，如连接意外断开怎么重新恢复，再次导入 	fmt.Printf(\u0026#34;load file[%s] failed:[%v]\\n\u0026#34;, filepath.Base(filePath), err) return } log.Printf(\u0026#34;file[%s] 数据导入完成....\\n\u0026#34;, filepath.Base(filePath)) } func main() { startTime := time.Now() flag.Parse() // 初始化 db 	err := initDB() if err != nil{ fmt.Printf(\u0026#34;init db failed:[%v]\\n\u0026#34;, err) return } // 获取到导入文件的路径 	files, err := ioutil.ReadDir(dir) if err != nil { fmt.Printf(\u0026#34;read file list failed:[%v]\\n\u0026#34;, err) return } // 遍历所有的文件，开启goroutine来执行导入数据 	for i, v := range files { path := dir + \u0026#34;\\\\\\\\\u0026#34; + v.Name() // 这里注意再windows下的路径 \\ \\\\ 	// 如果文件夹目录下存在其他的文件时？ 如：load.exe 	if strings.Contains(path, \u0026#34;.exe\u0026#34;) { continue } // 开启一个goroutine执行导入 	wg.Add(1) go loading(path) } wg.Wait() // 等待所有goroutine结束  fmt.Println(\u0026#34;总耗时:\u0026#34;, time.Since(startTime)) } 导入测试 #  sql.DB采用默认设置 #  对sql.DB对象不进行任何的设置，即采用默认设置来导入。\nload file[x03] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[430]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x02] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[432]} was closed ,reason is [err:java.io.IOException: Broken pipe]] [mysql] 2020/12/21 17:26:28 packets.go:427: busy buffer load file[x00] failed:[commands out of sync. You can't run this command now] load file[x08] failed:[Error 1152: Connection {DataHost[192.168.145.131:3306],Schema[test],threadID[418]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x06] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[428]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x01] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[433]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x07] failed:[Error 1152: Connection {DataHost[192.168.145.131:3306],Schema[test],threadID[409]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x04] failed:[Error 1152: Backend connect Error, Connection{DataHost[192.168.145.135:3306],Schema[test]} refused] 2020/12/21 17:30:10 file[x09] 数据导入完成.... load file[x05] failed:[Error 1105: Backend connect Error, Connection{DataHost[192.168.145.135:3306],Schema[test]} refused] 总耗时： 11m9.7511593s 1000万 条数据 导入成功 200万 条；\n上述日志：连接被关闭，造成MyCat中报IO异常；可能由于虚拟机的配置太低不能应对大批量数据的导入；限制同时进行导入连接数量；\n对sql.DB进行配置 #  1\n// 设置 sql.DB db.SetMaxOpenConns(5) // 设置连接池最大打开连接数 db.SetMaxIdleConns(2) // 设置连接池中最大空闲连接 出现超时以及管道断开等现象\nload file[x00] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[446]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x02] failed:[Error 1152: Connection {DataHost[192.168.145.135:3306],Schema[test],threadID[447]} was closed ,reason is [sql timeout]] load file[x06] failed:[Error 1152: Connection {DataHost[192.168.145.131:3306],Schema[test],threadID[427]} was closed ,reason is [err:java.io.IOException: Broken pipe]] load file[x03] failed:[Error 1152: Connection {DataHost[192.168.145.131:3306],Schema[test],threadID[426]} was closed ,reason is [err:java.io.IOException: Broken pipe]] 2\n// 设置 sql.DB db.SetMaxOpenConns(3) // 设置连接池最大打开连接数 db.SetMaxIdleConns(1) // 设置连接池中最大空闲连接 [mysql] 2020/12/22 10:14:33 packets.go:36: unexpected EOF load file[x09] failed:[invalid connection] [mysql] 2020/12/22 10:14:33 packets.go:36: unexpected EOF load file[x01] failed:[invalid connection] [mysql] 2020/12/22 10:14:33 packets.go:36: unexpected EOF load file[x04] failed:[invalid connection] load file[x03] failed:[dial tcp 192.168.145.134:8066: connectex: No connection could be made because the target machine actively refused it.] load file[x07] failed:[dial tcp 192.168.145.134:8066: connectex: No connection could be made because the target machine actively refused it.] load file[x06] failed:[dial tcp 192.168.145.134:8066: connectex: No connection could be made because the target machine actively refused it.] load file[x00] failed:[dial tcp 192.168.145.134:8066: connectex: No connection could be made because the target machine actively refused it.] 3\ndb.SetMaxOpenConns(3) // 设置连接池最大打开连接数 db.SetMaxIdleConns(0) // 设置连接池中最大空闲连接 只有一个X09 文件的导入出现如下问题：\n2020/12/22 10:49:24 sql res: \u0026lt;nil\u0026gt; load file[x09] failed:[commands out of sync. You can\u0026#39;t run this command now] 到这里 1000万数据全部导入成功。\n使用3个连接去导入数据，并且这三个连接每导入完成即进行关闭（不保留空闲连接）\n"}),a.add({id:8,href:'/docs/pxc/percona-percona-xtradb-cluster/',title:"Percona 集群相关",section:"Pxc",content:"Percona 集群相关 #  Percona 数据库 #  准备工作 #  jemalloc-3.6.0-1. centos7 el7.x86_64.rpm\nPercona-Server-5.7.32-35-r5688520-el7-x86_64-bundle centos7.tar\n安装 #  解压.tar #  # 拷贝至目录 scp jemalloc-3.6.0-1. centos7 el7.x86_64.rpm Percona-Server-5.7.32-35-r5688520-el7-x86_64-bundle centos7.tar centos7.tar root@192.168.31.129:/home cd /home tar -xf Percona-Server-5.7.32-35-r5688520-el7-x86_64-bundle centos7.tar yum localinstall *.rpm 启动 #  systemctl start mysqld\n防火墙开放 3306 #  firewall-cmd --zone=public --add-port=3306/tcp --permanent 开放3306\n\u0026ndash;permanent： 永久生效，重启系统后依然生效\nfirewall-cmd --reload 重新导入配置\n修改数据库配置文件 #  vi /etc/my.cnf character_set_server = utf8 bind-address = 0.0.0.0 skip-name-resolve # 跳过dns解析，可解决在云上安装后运行慢的情况 重启mysql systemctl restart mysqld\n禁用开机mysql自动启动 #  chkconfig mysqld off\nNote: Forwarding request to \u0026#39;systemctl disable mysqld.service\u0026#39;. Removed symlink /etc/systemd/system/multi-user.target.wants/mysqld.service. Removed symlink /etc/systemd/system/mysql.service. 原因： 当某个节点宕机时间过长时，如果随系统自动启动后，会同步宕机时间内更新的数据，如果时间过长，pxc集群会限制其它的写入操作，直到所有的数据全部同步完成，所以禁用开机自启是必要的。\n**正确做法：**从其它节点拷贝数据文件到当前节点里面，然后再去启动数据库。\n修改数据库root密码 #  cat /var/log/mysqld.log | grep \u0026quot;A temporary password\u0026quot; 查看root默认密码\nmysql_secure_installation\npassword: Mysql123456.\n[root@mysql-first ~]# mysql_secure_installation Securing the MySQL server deployment. Enter password for user root: The existing password for the user account root has expired. Please set a new password. New password: Re-enter new password: The \u0026#39;validate_password\u0026#39; plugin is installed on the server. The subsequent steps will run with the existing configuration of the plugin. Using existing password for root. Estimated strength of the password: 100 Change the password for root ? ((Press y|Y for Yes, any other key for No) : y New password: Re-enter new password: Sorry, passwords do not match. New password: Re-enter new password: Estimated strength of the password: 100 Do you wish to continue with the password provided?(Press y|Y for Yes, any other key for No) : y By default, a MySQL installation has an anonymous user, allowing anyone to log into MySQL without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? (Press y|Y for Yes, any other key for No) : y Success. Normally, root should only be allowed to connect from \u0026#39;localhost\u0026#39;. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? (Press y|Y for Yes, any other key for No) : y Success. By default, MySQL comes with a database named \u0026#39;test\u0026#39; that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? (Press y|Y for Yes, any other key for No) : y - Dropping test database... Success. - Removing privileges on test database... Success. Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? (Press y|Y for Yes, any other key for No) : y Success. All done! 创建远程连接账户 #  mysql -uroot -pMysql123456. mysql\u0026gt; create user \u0026#39;admin\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;Mysql123456.\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; grant all privileges on *.* to \u0026#39;admin\u0026#39;@\u0026#39;%\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) 忘记root密码 #   编辑数据库配置文件  vi /etc/my.cnf\n# 添加一行 skip-grant-tables 重启数据库  systemctl restart mysqld\nmysql命令直接进入数据库，并修改root密码为：Mysql12345.  mysql mysql\u0026gt; use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql\u0026gt; UPDATE user SET authentication_string = password(\u0026#39;Mysql12345.\u0026#39;) where User=\u0026#39;root\u0026#39;; Query OK, 1 row affected, 1 warning (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 1 mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) Percona XtraDB Cluster 集群 #  准备工作 #  删除 mariadb-libs #  yum -y remove mari* 卸载 mari 开头的全部程序包，避免影响PXC集群的安装\n开放PXC 依赖的端口 #     端口 描述     3306 MySQL服务端口   4444 请求全量同步（SST）端口，会引发集群限速，尽量避免   4567 数据库节点之间通信端口   4568 请求增量同步（IST）端口，平时节点同步采用方式    firewall-cmd --zone=public --add-port=3306/tcp --add-port=4444/tcp --add-port=4567/tcp --add-port=4568/tcp --permanent firewall-cmd --reload 关闭SELINUX #  Linux安全程序会影响PXC的运行，配置 SELINUX=disabled\nvi /etc/selinux/config\n# This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. # SELINUX=enforcing  SELINUX = disabled # 更改行 # SELINUXTYPE= can take one of three values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted reboot 重启生效\npkg包 #  Percona-XtraDB-Cluster-5.7.31-31.45-r10-el7-x86_64-bundle.tar 包含了percona数据库\nqpress-11-1.el7.x86_64.rpm\nPercona-XtraBackup-2.4.21-r5988af5-el7-x86_64-bundle.tar\n安装 #  拷贝至 /home 目录 #  scp qpress-11-1.el7.x86_64.rpm Percona-XtraDB-Cluster-5.7.31-31.45-r10-el7-x86_64-bundle.tar centos7.tar Percona-XtraBackup-2.4.21-r5988af5-el7-x86_64-bundle.tar root@192.168.31.129:/home\ncd /home [root@localhost home]# tar -xf Percona-XtraBackup-2.4.21-r5988af5-el7-x86_64-bundle.tar [root@localhost home]# tar -xf Percona-XtraDB-Cluster-5.7.31-31.45-r10-el7-x86_64-bundle.tar yum localinstall *.rpm 初始化工作 #  修改/etc/my.cnf #  vi /etc/my.cnf\n# # The Percona XtraDB Cluster 5.7 configuration file. # # # * IMPORTANT: Additional settings that can override those from this file! # The files must end with \u0026#39;.cnf\u0026#39;, otherwise they\u0026#39;ll be ignored. # Please make any edits and changes to the appropriate sectional files # included below. # !includedir /etc/my.cnf.d/ !includedir /etc/percona-xtradb-cluster.conf.d/ # 去目录下查看  cd /etc/percona-xtradb-cluster.conf.d/\n-rw-r--r--. 1 root root 381 Oct 20 15:57 mysqld.cnf # mysql配置文件 -rw-r--r--. 1 root root 440 Oct 20 15:57 mysqld_safe.cnf -rw-r--r--. 1 root root 1.1K Oct 20 15:57 wsrep.cnf # 集群配置文件 把该目录下的mysql配置文件更新到 /etc/my.cnf\n# Template my.cnf for PXC # Edit to your requirements. [client] socket=/var/lib/mysql/mysql.sock [mysqld] server-id=1 datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid log-bin log_slave_updates expire_logs_days=7 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 修改root用户密码 #  参考Percona数据库安装中方式\n创建远程连接账户 #  参考Percona数据库安装中方式\n禁用开机自启动 #  参考Percona数据库安装中方式\n配置集群相关配置 #  pcx01 节点配置\nserver-id=1 #PXC集群中MySQL实例的唯一ID，不能重复，必须是数字 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so wsrep_cluster_name=pxc-cluster #PXC集群的名称 PXC集群节点的IP wsrep_cluster_address=gcomm://192.168.145.131,192.168.145.132,192.168.145.133 # pxc集群节点ip wsrep_node_name=pxc01 #当前节点的名称 wsrep_node_address=192.168.145.131 #当前节点的IP wsrep_sst_method=xtrabackup-v2 #同步方法(mysqldump、rsync、xtrabackup) wsrep_sst_auth= admin:Mysql123456. #同步使用的帐户 pxc_strict_mode=ENFORCING #同步严厉模式 binlog_format=ROW #基于ROW复制(安全可靠) default_storage_engine=InnoDB #默认引擎 innodb_autoinc_lock_mode=2 #主键自增长不锁表 pcx02 节点配置\nserver-id=2 #PXC集群中MySQL实例的唯一ID，不能重复，必须是数字 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so wsrep_cluster_name=pxc-cluster #PXC集群的名称 PXC集群节点的IP wsrep_cluster_address=gcomm://192.168.145.131,192.168.145.132,192.168.145.133 # pxc集群节点ip wsrep_node_name=pxc02 #当前节点的名称 wsrep_node_address=192.168.145.132 #当前节点的IP wsrep_sst_method=xtrabackup-v2 #同步方法(mysqldump、rsync、xtrabackup) wsrep_sst_auth= admin:Mysql123456. #同步使用的帐户 pxc_strict_mode=ENFORCING #同步严厉模式 binlog_format=ROW #基于ROW复制(安全可靠) default_storage_engine=InnoDB #默认引擎 innodb_autoinc_lock_mode=2 #主键自增长不锁表 pcx03 节点配置\nserver-id=3 #PXC集群中MySQL实例的唯一ID，不能重复，必须是数字 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so wsrep_cluster_name=pxc-cluster #PXC集群的名称 PXC集群节点的IP wsrep_cluster_address=gcomm://192.168.145.131,192.168.145.132,192.168.145.133 # pxc集群节点ip wsrep_node_name=pxc03 #当前节点的名称 wsrep_node_address=192.168.145.133 #当前节点的IP wsrep_sst_method=xtrabackup-v2 #同步方法(mysqldump、rsync、xtrabackup) wsrep_sst_auth= admin:Mysql123456. #同步使用的帐户 pxc_strict_mode=ENFORCING #同步严厉模式 binlog_format=ROW #基于ROW复制(安全可靠) default_storage_engine=InnoDB #默认引擎, 只支持InnoDB innodb_autoinc_lock_mode=2 #主键自增长不锁表 分别在各个节点上，向/etc/my.cnf 中添加如上配置\npxc01\n[client] socket=/var/lib/mysql/mysql.sock [mysqld] character_set_server = utf8 bind-address = 0.0.0.0 skip-name-resolve # 跳过dns解析，可解决在云上安装后运行慢的情况 server-id=1 datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid log-bin log_slave_updates expire_logs_days=7 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 wsrep_provider=/usr/lib64/galera3/libgalera_smm.so wsrep_cluster_name=pxc-cluster #PXC集群的名称 PXC集群节点的IP wsrep_cluster_address=gcomm://192.168.145.131,192.168.145.132,192.168.145.133 # pxc集群节点ip wsrep_node_name=pxc01 #当前节点的名称 wsrep_node_address=192.168.145.131 #当前节点的IP wsrep_sst_method=xtrabackup-v2 #同步方法(mysqldump、rsync、xtrabackup) wsrep_sst_auth= admin:Abc_123456 #同步使用的帐户 pxc_strict_mode=ENFORCING #同步严厉模式 binlog_format=ROW #基于ROW复制(安全可靠) default_storage_engine=InnoDB #默认引擎 innodb_autoinc_lock_mode=2 #主键自增长不锁表 pxc02 pxc03 类似。\n集群初次启动 #  关闭各节点的msyql服务 #  systemctl stop mysql\n构建集群 #  从所有节点中选择一个节点，这里选择pxc01(192.168.145.131)\nsystemctl start mysql@bootstrap.service\n启动其他节点 #  service mysql start\n[root@pxc02 home]# systemctl status mysql.service ● mysql.service - Percona XtraDB Cluster Loaded: loaded (/usr/lib/systemd/system/mysql.service; disabled; vendor preset: disabled) Active: failed (Result: exit-code) since Thu 2020-11-26 16:18:08 CST; 3min 12s ago Process: 7624 ExecStopPost=/usr/bin/mysql-systemd stop-post (code=exited, status=0/SUCCESS) Process: 7595 ExecStop=/usr/bin/mysql-systemd stop (code=exited, status=2) Process: 6608 ExecStartPost=/usr/bin/mysql-systemd start-post $MAINPID (code=exited, status=1/FAILURE) Process: 6607 ExecStart=/usr/bin/mysqld_safe --basedir=/usr (code=exited, status=1/FAILURE) Process: 6538 ExecStartPre=/usr/bin/mysql-systemd start-pre (code=exited, status=0/SUCCESS) Main PID: 6607 (code=exited, status=1/FAILURE) Nov 26 16:18:08 pxc02 mysql-systemd[6608]: ERROR! mysqld_safe with PID 6607 has already exited: FAILURE Nov 26 16:18:08 pxc02 systemd[1]: mysql.service: control process exited, code=exited status=1 Nov 26 16:18:08 pxc02 mysql-systemd[7595]: WARNING: mysql pid file /var/run/mysqld/mysqld.pid empty or not readable Nov 26 16:18:08 pxc02 mysql-systemd[7595]: ERROR! mysql already dead Nov 26 16:18:08 pxc02 systemd[1]: mysql.service: control process exited, code=exited status=2 Nov 26 16:18:08 pxc02 mysql-systemd[7624]: WARNING: mysql pid file /var/run/mysqld/mysqld.pid empty or not readable Nov 26 16:18:08 pxc02 mysql-systemd[7624]: WARNING: mysql may be already dead Nov 26 16:18:08 pxc02 systemd[1]: Failed to start Percona XtraDB Cluster. Nov 26 16:18:08 pxc02 systemd[1]: Unit mysql.service entered failed state. Nov 26 16:18:08 pxc02 systemd[1]: mysql.service failed. 启动失败；经查找原因是 构建节点的配置文件中\nwsrep_sst_auth= admin:Mysql123456.  是密码配置不对\n测试集群是否搭建成功 #  连接任意集群节点，执行下面SQL\nshow status like 'wsrep_cluster%'\n输出如下：\n   Variable_name Value Comment     wsrep_cluster_weight 3 节点权重   wsrep_cluster_conf_id 3 集群成员更改总数   wsrep_cluster_size 3 集群大小   wsrep_cluster_state_uuid 85ab08a0-2fbc-11eb-b645-67acc08322c2    wsrep_cluster_status Primary     集群状态参数 #  节点同步相关 #     Variable_name Comment     wsrep_last_applied 最后一次应用的事务的序列号   wsrep_last_committed 最后提交的事务的序列号   wsrep_replicated 复制的写集总数（发送到其他节点）   wsrep_replicated_bytes 复制的写集的总大小   wsrep_received 从其他节点接收的写集总数（当前节点接收的同步次数）   wsrep_received_bytes 从其他节点收到的写集的总大小（以字节为单位）    队列相关 #     Variable_name Comment     wsrep_local_send_queue 发送队列的当前长度（即，等待发送的写集的数量）   wsrep_local_send_queue_avg 自上次状态查询以来发送队列的平均长度。当群集遇到网络吞吐量问题或复制限制时，该值将大大大于0。   wsrep_local_send_queue_max 发送队列的最大长度   wsrep_local_send_queue_min 发送队列的最小长度   wsrep_local_recv_queue 接收队列的当前长度（即，等待应用的写集的数量）   wsrep_local_recv_queue_avg 自上次状态查询以来接收队列的平均长度，当大于0表示队列过载，会造成复制限制   wsrep_local_recv_queue_max 接收队列的最大长度   wsrep_local_recv_queue_min,0 接收队列的最小长度    流量控制相关 #     Variable_name Comment     wsrep_flow_control_paused_ns 在暂停状态下花费的总时间（以纳秒为单位），流控时间   wsrep_flow_control_paused 自上次状态查询以来，由于流控制而暂停的时间。（占比0-1），流控的时间占比   wsrep_flow_control_sent 发送的流控暂停的事件数量，指节点发出流控命令   wsrep_flow_control_recv 收到的流控暂停的事件数量，指节点收到流控命令   wsrep_flow_control_interval 此变量显示Galera流量控制的下限和上限。上限是队列中允许的最大请求数。如果队列达到上限则拒绝新请求引发流控。随着现有请求的处理队列减少，并且一旦达到下限，将再次允许新请求   wsrep_flow_control_status 流量控制状态（off 表示流控关闭，on表示流控开启）    怎样避免流量控制：\n1.改善网速，提高带宽；升级网卡带宽\n2.增加线程数，提高同步效率\n​	在配置文件中增加，线程数一般是CPU线程数的1-1.5倍；\n​ wsrep_slave_threads=16\n3.升级计算机性能，如CPU 内存 硬盘\n节点与集群的相关 #     Variable_name Comment     wsrep_local_state_comment 节点状态   wsrep_cluster_status 集群状态   wsrep_connected 节点与集群连接状态   wsrep_ready 此变量显示节点是否准备好接受查询   wsrep_cluster_size 节点数量   wsrep_desync_count 延时节点数量   wsrep_incoming_addresses 集群节点的ip    事物相关 #     Variable_name Comment     wsrep_cert_deps_distance 最高和最低序号之间的平均距离，可以并行应用。事物执行并发数   wsrep_apply_oooe 此变量显示并行化效率，无序应用写入集的频率；接收队列中事物的占比   wsrep_apply_oool 变量显示具有较高序列号的写集在具有较低序列号的写集之前应用的频率。接收队列中事物乱序执行的频率   wsrep_apply_window 最高和最低同时应用序列号之间的平均距离；接收队列中事物的平均数量   wsrep_commit_oooe 此变量显示事务无序提交的频率。发送队列中事物的占比   wsrep_commit_oool 当前无意义   wsrep_commit_window 最高和最低同时提交序列号之间的平均距离。发送队列中事物的平均数量    具体示例 #  wsrep_apply_oooe,0.000000 wsrep_apply_oool,0.000000 wsrep_apply_window,1.000000 wsrep_causal_reads,0 wsrep_cert_bucket_count,22 wsrep_cert_deps_distance,1.000000 wsrep_cert_index_size,3 wsrep_cert_interval,0.000000 wsrep_cluster_conf_id,9 wsrep_cluster_size,3 wsrep_cluster_state_uuid,85ab08a0-2fbc-11eb-b645-67acc08322c2 wsrep_cluster_status,Primary wsrep_cluster_weight,3 wsrep_commit_oooe,0.000000 wsrep_commit_oool,0.000000 wsrep_commit_window,1.000000 wsrep_connected,ON wsrep_desync_count,0 wsrep_evs_delayed,\u0026#34;\u0026#34; wsrep_evs_evict_list,\u0026#34;\u0026#34; wsrep_evs_repl_latency,0/0/0/0/0 wsrep_evs_state,OPERATIONAL wsrep_flow_control_interval,\u0026#34;[ 173, 173 ]\u0026#34; wsrep_flow_control_interval_high,173 wsrep_flow_control_interval_low,173 wsrep_flow_control_paused,0.000000 wsrep_flow_control_paused_ns,0 wsrep_flow_control_recv,0 wsrep_flow_control_sent,0 wsrep_flow_control_status,OFF wsrep_gcache_pool_size,3704 wsrep_gcomm_uuid,118e17ce-2fc1-11eb-9f3f-cfb115f418ee wsrep_incoming_addresses,\u0026#34;192.168.145.131:3306,192.168.145.132:3306,192.168.145.133:3306\u0026#34; wsrep_ist_receive_seqno_current,0 wsrep_ist_receive_seqno_end,0 wsrep_ist_receive_seqno_start,0 wsrep_ist_receive_status,\u0026#34;\u0026#34; wsrep_last_applied,6 wsrep_last_committed,6 wsrep_local_bf_aborts,0 wsrep_local_cached_downto,1 wsrep_local_cert_failures,0 wsrep_local_commits,0 wsrep_local_index,0 wsrep_local_recv_queue,0 wsrep_local_recv_queue_avg,0.176471 wsrep_local_recv_queue_max,2 wsrep_local_recv_queue_min,0 wsrep_local_replays,0 wsrep_local_send_queue,0 wsrep_local_send_queue_avg,0.000000 wsrep_local_send_queue_max,1 wsrep_local_send_queue_min,0 wsrep_local_state,4 wsrep_local_state_comment,Synced wsrep_local_state_uuid,85ab08a0-2fbc-11eb-b645-67acc08322c2 wsrep_open_connections,0 wsrep_open_transactions,0 wsrep_protocol_version,9 wsrep_provider_name,Galera wsrep_provider_vendor,Codership Oy \u0026lt;info@codership.com\u0026gt; wsrep_provider_version,3.45(ra60e019) wsrep_ready,ON wsrep_received,34 wsrep_received_bytes,5976 wsrep_repl_data_bytes,0 wsrep_repl_keys,0 wsrep_repl_keys_bytes,0 wsrep_repl_other_bytes,0 wsrep_replicated,0 wsrep_replicated_bytes,0 集群的关闭与启动 #  安全关闭 #  启动 #  集群构建节点：systemctl start mysql@bootstrap.service\n普通节点启动：service mysql start  or systemctl start mysql\n关闭 #  节点怎么启动，就使用对应命令关闭\n集群构建节点的关闭：systemctl stop mysql@bootstrap.service\n普通节点的关闭：service mysql stop\n启动与关闭相关参数 #  /var/lib/mysql/grastate.dat\n# GALERA saved state version: 2.1 uuid: 85ab08a0-2fbc-11eb-b645-67acc08322c2 seqno: -1 safe_to_bootstrap: 0 # 如果为 1 当前节点需要作为集群构建节点启动 启动顺序：\n 当集群中所有节点均正常关闭时，集群会把最后正常关闭的节点的参数进行设置 safe_to_boostrap:1，因为该节点的数据是最新的，再次启动集群时，需要通过集群的构建节点方式优先启动该节点。 当整个集群均同时非正常关闭，造成集群不能设置某个节点作为集群构建节点启动时，需要手动设置某个节点的参数safe_to_boostrap:1，然后通 过构建节点启动方式启动。其他节点按普通方式启动加入集群。举个例子：当通过vmware同时进行关机时，虚拟机构建的节点会同时关闭，没有足够的时间进行safe_to_boostrap:1 设置。  节点关闭对集群的影响 #   当集群中超过半数的节点非正常关闭时，会造成集群所有的节点都停止服务；如果是属于正常关闭，则不会。 非正常关闭节点时，集群参数 wsrep_cluster_size 不会随节点的减少而改变  MySQL集群中间件 #  为什么还需要集群中间件？ #  中间件的作用主要是用于负载均衡，读写分离，数据切分(mysql数据库单表超2000万记录，读写性能会变差)等。\n负载均衡：Haproxy，MySQL-Proxy\n数据切分：MyCat ，Atlas，OneProxy，ProxySQL\n中间件对比 #      MyCat Atlas One_Proxy Proxy SQL     是否开源 开源（基于阿里巴巴的Corba中间件）部署在3000台服务器上，每天执行50亿次请求 基于My\u0026rsquo;SQL Proxy，主要用于360产品，每天承载几十亿次请求  开源免费   基于环境 JAVA      跨平台 是      功能 分片算法丰富，读写分离，全局主键，分布式事务 读写分析，少量的数据切分算法，不支持全局主键，分布式事务  性能出众，Perconna推荐，支持读写分离和数据切分，功能较基础   社区 活跃 无社区，无出版物，资料少  资料较多    MyCat #  准备工作 #  JDK：java-1.8.0-openjdk-devel.x86_64  (MyCat基于java开发)\nMyCat: Mycat-server-1.6.5-release-20180122220033-linux.tar.gz\n开放端口：8066（mycat数据服务） 和 9066（mycat管理端口）\nfirewall-cmd --zone=public --add-port=8066/tcp --add-port=9066/tcp --permanent firewall-cmd --reload 关闭SELINUX：关闭SELINUX请参考其他安装\n安装jdk #  yum install java-1.8.0-openjdk-devel.x86_64 \n环境配置\npath环境自动配置完成；\nJAVA_HOME配置：\nls -lrt /etc/alternatives/java ··· 输出 lrwxrwxrwx. 1 root root 73 Nov 30 15:28 /etc/alternatives/java -\u0026gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el7_9.x86_64/jre/bin/java ··· vi /etc/profile	··· 添加如下内容 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-1.el7_9.x86_64/ ··· source /etc/profile 安装mycat #  tar -xf Mycat-server-1.6.5-release-20180122220033-linux.tar.gz\ndrwxr-xr-x. 2 root root 190 Dec 1 11:30 bin drwxrwxrwx. 2 root root 6 Mar 1 2016 catlet drwxrwxrwx. 4 root root 4096 Dec 1 11:47 conf drwxr-xr-x. 2 root root 4096 Dec 1 11:30 lib drwxrwxrwx. 2 root root 6 Jan 22 2018 logs -rwxrwxrwx. 1 root root 219 Jan 22 2018 version.txt MyCat配置文件 #  server.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- - - Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); - you may not use this file except in compliance with the License. - You may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 - - Unless required by applicable law or agreed to in writing, software - distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the License for the specific language governing permissions and - limitations under the License. --\u0026gt; \u0026lt;!DOCTYPE mycat:server SYSTEM \u0026#34;server.dtd\u0026#34;\u0026gt; \u0026lt;mycat:server xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;system\u0026gt; \u0026lt;property name=\u0026#34;nonePasswordLogin\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户--\u0026gt; \u0026lt;property name=\u0026#34;useHandshakeV10\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;useSqlStat\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启实时统计、0为关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useGlobleTableCheck\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 1为开启全加班一致性检测、0为关闭 --\u0026gt; \u0026lt;property name=\u0026#34;sequnceHandlerType\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;subqueryRelationshipCheck\u0026#34;\u0026gt;false\u0026lt;/property\u0026gt; \u0026lt;!-- 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false --\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;useCompression\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--1为开启mysql压缩协议--\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;fakeMySQLVersion\u0026#34;\u0026gt;5.6.20\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--设置模拟的MySQL版本号--\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;processorBufferChunk\u0026#34;\u0026gt;40960\u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;processors\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;processorExecutor\u0026#34;\u0026gt;32\u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena | type 2 NettyBufferPool --\u0026gt; \u0026lt;property name=\u0026#34;processorBufferPoolType\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!--默认是65535 64K 用于sql解析时最大文本长度 --\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;maxStringLiteralLength\u0026#34;\u0026gt;65535\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;sequnceHandlerType\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;backSocketNoDelay\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;frontSocketNoDelay\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;processorExecutor\u0026#34;\u0026gt;16\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;serverPort\u0026#34;\u0026gt;8066\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;managerPort\u0026#34;\u0026gt;9066\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;idleTimeout\u0026#34;\u0026gt;300000\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;bindIp\u0026#34;\u0026gt;0.0.0.0\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;frontWriteQueueSize\u0026#34;\u0026gt;4096\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;processors\u0026#34;\u0026gt;32\u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志--\u0026gt; \u0026lt;property name=\u0026#34;handleDistributedTransactions\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- off heap for merge/order/group/limit 1开启 0关闭 --\u0026gt; \u0026lt;property name=\u0026#34;useOffHeapForMerge\u0026#34;\u0026gt;1\u0026lt;/property\u0026gt; \u0026lt;!-- 单位为m --\u0026gt; \u0026lt;property name=\u0026#34;memoryPageSize\u0026#34;\u0026gt;64k\u0026lt;/property\u0026gt; \u0026lt;!-- 单位为k --\u0026gt; \u0026lt;property name=\u0026#34;spillsFileBufferSize\u0026#34;\u0026gt;1k\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;useStreamOutput\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt; \u0026lt;!-- 单位为m --\u0026gt; \u0026lt;property name=\u0026#34;systemReserveMemorySize\u0026#34;\u0026gt;384m\u0026lt;/property\u0026gt; \u0026lt;!--是否采用zookeeper协调切换 --\u0026gt; \u0026lt;property name=\u0026#34;useZKSwitch\u0026#34;\u0026gt;false\u0026lt;/property\u0026gt; \u0026lt;!-- XA Recovery Log日志路径 --\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;XARecoveryLogBaseDir\u0026#34;\u0026gt;./\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;!-- XA Recovery Log日志名称 --\u0026gt; \u0026lt;!--\u0026lt;property name=\u0026#34;XARecoveryLogBaseName\u0026#34;\u0026gt;tmlog\u0026lt;/property\u0026gt;--\u0026gt; \u0026lt;/system\u0026gt; \u0026lt;!-- 全局SQL防火墙设置 --\u0026gt; \u0026lt;!--白名单可以使用通配符%或着*--\u0026gt; \u0026lt;!--例如\u0026lt;host host=\u0026#34;127.0.0.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--例如\u0026lt;host host=\u0026#34;127.0.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--例如\u0026lt;host host=\u0026#34;127.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--例如\u0026lt;host host=\u0026#34;1*7.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--这些配置情况下对于127.0.0.1都能以root账户登录--\u0026gt; \u0026lt;!-- \u0026lt;firewall\u0026gt; \u0026lt;whitehost\u0026gt; \u0026lt;host host=\u0026#34;1*7.0.0.*\u0026#34; user=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;/whitehost\u0026gt; \u0026lt;blacklist check=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;/blacklist\u0026gt; \u0026lt;/firewall\u0026gt; --\u0026gt; \u0026lt;!-- mysql 账户配置 --\u0026gt; \u0026lt;user name=\u0026#34;admin\u0026#34; defaultAccount=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;Mysql123456.\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;test\u0026lt;/property\u0026gt; \u0026lt;!-- 表级 DML 权限设置 --\u0026gt; \u0026lt;!-- \u0026lt;privileges check=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;TESTDB\u0026#34; dml=\u0026#34;0110\u0026#34; \u0026gt; \u0026lt;table name=\u0026#34;tb01\u0026#34; dml=\u0026#34;0000\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;table name=\u0026#34;tb02\u0026#34; dml=\u0026#34;1111\u0026#34;\u0026gt;\u0026lt;/table\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;/privileges\u0026gt;	--\u0026gt; \u0026lt;/user\u0026gt; \u0026lt;!-- \u0026lt;user name=\u0026#34;user\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;user\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;schemas\u0026#34;\u0026gt;TESTDB\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;readOnly\u0026#34;\u0026gt;true\u0026lt;/property\u0026gt; \u0026lt;/user\u0026gt; --\u0026gt; \u0026lt;/mycat:server\u0026gt; schema.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;!-- 虚拟逻辑库和表 --\u0026gt; \u0026lt;schema name=\u0026#34;test\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;!-- auto sharding by id (long) 切分算法 mod-long --\u0026gt; \u0026lt;table name=\u0026#34;t_user\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;!-- 分片关系配置 --\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;cluster1\u0026#34; database=\u0026#34;test\u0026#34; /\u0026gt; \u0026lt;dataNode name=\u0026#34;dn2\u0026#34; dataHost=\u0026#34;cluster2\u0026#34; database=\u0026#34;test\u0026#34; /\u0026gt; \u0026lt;!-- 连接信息配置 1--\u0026gt; \u0026lt;!-- balance: 代表负载均衡类型； 0 表示不开启读写分离； 1 表示保留一个写节点负责写入，其他节点处理读请求； 2 表示所有写节点都要额外承担读请求； 3 表示读节点只处理读请求，写节点只处理写请求； writeType: 分发请求到写节点的模式 0 表示分发所有的请求到第一个写节点，只有第一个写节点宕机才会启用第二个写节点； 1 表示分发所有的请求到所有写节点一起处理； switchType: 依据什么来判断切换节点； 1 依据mycat自己的心跳检测来识别是否切换； 2 依据数据库集群的信息来判断节点是否切换； --\u0026gt; \u0026lt;dataHost name=\u0026#34;cluster1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;2\u0026#34; writeType=\u0026#34;1\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;W1\u0026#34; url=\u0026#34;192.168.145.131:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt; \u0026lt;!-- can have multi read hosts --\u0026gt; \u0026lt;readHost host=\u0026#34;W1R1\u0026#34; url=\u0026#34;192.168.145.132:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;readHost host=\u0026#34;W1R2\u0026#34; url=\u0026#34;192.168.145.133:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;writeHost host=\u0026#34;W2\u0026#34; url=\u0026#34;192.168.145.132:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt; \u0026lt;!-- can have multi read hosts --\u0026gt; \u0026lt;readHost host=\u0026#34;W2R1\u0026#34; url=\u0026#34;192.168.145.131:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;readHost host=\u0026#34;W2R2\u0026#34; url=\u0026#34;192.168.145.133:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt;	\u0026lt;!-- 连接信息配置 2 --\u0026gt; \u0026lt;dataHost name=\u0026#34;cluster2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;2\u0026#34; writeType=\u0026#34;1\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- can have multi write hosts --\u0026gt; \u0026lt;writeHost host=\u0026#34;W1\u0026#34; url=\u0026#34;192.168.145.135:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt; \u0026lt;!-- can have multi read hosts --\u0026gt; \u0026lt;readHost host=\u0026#34;W1R1\u0026#34; url=\u0026#34;192.168.145.136:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;readHost host=\u0026#34;W1R2\u0026#34; url=\u0026#34;192.168.145.137:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;writeHost host=\u0026#34;W2\u0026#34; url=\u0026#34;192.168.145.136:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; \u0026gt; \u0026lt;!-- can have multi read hosts --\u0026gt; \u0026lt;readHost host=\u0026#34;W2R1\u0026#34; url=\u0026#34;192.168.145.135:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;readHost host=\u0026#34;W2R2\u0026#34; url=\u0026#34;192.168.145.137:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; rule.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- - - Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); - you may not use this file except in compliance with the License. - You may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 - - Unless required by applicable law or agreed to in writing, software - distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the License for the specific language governing permissions and - limitations under the License. --\u0026gt; \u0026lt;!DOCTYPE mycat:rule SYSTEM \u0026#34;rule.dtd\u0026#34;\u0026gt; \u0026lt;mycat:rule xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;tableRule name=\u0026#34;rule1\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;func1\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;rule2\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;user_id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;func1\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-intfile\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;auto-sharding-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;rang-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;mod-long\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;mod-long\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-murmur\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;murmur\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;crc32slot\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;crc32slot\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-by-month\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;create_time\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;partbymonth\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;latest-month-calldate\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;calldate\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;latestMonth\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;auto-sharding-rang-mod\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;rang-mod\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;tableRule name=\u0026#34;jch\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;jump-consistent-hash\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; \u0026lt;function name=\u0026#34;murmur\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMurmurHash\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;seed\u0026#34;\u0026gt;0\u0026lt;/property\u0026gt;\u0026lt;!-- 默认是0 --\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt;\u0026lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片 --\u0026gt; \u0026lt;property name=\u0026#34;virtualBucketTimes\u0026#34;\u0026gt;160\u0026lt;/property\u0026gt;\u0026lt;!-- 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍 --\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;weightMapFile\u0026#34;\u0026gt;weightMapFile\u0026lt;/property\u0026gt; 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 --\u0026gt; \u0026lt;!-- \u0026lt;property name=\u0026#34;bucketMapPath\u0026#34;\u0026gt;/etc/mycat/bucketMapPath\u0026lt;/property\u0026gt; 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 --\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;crc32slot\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByCRC32PreSlot\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt;\u0026lt;!-- 要分片的数据库节点数量，必须指定，否则没法分片 --\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;hash-int\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;rang-long\u0026#34; class=\u0026#34;io.mycat.route.function.AutoPartitionByLong\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;autopartition-long.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;mod-long\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMod\u0026#34;\u0026gt; \u0026lt;!-- how many data nodes --\u0026gt; \u0026lt;property name=\u0026#34;count\u0026#34;\u0026gt;2\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;func1\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByLong\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;partitionCount\u0026#34;\u0026gt;8\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;partitionLength\u0026#34;\u0026gt;128\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;latestMonth\u0026#34; class=\u0026#34;io.mycat.route.function.LatestMonthPartion\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;splitOneDay\u0026#34;\u0026gt;24\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;partbymonth\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByMonth\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dateFormat\u0026#34;\u0026gt;yyyy-MM-dd\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;sBeginDate\u0026#34;\u0026gt;2015-01-01\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;rang-mod\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByRangeMod\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-range-mod.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;function name=\u0026#34;jump-consistent-hash\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByJumpConsistentHash\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;totalBuckets\u0026#34;\u0026gt;3\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; \u0026lt;/mycat:rule\u0026gt; 启动与关闭 #  分配启动权限 #  cd mycat/bin chmod -R 777 *.sh # 添加权限 启动 #  ./startup_nowrap.sh # 启动mycat ./mycat start # 启动mycat 关闭 #  ps -aux | grep mycat kill -9 pid 测试 #  这里测试需要安装 mysql-client客户端（初学时，发现没有mysql客户端，没有mysql的命令）；\nmysql -uadmin -pMysql123456. -P 8066 -h 127.0.0.1 # 注意这里host：127.0.0.1 MyCat 切分 #     七分算法 适合场合 备注     主键求模切分 数据增长速度慢，难于增加分片 有明确主键值   枚举值切分 归类存储数据，适合大多数业务    主键范围切分 数据快速增长，容易增加分片，不利于归档，腾出空间不会再次使用 有明确主键值   日期切分 数据快速增长，容易增加分片，不利于归档，腾出空间不会再次使用     主键求模切分 #  对主键求模来切分，一般选择对分片数求模\n  适合初始数据量很大，但是数据增长不快的场景\n地图产品 行政数据 企业数据\n怎么去理解增速很快？\n因为如果数据库增速很快，导致集群需要增加分片，由于求模算法，回导致数据的迁移，占用很大的IO资源；\n  求模切分的弊端在于扩展新分片难度大，迁移的数据太多；\n举个例子：由原来的2分片，扩展到4分片，迁移前2分片的数据到新增的2分片中，数据迁移困难；\n  如果非增加分片不可的情况，建议成倍增加为原有分片的2n倍，这样可以预测数据迁移规则；\n举个例子：原始分片2个，扩展到4个；\n原始分片中求模余0或1还再原来的分片，余2的则迁移至第3个分片，余3则迁移至第4个分片；\n  什么时候该添加分片？\n现有分片不足以保存热数据才添加分片；\n  枚举值切分 #  按照某个sh字段的值（数字）来切分\n\u0026lt;tableRule name=\u0026#34;sharding-by-intfile\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;!-- sharding_id: 数据库中字段名 --\u0026gt; \u0026lt;algorithm\u0026gt;hash-int\u0026lt;/algorithm\u0026gt; \u0026lt;!-- 算法名，这是使用java实现的类 --\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; ... \u0026lt;function name=\u0026#34;hash-int\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;!-- 切分算法使用java实现 --\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;partition-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;!-- partition-hash-int.txt：配置枚举规则：如 001 是分片1， 201 是分片2 --\u0026gt; \u0026lt;!-- 010=0 024=0 0411=1 --\u0026gt; \u0026lt;/function\u0026gt; 例子：\ncustomer-hash-int.txt\n101=0 102=0 103=0 104=1 105=1 106=1 rule.xml\n\u0026lt;!-- 定义切分规则，指定数据列，及其切分算法 --\u0026gt; \u0026lt;tableRule name=\u0026#34;sharding-customer\u0026#34;\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;columns\u0026gt;sharding_id\u0026lt;/columns\u0026gt; \u0026lt;algorithm\u0026gt;customer-int\u0026lt;/algorithm\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/tableRule\u0026gt; ... \u0026lt;!-- 配置切分算法实现类和切分枚举规则 --\u0026gt; \u0026lt;function name=\u0026#34;customer-hash-int\u0026#34; class=\u0026#34;io.mycat.route.function.PartitionByFileMap\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mapFile\u0026#34;\u0026gt;customer-hash-int.txt\u0026lt;/property\u0026gt; \u0026lt;/function\u0026gt; schema.xml\n\u0026lt;!-- 虚拟逻辑库和表 --\u0026gt; \u0026lt;schema name=\u0026#34;test\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34;\u0026gt; ... \u0026lt;!-- 添加枚举切分t_customer --\u0026gt; \u0026lt;table name=\u0026#34;t_customer\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;sharding-customer\u0026#34; /\u0026gt; \u0026lt;/schema\u0026gt; 热重载mycat配置文件\n[root@mycat conf]# mysql -uadmin -pMysql123456. -P 9066 -h 127.0.0.1 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 23 Server version: 5.6.29-mycat-1.6.7.6-release-20201126013625 MyCat Server (monitor) Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; reload @@config_all; Query OK, 1 row affected (0.53 sec) Reload config success 创建t_customer 表进行测试切分\n-- DataGrip 通过mycat 来创建表，会出现创建的表名和字段名都为大写 -- 可以再分片中分别创建即可 CREATE TABLE t_customer ( id INT PRIMARY KEY, username VARCHAR(200) NOT NULL, sharding_id INT NOT NULL ); -- 插入数据 insert into t_customer (id, username, sharding_id) values (1, \u0026#34;xiaoming\u0026#34;, 101); 应用场景\n 淘宝网：数据分片按商品分类来枚举值切分，当某个商品类的数据库出现故障，并不会影响其他商品类别的正常工作； 美团或饿了么：按地区类别来进行数据切分，这样某个地区数据分片宕机并不会影响其他地区的业务进行；  MyCat 父子表 #  父子表要解决的问题是？ #  MyCat不支持跨分片连接查询；\n现有2分片，分片1记录了A用户的信息，但是A用户的购物记录被切分到了分片2，这样的话在做连接查询时就会遇到问题，而父子表就是为了解决这种问题而出现的，使得分片记录如下，A用户的信息和A用户购物记录均会保存到统一分片，这样就可以随意做连接查询了。\n配置父子表 #  schema.xml\n\u0026lt;!-- 添加枚举切分t_customer --\u0026gt; \u0026lt;table name=\u0026#34;t_customer\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; rule=\u0026#34;sharding-customer\u0026#34; \u0026gt; \u0026lt;childTable name=\u0026#34;t_orders\u0026#34; primaryKey=\u0026#34;ID\u0026#34; joinKey=\u0026#34;customer_id\u0026#34; parentKey=\u0026#34;id\u0026#34; /\u0026gt; \u0026lt;/table\u0026gt; -- mycat 热重载所有配置文件 mysql\u0026gt; reload @@config_all; Query OK, 1 row affected (0.52 sec) Reload config success MyCat集群 #  方案 #  图中Haproxy两个节点实现了高可用，当一个Haproxy节点宕机， 另外一个节点通过争抢ip来进行服务\n只有一个Haproxy节点 能应对高一个负载吗？ #  能应对；一个Haproxy节点能应对 80000 次/s 请求。\n一个日访问量5000000，平均每秒请求 5000000 / 24 / 3600 = 58 次；\nMySQL 要大量集群， MyCat 要少量集群，Haproxy 不需要集群。\n增加Mycat节点 #  请参考之前方式，或者直接vmware克隆\n部署Haproxy #  准备工作 #  开放端口：3306 TCP/IP转发端口；4001 监控界面端口；\nfirewall-cmd --zone=public --add-port=3306/tcp --add-port=4001/tcp --permanent firewall-cmd --reload 关闭SELINUX\nvi /etc/selinux/config\nSELINUX=disabled reboot 生效\n安装haproxy #  yum -y install haproxy\n启动与停止与重启：\nservice haproxy start\nservice haproxy stop\nservice haproxy restart\n配置文件 #  vi /etc/haproxy/haproxy.cfg\nglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 # 后台监控的配置 listen admin_stats # 名称 bind 0.0.0.0:4001 # 监控界面的访问的ip和端口 mode http # 访问协议 stats uri /dbs # URI相对地址 stats realm Global\\ statistics # 统计报告格式 stats auth admin:admin # 登录密码 # 负载均衡的配置 listen proxy-mysql # 名称 bind 0.0.0.0:3306 mode tcp balance roundrobin # 请求转发算法，这里时轮询 option tcplog # 日志格式 server mycat01 192.168.145.134:8066 check port 8066 weight 1 maxconn 2000 # 负载均衡  server mycat02 192.168.145.138:8066 check port 8066 weight 1 maxconn 2000 # 负载均衡 # 由于上面再用的转发算法为 “轮询”，这里的weight无效； # 当balance 采用权重算法来转发时，weight才会起到作用；那么什么情况下会使用权重算法转发呢？ # 在需要负载均衡的多个节点存在差异化时，如ab两节点，a主机性能更好，处理效率更高，那么会给他更多权重，处理更多的请求。 option tcpka # 使用keeplive 检测死链 启动错误，无提示 #  systemctl status haproxy  查看状态发现配置文件错误；\n部署keepalived #  准备工作 #  开启防火墙的VRRP协议\nfirewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --protocol vrrp -j ACCEPT firewall-cmd --reload 安装 #  yum -y install keepalived 配置文件 #  vi /etc/keepalived/keepalived.conf\nvrrp_instance VI_1 { state MASTER ! 如果2个节点都设置为MASTER，则当节点启动时会争抢虚拟IP，未抢到的接待你会编程SLAVE interface ens33 ! 网卡名称 virtual_router_id 51 ! 虚拟路由标识，代表 节点ID \u0026lt;255 priority 100 ! 定义优先级 advert_int 1 ! 秒 ! 认证，只有通过认证的才会心跳检测 authentication { auth_type PASS auth_pass 123456 } virtual_ipaddress { 192.168.145.139 ! 虚拟IP地址 } } 启动与关闭 #  systemctl start keepalived systemctl stop keepalived 测试 #  使用DataGrip 通过keepalived的虚拟IP来连接mycat\n或者可以通过虚拟IP登录到linux来测试\nSysbench 基准测试 #  安装 #  在线安装 #  curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash yum -y install sysbench 本地安装\nsysbench 命令 #  语法：sysbench script [option] [command]\nOPTION #  连接参数\n--mysql-host: 数据库IP地址\n--mysql-port: 端口号\n–-mysql-user: 用户名\n--mysql-password: 密码\n数据库测试\n--oltp-test-mode: 执行模式（simple只测试查询不测试写入 、nontrx测试无事务的增删改查、complex 带事务的增删改查）\n--oltp-tables-count: 测试表数量\n--oltp-table-size: 测试表的记录数\n--threads: 并发连接数\n--time: 测试执行时间（秒）\n--report-interval: 生成报告单的间隔时间（秒）\ncommand #  prepare: 准备测试数据\nrun : 执行测试\ncleanup: 清楚测试数据\n测试示例 #  通过prepare命令生成测试数据\n# 注意这里的script脚本的路径，下面为在线安装的脚本路径，编译安装版本需要注意放置位置 sysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua \\ --mysql-host=192.168.145.138 \\  --mysql-port=3306 \\  --mysql-user=admin \\  --mysql-password=Mysql123456. \\ --oltp-tables-count=10 \\ --oltp-table-size=100000 \\ prepare 配置Haproxy(192.168.145.138) 负载均衡拥有3个节点的分片\n/etc/haproxy/haproxy.cfg\n# 这三个为同一个分片 server mysql01 192.168.145.131:3306 check port 3306 weight 1 maxconn 2000 server mysql02 192.168.145.132:3306 check port 3306 weight 1 maxconn 2000 server mysql03 192.168.145.133:3306 check port 3306 weight 1 maxconn 2000 生成测试数据\nsysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua --mysql-host=192.168.145.138 --mysql-port=3306 --mysql-user=admin --mysql-password=Mysql123456. --oltp-test-mode=complex --threads=10 --time=300 --report-interval=10 run \u0026gt;\u0026gt; /home/mysql_sysbench.log 查看测试结果：\n小结 #  数据表建议不低于10个，单表数据量不低于500万行。\n如果配备了SSD或者PCIE SSD，则建议单表数据量最少不低于1亿行。\n真实物理主机上的基准测试，建议24小时以上。\nTPCC-MYSQL压力测试 #  测试方案 #  安装tpcc-mysql #  准备工作 #  vi /etc/my.cnf 编辑pxc集群配置文件\npxc_strict_mode=ENFORCING # 这个是默认，不允许不规范的操作 # 修改为下面配置 pxc_strict_mode=DISABLED # 这个是为了能运行tpcc测试模型（模型种存在无主键的数据 表） 使用haproxy做负载均衡\n# 负载均衡 server mysql01 192.168.145.131:3306 check port 3306 weight 1 maxconn 2000 server mysql02 192.168.145.132:3306 check port 3306 weight 1 maxconn 2000 server mysql03 192.168.145.133:3306 check port 3306 weight 1 maxconn 2000 tpcc 只有源代码，所以只能通过源代码编译执行\n安装编译所需的包\nyum -y install gcc yum install -y mysql-devel 下载tpcc-mysql源代码\ntpcc-mysql\n解压编译安装\nunzip tpcc-mysql-master.zip cd tpcc-mysql-master/src make 连接mysql 集群，创建tpcc测试的逻辑库\ntpcc\n导入tpcc 测试数据\n/tpcc_mysql_master/\ncd /home/tpcc_msyql_master ls *.sql add_fkey_idx.sql count.sql create_table.sql drop_cons.sql # create_table.sql: 创建数据表 add_fkey_idx.sql: 增加外键约束和索引 # 上面两个需要导入 mysql -uadmin -pMysql123456. -h 192.168.145.138 -P3306 use tpcc source create_table.sql source add_fkey_idx.sql 生成测试数据\ncd /home/tpcc_msyql_master ./tpcc_load -h 192.168.145.138 -P 3306 -d tpcc -uadmin -pMysql123456. -w 1 # w 代表tpcc测试模型种数据库种的仓库数，实际测试建议仓库数弄上千个，但这比较耗时 # vmware 虚拟机，生成w=1的测试数据大概耗时30分钟 执行测试\ncd /home/tpcc_msyql_master ./tpcc_start -h 192.168.145.138 -P 3306 -d tpcc -uadmin -pMysql123456. -w 1 -c 5 -r 300 -l 600 -\u0026gt; tpcc-output-log # -c 并发线程数 -r 数据库预热时间，单位秒 -l 测试时间s # tpcc-output-log 输出到文件 # 真实环境中，-r -l的时间都要长一些；如 -r 3600 -l 3600*24 PXC 原理 #  了解binlog 日志 #  binlog 日志文件种类 #  my.ini mysql配置文件\nbinlog-format=row # binlog模式 log-bin=mysql_bin # 日志文件名定义 日志文件 #  根据上面my.ini配置输出日志文件名称：\nmysql_bin.000001 mysql_bin.000002 这种文件名的文件，二进制方式存储，需要特定程序才能打开；\n打开日志文件方式：\n使用SQL语句\n-- 查看索引文件，显示有多少条binlog日志文件 show master logs; -- 查看具体的binlog日志文件 show binlogs events in \u0026#39;localhost:-bin.000009\u0026#39;; 索引文件 #  mysql_bin.index 以index结尾的文件，文本文件；\nbinlog 日志格式 #  Row #  每条记录的变化都会写入日志中，记录的是实实在在的数据变化；\nSTATEMENT 模式 #  每一条会修改数据的sql语句会记录到binlog中\nMixed #  普通操作使用STATEMENT格式，同步可能出现问题（例如，插入数据sql语句中包含某些函数UUID函数时）的操作选择ROW模式；\n集合了上述两种模式的优点\nPXC 同步原理 #  GTID (全局事务GIT, Global Transaction ID) #  组成：server uuid + transaction_id\nserver uuid #  show status like '%uuid%' 查看uuid\n   Variable_name Value      wsrep_local_state_uuid 85ab08a0-2fbc-11eb-b645-67acc08322c2 集群uuid   wsrep_gcomm_uuid 533dbf66-35ca-11eb-89ce-02d6a075f25a 节点uuid   wsrep_cluster_state_uuid 85ab08a0-2fbc-11eb-b645-67acc08322c2 集群uuid    transaction_id #  show binlog event in 'localhost-binlog.000001' 通过查看binlog日志文件，图中红色框内的就是transaction_id, 指的是pxc集群的transaction_id\n节点的事务id\nshow status like 'wsrep_last_committed%' 查看节点的transaction_id\n通过这个ID可以推断节点同步情况；如有一个节点在wsrep_last_committed = 100的时候宕机。当他启动一段时间后，wsrep_last_committed = 150 ，那么100~150 就是该节点上线来同步的事务id\npxc 同步流程图 #  问题：\n  当其他节点接收到GTID之后宕机，那么其他节点Galera返回成功的响应，本地节点Galera正常提交，记录日志数据写入成功，而其他节点由于宕机并没真正写入数据，这是不是说“pxc集群并不是强一致性”。\npxc在这里还是强一致性的，因为宕机的节点已经不在集群中存活了，重启启动之前不会提供服务，所以并没有什么关系；当宕机节点再次启动后，还是会与集群中的节点进行同步，达到数据的一致性；\n  pxc集群由于网络原因会不会出现读写不一致的问题\n不会，pxc集群是同步发送writeSet和GTID的，如果网络故障Master收不到发送成功的响应是不会进行提交的。\n  pxc 中锁冲突流程图 #  有AB两个节点，这两个节点同时操作同一数据时可能引发锁冲突。\n举个例子：\n有AB两节点同时向数据库中的同一张表插入数据，且该表的主键是“自增长”的。且这两个节点同时争抢到主键ID为1的，并向对方发送writeSet，当A还没收到锁冲突的验证结果时，而先收到了B发给他的writeSet，A节点发现主键1自己正在使用，所以A节点会发送锁冲突的响应；同理B节点也可能会发送锁冲突的响应，这样对于主键1，AB两节点均收到锁冲突，而放弃使用；\n这样会造成什么影响呢？\n如在自增长主键的表中，可能会出现主键不连续的情况。这是因为在争抢的过程中，出现上述情况，就会重新争抢新的主键，而放弃了存在冲突的主键值。\n怎么避免这种问题呢？\n 不使用自增长主键 采用MyCat的全局主键  Replication集群 #  同步数据过程图：\n采用的是 异步机制，Master节点只管自身的数据的插入，并不主动发送数据到其他节点。其他slave节点会开启专用的线程来读取Master节点的binlog日志来进行同步；这样的集群适合读多写少的数据库。\nMySQL 5种架构设计 #  MySQL + 分布式Proxy扩展 #  PXC 集群\n适用于需要强一致性的系统，如与钱相关的。一般是PXC 集群+ MyCat（中间件） + Haproxy（负载均衡） + keepalived（双机热备）\nReplication集群\nPXC + Replication 集群\n集群表连接查询：\n  采用同步中间件，把pxc集群的数据同步到replication集群种，再做表连接查询\n  使用类似于kettle先分别从PXC集群和Replication集群获取数据，然后通过kettle来进行连接查询\n  数据归档，冷热数据分离 #  MongoDB 和 TokuDB\nMongoDB：兼顾读写性能，对于归档数据需要进行查询的场景，推荐使用MongoDB。4.0已支持事务\nTokuDB: MySQL一种存储引擎，性能比MongoDB 快且是带事务的写入\nMySQL + 缓存（redis）高并发架构 #  redis 或memcached\nMySQL + 小文件系统 #  文件体积大： Hadoop 的 HDFS 文件系统\n文件体积小： MongoDB的GridFS(可以存储图片、语音、短视频灯)，如果文件数据较小如 16m以下，可以使用默认的Binary BSON\nMySQL + Inforbright统计分析架构 #  对数据有统计分析的需求时采用\nMySQL 的设计原则 #  MySQL 架构的演化 #  单体单节点阶段\nPXC 集群的使用 #  导入数据 #  sql文件 #  source 命令： source test.sql\n批量导入sql文件：source all.sql (先把所有的sql文件的路径，写入到all.sql 中，然后再导入)\n适用数据不多的情况；\n导入慢的原因：由于MySQL导入sql文件时，需要先对sql语句进行词法分析和分析，然后在继续数据的写入。当数据量过大，也就是sql语句过多，自然就会慢起来。\n文本文件 #  LOAD DATA  纯数据导入，速度快\nLOAD DATA LOCAL INFILE 'data.txt' INTO TABLE orders FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\u0026quot;' LINES TERMINATED BY '\\n'\n解释：从本地文件data.txt 导入表 orders 中，字段按 “,” 分隔；无视双引号，每行以换行符结束（不同操作系统不同“\\n” “\\r\\n”）。\nLOAD DATA 为单线程，可以先对data.txt来进行切分，然后采用多个线程来导入（30G 文件 6000万多条数据，大概50分钟即可导入完成）；\n注意 ： 在向MyCat 中间件使用上述命令时，需要在表名后面加上对应的字段\nLOAD DATA LOCAL INFILE 'data.txt' INTO TABLE orders(字段1，字段2) FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\u0026quot;' LINES TERMINATED BY '\\n'\n准备导入数据 #  使用熟悉的语言生成1000万条数据\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) var num = 10000000 func generate() { file, err := os.Create(\u0026#34;./data.txt\u0026#34;) if err != nil { fmt.Printf(\u0026#34;create file failed:[%v]\\n\u0026#34;, err) return } defer file.Close() buf := bufio.NewWriter(file) for i:=1; i\u0026lt;=num; i++ { _, err := buf.WriteString(fmt.Sprintf(\u0026#34;%d, 测试数据\\n\u0026#34;, i)) // id, name 	//_, err := file.WriteString(fmt.Sprintf(\u0026#34;%d, 测试数据\\n\u0026#34;, i)) 	if err != nil { fmt.Printf(\u0026#34;WriteString failed:[%v]\\n\u0026#34;, err) continue } } } func main() { startTime := time.Now() generate() time := time.Since(startTime) fmt.Println(time) // 耗时 2s } 切分文件为多份\nsplit -l 1000000 -d data.txt\n导入大量数据时MySQL配置 #   当导入大量数据时，以下配置可以提高导入速度  [mysqld] ...... # 正常情况下为事务提交后，日志才写入硬盘，当设置为0后，日志每秒都写入磁盘，与事务是否提交没关系，代表数据库在事务# # 提交之前把日志写入磁盘，免去事务提交后才写入磁盘，提高事务效率。 innodb_flush_log_at_trx_commit = 0 # 不等待提交，直接写入磁盘； # 日志数据直接写入磁盘，而不会写到系统缓冲区。跳过缓冲区，减少CPU和内存的占用 innodb_flush_method = O_DIRECT # 设置引擎缓冲区的大小，减少写入次数，提高io效率 innodb_buffer_pool_size = 200M # 导入安全设置 =null表示禁用， /home表示仅限于该目录， 空为不做限制  secure_file_priv = 授予账户导入权限  grant file on *.* to admin@\u0026#39;%\u0026#39;  关闭集群分片节点（保留一个节点）  PXC集群在导入大量数据时，会导致限流，为了快速导入数据，就不能有限流；所以在导入时，一个pxc集群只开启一个节点，其他节点通过拷贝数据库文件来实现同步；\n我这里保留的节点为： 192.168.145.131（分片1） 和 192.168.145.135（分片2）\n在两个节点上分别创建t_test表；  CREATE TABLE t_test ( id int primary key, name varchar(200) not null )  修改MyCat配置文件\n修改之前记得保存之前的schme.xml文件\ncp schema.xml schema.xml_pxc\nschema.xml [192.168.145.131（分片1） 和 192.168.145.135（分片2）]\n  ... \u0026lt;!-- 添加需要进行七分的表，按mod-long切分 --\u0026gt; \u0026lt;table name=\u0026#34;t_test\u0026#34; dataNode=\u0026#34;dn1,dn2\u0026#34; primaryKey=\u0026#34;id\u0026#34; rule=\u0026#34;mod-long\u0026#34; /\u0026gt;	\u0026lt;!-- 连接信息配置 1--\u0026gt; \u0026lt;dataHost name=\u0026#34;cluster1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;1\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- can have multi write hosts --\u0026gt; \u0026lt;writeHost host=\u0026#34;W1\u0026#34; url=\u0026#34;192.168.145.131:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt;\u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;!-- 连接信息配置 2 --\u0026gt; \u0026lt;dataHost name=\u0026#34;cluster2\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;0\u0026#34; writeType=\u0026#34;1\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;!-- can have multi write hosts --\u0026gt; \u0026lt;writeHost host=\u0026#34;W1\u0026#34; url=\u0026#34;192.168.145.135:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;Mysql123456.\u0026#34;\u0026gt;\u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; ... 重新启动pxc 和 mycat\nsystemctl restart mysql@bootstrap.service cd /mycat/bin/ ./mycat restart 查看集群的情况\n开始数据导入 #  具体导入请查看 数据批量导入\n同步其他节点数据 #  对数据文件进行拷贝来同步其他节点的数据，这样会提高同步的效率，但需要使用 percona 专业的数据打包工具来进行，这边之后再进行研究；\n由于当前数据较少，直接采用pxc集群的全量同步进行。即把之前改动的MyCat记忆Mysql配置部分文件进行还原即可。\nPXC节点(/etc/my.cnf)\nvi /etc/my.cnf systemctl restart mysql@bootstrap.service my.cnf 下面三项：使用load data命令导入数据时的配置文件；开启集群后需要删除； innodb_flush_log_at_trx_commit = 0 innodb_flush_method = O_DIRECT innodb_buffer_pool_size = 200M    MyCat配置文件(/home/mycat/conf/)\nmv schema.xml schema.xml_load_data mv schema.xml_pxc schema.xml vi schema.xml ../bin/mycat restart schema.xml \u0026lt;schema name=\u0026quot;test\u0026quot; checkSQLschema=\u0026quot;false\u0026quot; sqlMaxLimit=\u0026quot;100\u0026quot;\u0026gt; \u0026lt;!-- 增加下方t_test的虚拟表及其分片算法 --\u0026gt; \u0026lt;table name=\u0026quot;t_test\u0026quot; dataNode=\u0026quot;dn1,dn2\u0026quot; primaryKey=\u0026quot;id\u0026quot; rule=\u0026quot;mod-long\u0026quot; /\u0026gt; ... \u0026lt;/schema\u0026gt;    集群同步完成。\n"}),a.add({id:9,href:'/docs/rabbitmq/',title:"RabbitMQ",section:"Docs",content:"RabbitMQ\n"}),a.add({id:10,href:'/docs/rabbitmq/rabbitmq-remote-procedure-call-rpc/',title:"Remote Procedure Call",section:"RabbitMQ",content:"Remote Procedure Call （RPC） #  using Go RabbitMQ client\nIn the second tutorial we learned how to use Work Queues to distribute time-consuming tasks among multiple workers.\n在第二个教程中，我们学习了怎么使用 Work Queues 在多个工作人员之间分配耗时任务。\nBut what if we need to run a function on a remote computer and wait for the result? Well, that\u0026rsquo;s a different story. This pattern is commonly known as Remote Procedure Call or RPC.\n但是，如果我们需要在远程计算机运行一个函数并等待结果呢？好吧，那就另当别论。此模式通常称为 Remote Procedure Call 或 RPC （远程过程调用）。\nIn this tutorial we\u0026rsquo;re going to use RabbitMQ to build an RPC system: a client and a scalable RPC server. As we don\u0026rsquo;t have any time-consuming tasks that are worth distributing, we\u0026rsquo;re going to create a dummy RPC service that returns Fibonacci numbers.\n在这个教程中我们将使用 RabbitMQ 来构建一个 RPC 系统：一个客户端和一个可扩展的RPC服务器。由于我们没有任何值得分发的耗时任务，我们将创建一个虚拟 RPC 服务，它返回一个 Fibonacci（斐波拉契数）。\n A note on RPC\n关于RPC说明\nAlthough RPC is a pretty common pattern in computing, it\u0026rsquo;s often criticised. The problems arise when a programmer is not aware whether a function call is local or if it\u0026rsquo;s a slow RPC. Confusions like that result in an unpredictable system and adds unnecessary complexity to debugging. Instead of simplifying software, misused RPC can result in unmaintainable spaghetti code.\n尽管 RPC 是在计算中非常普遍的模式，但它经常受到批评。当一个程序员不知道一个函数调用是本地还是一个慢的RPC时，就会出现问题。这样的混乱会导致系统变幻莫测，并给调试增加了不必要的复杂性。滥用RPC可能会导致无法维护的意大利面条代码，而不是简化软件。\nBearing that in mind, consider the following advice:\n考虑到这一点，请考虑以下建议：\n Make sure it\u0026rsquo;s obvious which function call is local and which is remote. 确保函数本地调用和远程调用是明显的 Document your system. Make the dependencies between components clear. 记录您的系统，使组件之间依赖关系清晰明了 Handle error cases. How should the client react when the RPC server is down for a long time? 处理错误情况。当RPC服务器宕机很长时间，客户端应该如何响应。  When in doubt avoid RPC. If you can, you should use an asynchronous pipeline - instead of RPC-like blocking, results are asynchronously pushed to a next computation stage.\n在有疑问时避免 RPC。如果可以，你应该使用异步管道\u0026ndash;代替类似 RPC的阻塞，结果将被异步推送到下一个计算阶段。\n Callback queue #  In general doing RPC over RabbitMQ is easy. A client sends a request message and a server replies with a response message. In order to receive a response we need to send a \u0026lsquo;callback\u0026rsquo; queue address with the request. We can use the default queue. Let\u0026rsquo;s try it:\n通常，通过RabbitMQ进行 RPC 很容易。一个客户端发送一个请求消息，服务器回复一个响应消息。为了接受响应，我们需要随请求发送一个 \u0026lsquo;callback\u0026rsquo; 队列地址。我们能使用默认的队列，让我们试试吧：\nq, err := ch.QueueDeclare( \u0026#34;\u0026#34;, // name 队列名字  false, // durable 持久  false, // delete when unused 未使用是否删除  true, // exclusive 是否独占  false, // noWait 等待与否  nil, // arguments ) err = ch.Publish( \u0026#34;\u0026#34;, // exchange 交易所  \u0026#34;rpc_queue\u0026#34;, // routing key 路由秘钥  false, // mandatory 强制的  false, // immediate 立即  amqp.Publishing{ ContentType: \u0026#34;text/plain\u0026#34;, // 内容类型  CorrelationId: corrId, //  ReplyTo: q.Name, Body: []byte(strconv.Itoa(n)), })  Message properties 消息属性\nThe AMQP 0-9-1 protocol predefines a set of 14 properties that go with a message. Most of the properties are rarely used, with the exception of the following:\nAMQP 0-9-1 协议预定义了消息附带的 14个属性集。 除了以下属性外，大多数属性都很少使用：\n  persistent: Marks a message as persistent (with a value of true) or transient (false). You may remember this property from the second tutorial.\npersistent: 标记一个消息是持久的（值：true）或 瞬时的（值：false）。您可能还记得第二个教程中的此属性。\n  content_type: Used to describe the mime-type of the encoding. For example for the often used JSON encoding it is a good practice to set this property to: application/json.\ncontent_type：常常描述编码的mime类型。例如对于经常使用 JSON 编码，该属性设置为：application/json是一个好的实践。\n  reply_to: Commonly used to name a callback queue.\nreply_to：通常用于命名回调队列\n  correlation_id: Useful to correlate RPC responses with requests.\ncorrelation_id：有利于关联 RPC响应与请求\n   Correlation Id （关联 id） #  In the method presented above we suggest creating a callback queue for every RPC request. That\u0026rsquo;s pretty inefficient, but fortunately there is a better way - let\u0026rsquo;s create a single callback queue per client.\n在上面呈现的方法中，我们建议为每一个 RPC 请求创建一个 回调队列。这是相当低效的，但是幸运的是有一个较好的方式-让我们为每一个客户端创建一个回调队列\nThat raises a new issue, having received a response in that queue it\u0026rsquo;s not clear to which request the response belongs. That\u0026rsquo;s when the correlation_id property is used. We\u0026rsquo;re going to set it to a unique value for every request. Later, when we receive a message in the callback queue we\u0026rsquo;ll look at this property, and based on that we\u0026rsquo;ll be able to match a response with a request. If we see an unknown correlation_id value, we may safely discard the message - it doesn\u0026rsquo;t belong to our requests.\n这就提出了一个新的问题，在该队列收到响应后，响应属于那个请求是不清楚地。这就是 correlation_id 属性使用地时候了。我们将为每一个请求设置一个独一无二的值。之后，当我们在回调队列收到一个消息时，我们将查找这个属性，基于此我们将能够匹配响应与请求。如果我们看到衣蛾未知的 correlation_id 值，我们能安全的丢弃这个消息-它不属于我们的请求。\nYou may ask, why should we ignore unknown messages in the callback queue, rather than failing with an error? It\u0026rsquo;s due to a possibility of a race condition on the server side. Although unlikely, it is possible that the RPC server will die just after sending us the answer, but before sending an acknowledgment message for the request. If that happens, the restarted RPC server will process the request again. That\u0026rsquo;s why on the client we must handle the duplicate responses gracefully, and the RPC should ideally be idempotent.\n你可能会问，为什么我们应该忽视回调队列中的未知消息，而不是因为错误而失败？这是由于服务端可能出现竞争状况。虽然可能性不大，RPC服务器有可能在向我们发送答案之后在发送请求的确认消息之前就死掉。如果这种情况发生，重启RPC服务将再次处理这个请求。这是为什么我们必须优雅处理重复的响应，并且理想情况下 RPC应该是幂等的。\nSummary #  Our RPC will work like this:\n我们的RPC将这样工作：\n  When the Client starts up, it creates an anonymous exclusive callback queue.\n当客户端开始，它创建一个匿名独占回调队列。\n  For an RPC request, the Client sends a message with two properties: reply_to, which is set to the callback queue and correlation_id, which is set to a unique value for every request.\n对于一个 RPC 请求，客户端发送一个带有两个属性消息: reply_to 是用来设置回调队列， correlation_id 是用来为每一个请求设置单独的值。\n  The request is sent to an rpc_queue queue.\n这个请求被发送到一个 rpc_queue 队列。\n  The RPC worker (aka: server) is waiting for requests on that queue. When a request appears, it does the job and sends a message with the result back to the Client, using the queue from the reply_to field.\n这个RPC服务器等待队列上的请求。当一个请求出现，它将做这个工作并使用reply_to 字段的队列 发送一个带有结果的消息给客户端，\n  The client waits for data on the callback queue. When a message appears, it checks the correlation_id property. If it matches the value from the request it returns the response to the application.\n客户端等待这个回调队列的数据。当一个消息出现，它检测correlation_id属性值。如果它匹配来自于请求的值，它会返回这个响应给应用程序。\n  Putting it all together #  the Fibonacci function：\nfunc fib(n int) int { if n \u0026gt; =0 \u0026amp;\u0026amp; n \u0026lt;= 1 { return n } else { return fib(n-1) + fib(n-2) } } We declare our fibonacci function. It assumes only valid positive integer input. (Don\u0026rsquo;t expect this one to work for big numbers, and it\u0026rsquo;s probably the slowest recursive implementation possible).\n我们声明我们的fibonacci 函数。它假设仅有效的正整数的输入。（不要期待一个很大的数，这可能是最慢的递归实现）\nThe code for our RPC server rpc_server.go looks like this:\nRPC服务器代码\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;github.com/streadway/amqp\u0026#34; ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\u0026#34;%s: %s\u0026#34;, msg, err) } } func fib(n int) int { if n == 0 { return 0 } else if n == 1 { return 1 } else { return fib(n-1) + fib(n-2) } } func main() { conn, err := amqp.Dial(\u0026#34;amqp://guest:guest@localhost:5672/\u0026#34;) failOnError(err, \u0026#34;Failed to connect to RabbitMQ\u0026#34;) defer conn.Close() ch, err := conn.Channel() failOnError(err, \u0026#34;Failed to open a channel\u0026#34;) defer ch.Close() q, err := ch.QueueDeclare( \u0026#34;rpc_queue\u0026#34;, // name  false, // durable  false, // delete when unused  false, // exclusive  false, // no-wait  nil, // arguments  ) failOnError(err, \u0026#34;Failed to declare a queue\u0026#34;) err = ch.Qos( 1, // prefetch count 拉取数量  0, // prefetch size  false, // global  ) failOnError(err, \u0026#34;Failed to set QoS\u0026#34;) msgs, err := ch.Consume( q.Name, // queue  \u0026#34;\u0026#34;, // consumer  false, // auto-ack  false, // exclusive  false, // no-local  false, // no-wait  nil, // args  ) failOnError(err, \u0026#34;Failed to register a consumer\u0026#34;) forever := make(chan bool) go func() { for d := range msgs { n, err := strconv.Atoi(string(d.Body)) failOnError(err, \u0026#34;Failed to convert body to integer\u0026#34;) log.Printf(\u0026#34; [.] fib(%d)\u0026#34;, n) response := fib(n) err = ch.Publish( \u0026#34;\u0026#34;, // exchange  d.ReplyTo, // routing key  false, // mandatory  false, // immediate  amqp.Publishing{ ContentType: \u0026#34;text/plain\u0026#34;, CorrelationId: d.CorrelationId, Body: []byte(strconv.Itoa(response)), }) failOnError(err, \u0026#34;Failed to publish a message\u0026#34;) d.Ack(false) } }() log.Printf(\u0026#34; [*] Awaiting RPC requests\u0026#34;) \u0026lt;-forever } The server code is rather straightforward:\n服务器代码是非常简单的\n  As usual we start by establishing the connection, channel and declaring the queue.\n像往常一样我们通过建立连接，通道，和声明队列开始\n  We might want to run more than one server process. In order to spread the load equally over multiple servers we need to set the prefetch setting on channel.\n我们可能像运行多个服务器程序。为了将负载平均分配到多个服务器上，我们需要在通道上设置prefetch 设置。\n  We use Channel.Consume to get the go channel where we receive messages from the queue. Then we enter the goroutine where we do the work and send the response back.\n我们使用Channel.Consumer获取从队列接收消息的GO通道。然后我们进入 goroutine 我们做一些工作，并将响应发送回去。\n  The code for our RPC client rpc_client.go:\nRPC 客户端代码\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/streadway/amqp\u0026#34; ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\u0026#34;%s: %s\u0026#34;, msg, err) } } func randomString(l int) string { bytes := make([]byte, l) for i := 0; i \u0026lt; l; i++ { bytes[i] = byte(randInt(65, 90)) } return string(bytes) } func randInt(min int, max int) int { return min + rand.Intn(max-min) } func fibonacciRPC(n int) (res int, err error) { conn, err := amqp.Dial(\u0026#34;amqp://guest:guest@localhost:5672/\u0026#34;) failOnError(err, \u0026#34;Failed to connect to RabbitMQ\u0026#34;) defer conn.Close() ch, err := conn.Channel() failOnError(err, \u0026#34;Failed to open a channel\u0026#34;) defer ch.Close() q, err := ch.QueueDeclare( \u0026#34;\u0026#34;, // name  false, // durable  false, // delete when unused  true, // exclusive  false, // noWait  nil, // arguments  ) failOnError(err, \u0026#34;Failed to declare a queue\u0026#34;) msgs, err := ch.Consume( q.Name, // queue  \u0026#34;\u0026#34;, // consumer  true, // auto-ack  false, // exclusive  false, // no-local  false, // no-wait  nil, // args  ) failOnError(err, \u0026#34;Failed to register a consumer\u0026#34;) corrId := randomString(32) err = ch.Publish( \u0026#34;\u0026#34;, // exchange  \u0026#34;rpc_queue\u0026#34;, // routing key  false, // mandatory  false, // immediate  amqp.Publishing{ ContentType: \u0026#34;text/plain\u0026#34;, CorrelationId: corrId, ReplyTo: q.Name, Body: []byte(strconv.Itoa(n)), }) failOnError(err, \u0026#34;Failed to publish a message\u0026#34;) for d := range msgs { if corrId == d.CorrelationId { res, err = strconv.Atoi(string(d.Body)) failOnError(err, \u0026#34;Failed to convert body to integer\u0026#34;) break } } return } func main() { rand.Seed(time.Now().UTC().UnixNano()) n := bodyFrom(os.Args) log.Printf(\u0026#34; [x] Requesting fib(%d)\u0026#34;, n) res, err := fibonacciRPC(n) failOnError(err, \u0026#34;Failed to handle RPC request\u0026#34;) log.Printf(\u0026#34; [.] Got %d\u0026#34;, res) } func bodyFrom(args []string) int { var s string if (len(args) \u0026lt; 2) || os.Args[1] == \u0026#34;\u0026#34; { s = \u0026#34;30\u0026#34; } else { s = strings.Join(args[1:], \u0026#34; \u0026#34;) } n, err := strconv.Atoi(s) failOnError(err, \u0026#34;Failed to convert arg to integer\u0026#34;) return n } Now is a good time to take a look at our full example source code for rpc_client.go and rpc_server.go.\n代码资源链接\nOur RPC service is now ready. We can start the server:\nRPC 服务已经准备完毕，我们运行服务\ngo run rpc_server.go To request a fibonacci number run the client:\n为了请求一个 fibonacci 数 运行这个客户端\ngo run rpc_client.go 30 The design presented here is not the only possible implementation of a RPC service, but it has some important advantages:\n这儿呈现的设计不仅仅是 RPC 服务的可能的实现，而且它有一些重要的好处\n  If the RPC server is too slow, you can scale up by just running another one. Try running a second rpc_server.go in a new console.\n如果 RPC 服务器太慢，你仅仅运行另一个来提高效率。尝试在一个控制台运行第二个 rpc_server.go\n  On the client side, the RPC requires sending and receiving only one message. As a result the RPC client needs only one network round trip for a single RPC request.\n在客户端， RPC 只需要发送和接受一个消息。 因此 RPC客户端对一个 RPC 请求只需要一次网络往返。\n  Our code is still pretty simplistic and doesn\u0026rsquo;t try to solve more complex (but important) problems, like:\n我们的代码仍然是非常简单的并且没有尝试解决更多复查且重要的问题，如\n  How should the client react if there are no servers running?\n如果没有服务器运行，客户端响应应该怎么做？\n  Should a client have some kind of timeout for the RPC?\n客户端是否应该为RPC设置某种超时时间？\n  If the server malfunctions and raises an exception, should it be forwarded to the client?\n如果服务器故障并抛出异常，它应该转发给客户端吗？\n  Protecting against invalid incoming messages (eg checking bounds, type) before processing.\n在处理之前防止无效的传入消息（例如 检查边界，类型）\n  "}),a.add({id:11,href:'/docs/linux/ubuntu-%E4%B8%AD%E8%AE%BE%E7%BD%AE%E5%9B%BD%E5%86%85%E8%BD%AF%E4%BB%B6%E6%BA%90/',title:"Ubuntu 软件源",section:"Linux",content:"ubuntu 把软件源修改为国内源和更新 #    备份原始文件\nsudo cp /etc/apt/sources.list /etc/apt/sources.list.backup   修改文件并添加国内源\nvi /etc/apt/sources.list	  注释原文件内的源 并添加如下地址 复制代码\n# Ubuntu 官方源 deb http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiverse deb http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiverse deb http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiverse deb http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiverse deb http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ gutsy main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ gutsy-security main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ gutsy-updates main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ gutsy-proposed main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ gutsy-backports main restricted universe multiverse # 阿里云 deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse # 网易163 deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse # 非官方包可能存在不完整情况，可在尾部添加官方源 deb http://archive.ubuntu.org.cn/ubuntu-cn/ feisty main restricted universe multiverse   更新源\nsudo apt-get update   更新软件\n注意：\n由于包与包之间存在各种依赖关系。upgrade只是简单的更新包，不管这些依赖，它不和添加包，或是删除包。而dist-upgrade可以根据依赖关系的变化，添加包，删除包。upgrade:系统将现有的Package升级,如果有相依性的问题,而此相依性需要安装其它新的Package或影响到其它Package的相依性时,此Package就不会被升级,会保留下来. dist-upgrade:可以聪明的解决相依性的问题,如果有相依性问题,需要安装/移除新的Package,就会试着去安装/移除它. (所以通常这个会被认为是有点风险的升级)\n# 谨慎操作 sudo apt-get dist-upgrade sudo apt-get upgrade   常见的修复安装命令\nsudo apt-get -f install    国内主要软件源 #  企业站 #  1.搜狐：http://mirrors.sohu.com/ 2.网易：http://mirrors.163.com/ 3.阿里云：http://mirrors.aliyun.com/ 4.腾讯：http://Android-mirror.bugly.qq.com:8080/（仅针对APP开发的软件，限流，不推荐） 5.淘宝：http://npm.taobao.org/ 教育站 #  1.上海交通大学：http://ftp.sjtu.edu.cn/html/resources.xml（部分移动运营商出口状况不佳，无法访问） 2.华中科技大学：http://mirror.hust.edu.cn/（当前已用容量估计：4.83T） 3.清华大学：http://mirrors.tuna.tsinghua.edu.cn/（当前已用容量估计：9.8T） 4.北京理工大学：http://mirror.bit.edu.cn/web/ 5.兰州大学：http://mirror.lzu.edu.cn/ 6.中国科技大学：http://mirrors.ustc.edu.cn/（当前已用容量估计：21.32T） 7.大连东软信息学院：http://mirrors.neusoft.edu.cn/（当前已用容量估计：2.5T） 8.东北大学：http://mirror.neu.edu.cn/ 9.大连理工大学：http://mirror.dlut.edu.cn/ 10.哈尔滨工业大学：http://run.hit.edu.cn/html/（部分联通运营商出口状况不佳，无法访问） 11.北京交通大学：http://mirror.bjtu.edu.cn/cn/ 12.天津大学：http://mirror.tju.edu.cn（无法访问，ping超时） 13.中国地质大学：http://mirrors.cug.edu.cn/（当前已用容量估计：2.3T） 14.浙江大学：http://mirrors.zju.edu.cn/ 15.厦门大学：http://mirrors.xmu.edu.cn/ 16.中山大学：http://mirror.sysu.edu.cn/ 17.重庆大学：http://mirrors.cqu.edu.cn/（当前已用容量估计：3.93T） 18.北京化工大学：http://Ubuntu.buct.edu.cn/（Android SDK镜像仅供校内使用，当前已用容量估计：1.72T） 19.南阳理工学院：http://mirror.nyist.edu.cn/ 20.中国科学院：http://www.opencas.org/mirrors/ 21.电子科技大学：http://ubuntu.uestc.edu.cn/（无法访问，ping超时） 22.电子科技大学星辰工作室：http://mirrors.stuhome.net/（当前已用容量估计：1.08T） 23.西北农林科技大学：http://mirrors.nwsuaf.edu.cn/（只做CentOS镜像，当前已用容量估计：140GB） 24.浙江大学：http://mirrors.zju.edu.cn/ 25.台湾淡江大学: http://ftp.tku.edu.tw/Linux/ 其他 #  1.首都在线科技股份有限公司（英文名Capital Online Data Service）：http://mirrors.yun-idc.com/ 2.中国电信天翼云：http://mirrors.ctyun.cn/ 3.noc.im：http://mirrors.noc.im/（当前已用容量估计：3.74T） 4.常州贝特康姆软件技术有限公司：http://centos.bitcomm.cn/（只做CentOS镜像，当前已用容量估计：140GB） 5.公云PubYun（母公司为贝特康姆）：http://mirrors.pubyun.com/ 6.Linux运维派：http://mirrors.skyshe.cn/（使用阿里云服务器，界面使用浙江大学的模板，首页维护，内容可访问） 7.中国互联网络信息中心：http://mirrors.cnnic.cn/（只做Apache镜像，当前已用容量估计：120GB） 8.Fayea工作室：http://apache.fayea.com/（只做Apache镜像，当前已用容量估计：120GB） 9.开源中国社区 http://mirrors.oss.org.cn/ 软件版 #  操作系统类 #  # Ubuntu 阿里云：http://mirrors.aliyun.com/ubuntu-releases/ 网易：http://mirrors.163.com/ubuntu-releases/ 搜狐：http://mirrors.sohu.com/ubuntu-releases/（搜狐在12年之后似乎不同步了） 首都在线科技股份有限公司：http://mirrors.yun-idc.com/ubuntu-releases/ # CentOS 网易：http://mirrors.163.com/centos/ 搜狐：http://mirrors.sohu.com/centos/ 阿里云：http://mirrors.aliyun.com/centos/ 服务器类 #  # Apache 中国互联网络信息中心：http://mirrors.cnnic.cn/apache/ 华中科技大学：http://mirrors.hust.edu.cn/apache/ 北京理工大学：http://mirror.bit.edu.cn/apache/ # MySQL 北京理工大学：http://mirror.bit.edu.cn/mysql/Downloads/ 中国电信天翼云：http://mirrors.ctyun.cn/Mysql/ # PostgreSQL 浙江大学：http://mirrors.zju.edu.cn/postgresql/ # MariaDB 中国电信天翼云：http://mirrors.ctyun.cn/MariaDB/ # VideoLAN 大连东软信息学院：http://mirrors.neusoft.edu.cn/videolan/ 中国科技大学：http://mirrors.ustc.edu.cn/videolan-ftp/ 开发工具类 #  # Eclipse 中国科技大学：http://mirrors.ustc.edu.cn/eclipse/ 中国科学院：http://mirrors.opencas.cn/eclipse/ 东北大学：http://ftp.neu.edu.cn/mirrors/eclipse/，http://mirror.neu.edu.cn/eclipse/ # 安卓SDK 中国科学院：http://mirrors.opencas.ac.cn/android/repository/ 南洋理工学院：http://mirror.nyist.edu.cn/android/repository/ 中国科学院：http://mirrors.opencas.cn/android/repository/ 腾讯：http://android-mirror.bugly.qq.com:8080/android/repository/（限流，不推荐） 大连东软信息学院：http://mirrors.neusoft.edu.cn/android/repository/（同步效果不如中科院的镜像，不推荐） # Xcode 腾讯：http://android-mirror.bugly.qq.com:8080/Xcode/（从7.2之后不再更新，建议直接从官网下载） 官方镜像列表状态地址 #  CentOS：http://mirror-status.centos.org/#cn Archlinux：https://www.archlinux.org/mirrors/status/ Ubuntu：https://launchpad.net/ubuntu/+cdmirrors Debian：http://mirror.debian.org/status.html Fedora Linux/Fedora EPEL：https://admin.fedoraproject.org/mirrormanager/mirrors Apache：http://www.apache.org/mirrors/#cn Cygwin：https://www.cygwin.com/mirrors.html "}),a.add({id:12,href:'/docs/golang/go-%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/',title:"多平台交叉编译",section:"Golang",content:"多平台交叉编译 #  windows #  window平台下编译其他平台的程序文件，修改 go env 配置\nMac # go env SET CGO_ENABLED=0 SET GOOS=darwin SET GOARCH=amd64 Linux # go env SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64  示例：go env -w CGO_ENABLED=0 GOOS=linux GOARCH=amd64\nLinux #  Linux平台下编译其他平台的程序文件，修改 go env 配置\nMac # go env SET CGO_ENABLED=0 SET GOOS=darwin SET GOARCH=amd64 Windows # go env SET CGO_ENABLED=0 SET GOOS=windows SET GOARCH=amd64  示例：go env -w CGO_ENABLED=0 GOOS=windows GOARCH=amd64\nMac #  Mac平台下编译其他平台的程序文件，修改 go env 配置\nLinux # go env SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 Windows # go env SET CGO_ENABLED=0 SET GOOS=windows SET GOARCH=amd64  示例：go env -w CGO_ENABLED=0 GOOS=windows GOARCH=amd64\n"}),a.add({id:13,href:'/posts/%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8git%E7%AE%A1%E7%90%86%E5%A4%9A%E4%B8%AA%E5%B5%8C%E5%A5%97%E7%9A%84%E4%BB%93%E5%BA%93/',title:"怎么使用Git管理多个嵌套的仓库?",section:"Blog",content:"怎么使用Git管理多个嵌套的仓库? #  场景: 在使用hugo来生成静态网页博客的项目中,除了要管理public中生存的静态网页文件,还需要管里保存hugo生存的站点等文件仓库,以及主题仓库等;他们之间的仓库文件关系如下:\n# 整个作为一个git仓库进行保存 ├── README.md ├── archetypes │ └── default.md ├── auto\\ push.bat # 自动推送脚本到 github ├── auto_push.sh # 自动生成网页查看 ├── config.toml ├── content │ ├── _index.md │ ├── docs │ ├── menu │ └── posts ├── hugo ├── hugo.exe ├── public # 这个是生成的静态网页数据(作为一个git仓库),这里会推送到github.io 进行展示 ├── resources │ └── _gen ├── start.bat ├── start.sh ├── static │ └── docs └── themes └── book # 这里是主题,也是作为 子模块 添加的hugo的主题仓库 也就是一个git仓库下,还存在两个git仓库. 怎样实现正常规范的管理\nGit 多项目管理\u0026ndash;git submodule #  子模块管理能实现git仓库的独立管理,尽管文件的结构目录是嵌套的. 下面是引用官方的文档翻译:\n Git子模块允许你将一个Git仓库作为另一个Git仓库的子目录。它能让你将另一个仓库克隆到自己的项目中，同时还保持独立的提交\n 添加public的子模块仓库 #  # 如果已经在主 git 仓库中存在 public 需要进行删除并进行提交 git submodule add https://github.com/menggus/menggus.github.io.git public 添加themmes/book的子模块仓库 #  # 出现提示 已存在报错时,可以向上面一样进行处理 git submodule add https://github.com/alex-shpak/hugo-book themes/book 这样三个git 仓库可以独立管理,互不干扰.\n查看 子仓库管理文件 #  [submodule \u0026quot;themes/book\u0026quot;] path = themes/book url = https://github.com/alex-shpak/hugo-book [submodule \u0026quot;public\u0026quot;] path = public url = https://github.com/menggus/menggus.github.io.git 文件内容就是所有添加的子模块信息\n"}),a.add({id:14,href:'/docs/golang/go-%E4%B8%AD%E7%9A%84%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E7%AD%96%E7%95%A5/',title:"错误处理策略",section:"Golang",content:"Go 中的错误处理策略 #  一、传递错误 #  传递错误就是向函数的调用者传递错误。\n当函数返回错误时，调用者应该负责检查错误并采取合适的方式进行处理。\n 1.直接返回错误，不做任何的修改与包装\nreturn nil, err   2.对错误进行包装再返回\nif err != nil { return nil, fmt.Errorf(\u0026#34;parsing %s as HTML: %V\u0026#34;, url, err) }  包装error宗旨：错误信息能够提供一个从最根本问题到总体问题故障的清晰因果链\n1.包含充足的相关信息，并保持一致性\n2.传递过程中不断补充在处理错误可能需要的信息\n二、多次重试后，再传递错误 #  对于不固定和不可预测的错误，在短暂的间隔后再进行重试，超出重试次数和限定时间后再报错退出。\ngop1.io/ch5/wait\n// WaitForServer 尝试连接URL对应的服务器 // 在一分钟内使用指数退避策略进行重试 // 所有尝试失败后退出 func WaitForServer(url string) error { const timeout = 1 * time.Minute deadline := time.Now().Add(timeout) for tries := 0; time.Now().Before(deadline); tries ++ { _, err := http.Head(url) if err == nil { return nil // 成功  } log.Printf(\u0026#34;server not responding (%s); retrying...\u0026#34;, err) time.sleep(time.Second \u0026lt;\u0026lt; unit(tries)) // 指数退避策略 休眠2的n次方时间  } return fmt.Errorf(\u0026#34;server %s failed to respond after %s\u0026#34;, url, timeout) } 三、输出错误，并优雅的停止程序 #  如果对于多次重试后，仍然不能顺利进行下去，调用者能够输出错误然后优雅的停止程序。\n 这里的停止程序，应该要留给主程序部分来停止\n 举例：\n通常库函数应当传递错误给调用者，除非这个错误表示一个内部一致性的错误\nif err := WaitForServer(url); err != nil { fmt.FPrintf(os.Stderr, \u0026#34;Site is down: %v\\n\u0026#34;, err) os.Exit(1) } // 上述打印输出以及退出程序可以有代替方法 if err := WaitForServer(url); err != nil { log.Fatalf(\u0026#34;Site is down: %v\\n\u0026#34;, err) // 直接输出并退出，输出有时间等信息，并可定制输出格式 } 四、只记录错误，程序继续运行 #  使用log包来输出日志，可定制\nif err := Ping(); err != nil { log.Printf(\u0026#34;ping failed %v; networking disabled\u0026#34;, err) // log包的相关函数会自动添加换行 } 五、少数情况下，直接忽略日志 #  os.RemoveAll(dir) // 忽略错误，但是需要注释 忽略的意图 "}),a.add({id:15,href:'/docs/pxc/%E4%BC%98%E5%8C%96%E7%9B%B8%E5%85%B3/',title:"集群优化相关",section:"Pxc",content:"分页查询优化 #  这边先看几个简单例子：\n-- 查询优化 select * from t_test limit 100,100; -- 85ms select * from t_test limit 1000,100; -- 279ms select * from t_test limit 10000,100;	-- 2s31ms select * from t_test limit 100000,100; -- 19s497ms 怎么去优化呢？\n我们可以通过 explain 命令来查看，可关注type all为全表扫描，查看rows可以知道扫描数据row数\nmysql\u0026gt; explain select * from t_test limit 1000,100; +----+-------------+--------+------------+------+---------------+------+---------+------+---------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+------+---------------+------+---------+------+---------+----------+-------+ | 1 | SIMPLE | t_test | NULL | ALL | NULL | NULL | NULL | NULL | 4585371 | 100.00 | NULL | +----+-------------+--------+------------+------+---------------+------+---------+------+---------+----------+-------+ 1 row in set, 1 warning (0.00 sec) 如果使用条件where， type 为range 变成范围查询，并且使用主键，扫描的row数变少很多；\nmysql\u0026gt; explain select * from t_test where id\u0026gt;1000 limit 100; +----+-------------+--------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ | 1 | SIMPLE | t_test | NULL | range | PRIMARY | PRIMARY | 4 | NULL | 2292685 | 100.00 | Using where | +----+-------------+--------+------------+-------+---------------+---------+---------+------+---------+----------+-------------+ 1 row in set, 1 warning (0.01 sec) 直接使用where 条件过滤出数据，扫描行数才仅仅50\nmysql\u0026gt; explain select * from t_test where id\u0026gt;1000 and id\u0026lt; 1100; +----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+ | 1 | SIMPLE | t_test | NULL | range | PRIMARY | PRIMARY | 4 | NULL | 50 | 100.00 | Using where | +----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec) 可知第三种方式应该是最优情况；\n但是第三种方式是否存在问题呢？如果说主键不连续的情况下，过滤的数据是否一定是刚好100条呢？\n答案是否定的，如果主键不连续，那就是少于100条数据。\n解决办法：采用逻辑删除\n如果物理删除时，这里也有一个折中办法。利用主键来加速。\nselect * from t_test t join (select id from t_test where id\u0026gt;100000 limit 100) t1 on t.id=t1.id; "})})()